0 bad agents
      adv rate for q_index :  0 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
      adv rate for p_index :  0 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
1 bad agents
      adv rate for q_index :  1 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
      adv rate for p_index :  1 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
2 bad agents
      adv rate for q_index :  2 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
      adv rate for p_index :  2 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
3 bad agents
      adv rate for q_index :  3 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
      adv rate for p_index :  3 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
4 good agents
      adv rate for q_index :  4 [0.001, 0.001, 0.001, 0.001, 1e-05, 1e-05]
      adv rate for p_index :  4 [0.001, 0.001, 0.001, 0.001, 1e-05, 1e-05]
5 good agents
      adv rate for q_index :  5 [0.001, 0.001, 0.001, 0.001, 1e-05, 1e-05]
      adv rate for p_index :  5 [0.001, 0.001, 0.001, 0.001, 1e-05, 1e-05]
Using good policy mmmaddpg and bad policy mmmaddpg with 4 adversaries
Starting iterations...
mmmaddpg vs mmmaddpg steps: 24975, episodes: 1000, mean episode reward: -24.520065988450884, agent episode reward: [1.104319025943338, 1.0683268684922504, 1.0667367260667064, 1.1439528706493076, -10.434978851313568, -18.46842262828892], time: 149.541
mmmaddpg vs mmmaddpg steps: 49975, episodes: 2000, mean episode reward: -10.462065533711666, agent episode reward: [2.905651646404803, 2.8524180414999396, 3.091870410087691, 2.985930288816812, -14.540185350893653, -7.7577505696272535], time: 247.065
mmmaddpg vs mmmaddpg steps: 74975, episodes: 3000, mean episode reward: 12.666798242123614, agent episode reward: [4.052863855962013, 4.21195320924393, 4.689098051445345, 4.364867793513817, -2.3241159187029243, -2.3278687493385664], time: 249.521
mmmaddpg vs mmmaddpg steps: 99975, episodes: 4000, mean episode reward: 15.28753319643131, agent episode reward: [5.151320521508483, 4.6310587973103585, 5.539232657323222, 4.990328908382189, -2.452871903507496, -2.5715357845854485], time: 249.707
mmmaddpg vs mmmaddpg steps: 124975, episodes: 5000, mean episode reward: 21.827282929161374, agent episode reward: [6.988406834111619, 6.829849990343956, 7.638980702639007, 6.99464650576779, -3.729549665695946, -2.8950514380050474], time: 250.849
mmmaddpg vs mmmaddpg steps: 149975, episodes: 6000, mean episode reward: 28.572743992033285, agent episode reward: [9.246891213068077, 9.090760761518203, 9.223480321464395, 9.598146837228237, -4.526013627170824, -4.060521514074805], time: 251.715
mmmaddpg vs mmmaddpg steps: 174975, episodes: 7000, mean episode reward: 42.874712134454974, agent episode reward: [13.913068408211831, 13.906449386042459, 14.130887260050466, 14.403842702811875, -7.16950046811715, -6.31003515454451], time: 256.981
mmmaddpg vs mmmaddpg steps: 199975, episodes: 8000, mean episode reward: 41.257054443261936, agent episode reward: [13.161980258327135, 13.392657964879826, 13.60936424675036, 13.765695602087147, -8.018399400772639, -4.6542442280098975], time: 256.716
mmmaddpg vs mmmaddpg steps: 224975, episodes: 9000, mean episode reward: 49.44789671329543, agent episode reward: [15.773361250118997, 16.450153702133598, 16.405584311545777, 16.551893952294325, -10.902201412885013, -4.8308950899122545], time: 257.666
mmmaddpg vs mmmaddpg steps: 249975, episodes: 10000, mean episode reward: 41.77661788134152, agent episode reward: [13.510593981966503, 13.933748805774208, 13.808952026401224, 13.939296536141715, -9.132916411975017, -4.283057056967111], time: 259.707
mmmaddpg vs mmmaddpg steps: 274975, episodes: 11000, mean episode reward: 37.290601463714204, agent episode reward: [12.464883530636147, 12.587043806696311, 12.248525223718255, 12.615360501601343, -8.913659560269457, -3.711552038668395], time: 258.812
mmmaddpg vs mmmaddpg steps: 299975, episodes: 12000, mean episode reward: 21.20192801559595, agent episode reward: [7.485045561311589, 7.649456385421063, 7.536094888977898, 7.644692128010531, -6.007018569994212, -3.106342378130924], time: 260.136
mmmaddpg vs mmmaddpg steps: 324975, episodes: 13000, mean episode reward: 10.561336445914822, agent episode reward: [4.861672930420502, 4.869884855896793, 4.84971613364, 4.873045405634096, -6.247343136766494, -2.6456397429100775], time: 260.925
mmmaddpg vs mmmaddpg steps: 349975, episodes: 14000, mean episode reward: 9.346073633705794, agent episode reward: [4.860321223607039, 4.706020638265465, 4.739656350928532, 4.740276382744896, -6.837329751111205, -2.862871210728935], time: 255.602
mmmaddpg vs mmmaddpg steps: 374975, episodes: 15000, mean episode reward: 12.719373541367927, agent episode reward: [5.477297428015596, 5.327195035484524, 5.36256895878535, 5.319626888094445, -6.229812434580066, -2.53750233443192], time: 263.608
mmmaddpg vs mmmaddpg steps: 399975, episodes: 16000, mean episode reward: 13.440134859349081, agent episode reward: [5.372955195227643, 5.216857253140082, 5.281529516185503, 5.265532605261442, -5.925119457248058, -1.7716202532175318], time: 260.764
mmmaddpg vs mmmaddpg steps: 424975, episodes: 17000, mean episode reward: 14.224993726766227, agent episode reward: [5.735707684071828, 5.616413220109795, 5.667398193706927, 5.633566091338061, -6.157674481987876, -2.270416980472509], time: 259.971
mmmaddpg vs mmmaddpg steps: 449975, episodes: 18000, mean episode reward: 20.278785767133705, agent episode reward: [7.365357780101897, 7.307662899528368, 7.35586227764609, 7.368151187866699, -6.5966184959296745, -2.5216298820796754], time: 261.993
mmmaddpg vs mmmaddpg steps: 474975, episodes: 19000, mean episode reward: 21.115371392012026, agent episode reward: [7.747490887620267, 7.620914696189784, 7.673108453178929, 7.691293796285542, -6.748305931690618, -2.869130509571878], time: 254.599
mmmaddpg vs mmmaddpg steps: 499975, episodes: 20000, mean episode reward: 26.239357251503765, agent episode reward: [9.428317954148921, 9.415365633018228, 9.381190425832447, 9.426236908701627, -9.078130845567884, -2.3336228246295687], time: 261.52
mmmaddpg vs mmmaddpg steps: 524975, episodes: 21000, mean episode reward: 26.27032873464032, agent episode reward: [9.245507767565456, 9.233164951157299, 9.207982428438237, 9.184848995912827, -8.762570034579129, -1.8386053738543742], time: 261.517
mmmaddpg vs mmmaddpg steps: 549975, episodes: 22000, mean episode reward: 26.24220871132202, agent episode reward: [9.513082932393685, 9.578707472065217, 9.456328839048812, 9.36608981925955, -10.255618614720037, -1.4163817367252045], time: 262.479
mmmaddpg vs mmmaddpg steps: 574975, episodes: 23000, mean episode reward: 21.46595409027973, agent episode reward: [8.289874611335982, 8.348554670139924, 8.22494438231802, 8.03712039849396, -9.957279719990362, -1.4772602520177882], time: 258.264
mmmaddpg vs mmmaddpg steps: 599975, episodes: 24000, mean episode reward: 17.08548161568177, agent episode reward: [7.276002483706201, 7.381723207899634, 7.129304906491294, 7.215282260207686, -9.844656993015109, -2.0721742496079374], time: 268.354
mmmaddpg vs mmmaddpg steps: 624975, episodes: 25000, mean episode reward: 9.081095663691345, agent episode reward: [5.730968281940011, 5.611609105354834, 5.5798320133502655, 5.434650976845745, -11.28867815591463, -1.9872865578848817], time: 265.166
mmmaddpg vs mmmaddpg steps: 649975, episodes: 26000, mean episode reward: 11.207504029306866, agent episode reward: [5.806264748727888, 5.460815752435348, 5.539860058455788, 5.369213646749376, -9.09064390403921, -1.8780062730223253], time: 266.623
mmmaddpg vs mmmaddpg steps: 674975, episodes: 27000, mean episode reward: 13.874893274488063, agent episode reward: [6.357452309556626, 5.858131130584896, 6.2823315945217235, 5.82086157315889, -7.8780227918477905, -2.565860541486283], time: 269.585
mmmaddpg vs mmmaddpg steps: 699975, episodes: 28000, mean episode reward: 28.00026802149932, agent episode reward: [10.374655186058277, 9.854829458153773, 10.11331313384664, 9.914597324314535, -8.698995183311355, -3.558131897562549], time: 272.35
mmmaddpg vs mmmaddpg steps: 724975, episodes: 29000, mean episode reward: 38.00285947178426, agent episode reward: [13.306151539494211, 13.140466427361298, 12.78312874910039, 13.14506212894546, -11.059892262507834, -3.3120571106092664], time: 270.587
mmmaddpg vs mmmaddpg steps: 749975, episodes: 30000, mean episode reward: 28.19957507139754, agent episode reward: [10.186406615112196, 10.043243382956392, 9.655563006043783, 10.023124780480352, -8.213300947548753, -3.4954617656464295], time: 263.218
mmmaddpg vs mmmaddpg steps: 774975, episodes: 31000, mean episode reward: 24.703708986372995, agent episode reward: [9.415906575263362, 9.291024183636898, 9.209580005800966, 9.242236959338621, -8.026123184156278, -4.428915553510575], time: 269.734
mmmaddpg vs mmmaddpg steps: 799975, episodes: 32000, mean episode reward: 20.60164915047445, agent episode reward: [8.506452127526286, 8.382377796289337, 8.23406794874267, 8.334404212413093, -7.913012595646049, -4.942640338850883], time: 263.507
mmmaddpg vs mmmaddpg steps: 824975, episodes: 33000, mean episode reward: 17.56945657614333, agent episode reward: [6.7349889421923965, 6.6677804119112585, 6.574647758166873, 6.5461022892298955, -6.171480663317011, -2.7825821620400846], time: 269.013
mmmaddpg vs mmmaddpg steps: 849975, episodes: 34000, mean episode reward: 21.012862393656494, agent episode reward: [8.076736581362292, 7.917918649727294, 7.880236690067781, 7.839218759404756, -7.791134542320583, -2.9101137445850442], time: 271.778
mmmaddpg vs mmmaddpg steps: 874975, episodes: 35000, mean episode reward: 22.094834523556738, agent episode reward: [8.804413154415432, 8.7410847257787, 8.611356838557054, 8.627123594323784, -9.740436524878806, -2.9487072646394297], time: 265.722
mmmaddpg vs mmmaddpg steps: 899975, episodes: 36000, mean episode reward: 26.28222723390549, agent episode reward: [9.83427694861451, 9.737375830238411, 9.597176660012057, 9.65852284272593, -9.959269221495727, -2.585855826189695], time: 269.389
mmmaddpg vs mmmaddpg steps: 924975, episodes: 37000, mean episode reward: 23.797402950619443, agent episode reward: [9.077585714576598, 8.983696484826355, 8.806756477200317, 8.79134335656345, -9.611559249161557, -2.2504198333857204], time: 275.5
mmmaddpg vs mmmaddpg steps: 949975, episodes: 38000, mean episode reward: 27.268752703498087, agent episode reward: [10.69237056114443, 10.410353200425678, 10.401446287435745, 10.35230802126742, -11.783305363079439, -2.8044200036957463], time: 277.555
mmmaddpg vs mmmaddpg steps: 974975, episodes: 39000, mean episode reward: 27.39865650266699, agent episode reward: [10.90693543727895, 10.64030860324295, 10.681518152304422, 10.57656673290207, -12.48093761386577, -2.925734809195631], time: 268.345
mmmaddpg vs mmmaddpg steps: 999975, episodes: 40000, mean episode reward: 27.551200998001846, agent episode reward: [10.660255108152258, 10.556233107769462, 10.63956740544313, 10.475587180305796, -11.48945454843843, -3.290987255230371], time: 274.214
mmmaddpg vs mmmaddpg steps: 1024975, episodes: 41000, mean episode reward: 30.367511907691913, agent episode reward: [11.736641684658512, 11.533574002771289, 11.5983652764284, 11.462374368015801, -12.700283582855155, -3.2631598413269294], time: 269.157
mmmaddpg vs mmmaddpg steps: 1049975, episodes: 42000, mean episode reward: 29.95525085502655, agent episode reward: [11.100428971389269, 10.890355507749474, 10.918463788905276, 10.932132433522561, -9.585931481905572, -4.300198364634461], time: 273.666
mmmaddpg vs mmmaddpg steps: 1074975, episodes: 43000, mean episode reward: 32.31777143488028, agent episode reward: [12.354466528347228, 12.167676307322445, 12.144522033180953, 12.267539866589651, -10.396966021545955, -6.219467279014046], time: 272.771
mmmaddpg vs mmmaddpg steps: 1099975, episodes: 44000, mean episode reward: 53.94507864471411, agent episode reward: [19.937481943039785, 19.849284716486373, 19.810871532736375, 19.870840854648684, -17.913471426897406, -7.609928975299712], time: 272.811
mmmaddpg vs mmmaddpg steps: 1124975, episodes: 45000, mean episode reward: 50.08638700113533, agent episode reward: [18.441567620771217, 18.34593025263032, 18.316491853474147, 18.33526667146899, -16.53907654629588, -6.813792850913462], time: 258.832
mmmaddpg vs mmmaddpg steps: 1149975, episodes: 46000, mean episode reward: 49.65401640501263, agent episode reward: [17.820235833880492, 17.76567940194647, 17.746177274331842, 17.749846009999647, -15.482111188982369, -5.945810926163462], time: 262.927
mmmaddpg vs mmmaddpg steps: 1174975, episodes: 47000, mean episode reward: 40.87611812127307, agent episode reward: [14.888314949103693, 14.795740464277138, 14.843999574641918, 14.774017219700669, -12.739392234636314, -5.686561851814031], time: 263.168
mmmaddpg vs mmmaddpg steps: 1199975, episodes: 48000, mean episode reward: 35.772026087893906, agent episode reward: [13.350788331424315, 13.182274518067443, 13.132188779386412, 13.156735766637372, -12.299065960770621, -4.750895346851008], time: 264.264
mmmaddpg vs mmmaddpg steps: 1224975, episodes: 49000, mean episode reward: 34.4664229252769, agent episode reward: [13.024504560812552, 12.826879343152887, 12.754851543086971, 12.740128059024661, -12.878857032029023, -4.001083548771148], time: 263.977
mmmaddpg vs mmmaddpg steps: 1249975, episodes: 50000, mean episode reward: 35.37144344896355, agent episode reward: [13.23046865371642, 12.985951769981508, 12.924473208564343, 12.941977295032705, -13.768220309648042, -2.9432071686833834], time: 265.488
mmmaddpg vs mmmaddpg steps: 1274975, episodes: 51000, mean episode reward: 24.916123241256503, agent episode reward: [10.290770742966927, 10.139015738379578, 10.020271434250528, 9.980653185677712, -12.939255310172436, -2.575332549845804], time: 267.815
mmmaddpg vs mmmaddpg steps: 1299975, episodes: 52000, mean episode reward: 28.894692009516294, agent episode reward: [10.878612673303504, 10.671914247485514, 10.541549771854784, 10.504104963687183, -10.806135310527297, -2.8953543362873906], time: 266.217
mmmaddpg vs mmmaddpg steps: 1324975, episodes: 53000, mean episode reward: 30.74740462357139, agent episode reward: [11.702911907825099, 11.470958699961338, 11.368682287414487, 11.346468266634606, -12.66441677957519, -2.477199758688952], time: 262.468
mmmaddpg vs mmmaddpg steps: 1349975, episodes: 54000, mean episode reward: 37.44814426596727, agent episode reward: [13.942524573471015, 13.738517074249936, 13.712409819395845, 13.641719167662108, -14.383594142632791, -3.2034322261788386], time: 273.133
mmmaddpg vs mmmaddpg steps: 1374975, episodes: 55000, mean episode reward: 39.550128329113384, agent episode reward: [14.55310265738657, 14.369154635859166, 14.417744722556513, 14.311194082768647, -14.745257028457837, -3.355810740999676], time: 273.409
mmmaddpg vs mmmaddpg steps: 1399975, episodes: 56000, mean episode reward: 45.59435417373745, agent episode reward: [16.66240364901984, 16.461357799794683, 16.488229325843623, 16.520012730976674, -17.206727651888478, -3.330921680008905], time: 265.548
mmmaddpg vs mmmaddpg steps: 1424975, episodes: 57000, mean episode reward: 40.527429432726066, agent episode reward: [14.788747282531906, 14.676192182877417, 14.712742946828865, 14.747487356284973, -15.443826910443077, -2.9539134253540205], time: 264.472
mmmaddpg vs mmmaddpg steps: 1449975, episodes: 58000, mean episode reward: 44.08065206244707, agent episode reward: [15.789224707212492, 15.678247813286646, 15.696012743484017, 15.703564290434485, -15.372923719349117, -3.41347377262145], time: 273.611
mmmaddpg vs mmmaddpg steps: 1474975, episodes: 59000, mean episode reward: 46.52283299499091, agent episode reward: [16.413676675311994, 16.247196017187694, 16.316112678085076, 16.3298060015268, -14.779236528163135, -4.00472184895752], time: 267.221
mmmaddpg vs mmmaddpg steps: 1499975, episodes: 60000, mean episode reward: 42.22688221491583, agent episode reward: [15.20571807742833, 15.091513967159393, 15.040262911709126, 15.01440763475422, -13.950743244801119, -4.174277131334124], time: 270.496
mmmaddpg vs mmmaddpg steps: 1524975, episodes: 61000, mean episode reward: 38.520203368872785, agent episode reward: [13.90394115265094, 13.783819640035738, 13.736791843343669, 13.711456976214453, -12.688846608411168, -3.9269596349608444], time: 272.059
mmmaddpg vs mmmaddpg steps: 1549975, episodes: 62000, mean episode reward: 37.062819549679055, agent episode reward: [13.761369352393489, 13.627457604245222, 13.64887963759578, 13.577535059023658, -14.476132758790403, -3.0762893447886936], time: 266.989
mmmaddpg vs mmmaddpg steps: 1574975, episodes: 63000, mean episode reward: 36.50826449071785, agent episode reward: [13.607721103082037, 13.46761742415953, 13.482471239103274, 13.457827754427804, -14.301375767294466, -3.205997262760334], time: 270.321
mmmaddpg vs mmmaddpg steps: 1599975, episodes: 64000, mean episode reward: 33.515626764625814, agent episode reward: [13.089999604577384, 12.934874490922875, 12.95686037040023, 12.972688426007077, -16.028230814954334, -2.410565312327418], time: 269.197
mmmaddpg vs mmmaddpg steps: 1624975, episodes: 65000, mean episode reward: 36.85980726561369, agent episode reward: [13.822068679739504, 13.755794343363702, 13.679692228197837, 13.70494403535615, -15.736375035662721, -2.366316985380785], time: 270.446
mmmaddpg vs mmmaddpg steps: 1649975, episodes: 66000, mean episode reward: 36.93401800965011, agent episode reward: [13.639269458590475, 13.4797402752337, 13.480784660606894, 13.46337995125831, -14.87590892648695, -2.2532474095523125], time: 268.612
mmmaddpg vs mmmaddpg steps: 1674975, episodes: 67000, mean episode reward: 37.75135497708256, agent episode reward: [14.194013167055534, 14.098666422952062, 14.015842323353127, 14.05989301214549, -15.879015620328497, -2.738044328095153], time: 271.735
mmmaddpg vs mmmaddpg steps: 1699975, episodes: 68000, mean episode reward: 37.377874511608745, agent episode reward: [14.008307495022663, 13.89167530333872, 13.837601108373699, 13.815731489783666, -14.633651727974307, -3.541789156935692], time: 271.079
mmmaddpg vs mmmaddpg steps: 1724975, episodes: 69000, mean episode reward: 34.375662385761885, agent episode reward: [12.934969357958995, 12.796766062872138, 12.765239019136216, 12.773074139982937, -13.621688469424035, -3.2726977247643645], time: 272.124
mmmaddpg vs mmmaddpg steps: 1749975, episodes: 70000, mean episode reward: 35.77841777153726, agent episode reward: [13.350875506988515, 13.278295570153983, 13.276302671921684, 13.311968382667445, -14.393084380010286, -3.04593998018408], time: 273.024
mmmaddpg vs mmmaddpg steps: 1774975, episodes: 71000, mean episode reward: 39.56580123097848, agent episode reward: [14.406569139799156, 14.33245325051756, 14.316175033309744, 14.31424570173855, -14.445578364396807, -3.3580635299897215], time: 278.47
mmmaddpg vs mmmaddpg steps: 1799975, episodes: 72000, mean episode reward: 36.90147119989124, agent episode reward: [13.894558180952833, 13.788869539707164, 13.798052451888056, 13.773676894318323, -14.914687728975787, -3.438998137999358], time: 272.207
mmmaddpg vs mmmaddpg steps: 1824975, episodes: 73000, mean episode reward: 36.5808485334135, agent episode reward: [13.576037769188078, 13.517636259684071, 13.524314500649522, 13.472145049069441, -14.38608619232973, -3.123198852847876], time: 268.366
mmmaddpg vs mmmaddpg steps: 1849975, episodes: 74000, mean episode reward: 32.569498547407356, agent episode reward: [12.444947850599288, 12.358629504534962, 12.355431596469327, 12.326063637377796, -14.479336620841414, -2.4362374207326045], time: 266.208
mmmaddpg vs mmmaddpg steps: 1874975, episodes: 75000, mean episode reward: 32.62374983349356, agent episode reward: [12.798159687823041, 12.706863997953066, 12.692543562391165, 12.686950421144061, -14.687984465840625, -3.5727833699771496], time: 273.442
mmmaddpg vs mmmaddpg steps: 1899975, episodes: 76000, mean episode reward: 30.630531493136946, agent episode reward: [12.046300023943939, 11.97053490401588, 12.010814249654013, 11.977310505147615, -13.74476255320594, -3.62966563641856], time: 268.889
mmmaddpg vs mmmaddpg steps: 1924975, episodes: 77000, mean episode reward: 32.676749372570505, agent episode reward: [12.596384907021525, 12.461663263733337, 12.502732353291313, 12.484404199274683, -13.691666587063075, -3.6767687636872783], time: 271.669
mmmaddpg vs mmmaddpg steps: 1949975, episodes: 78000, mean episode reward: 31.52258291077903, agent episode reward: [12.234119348234453, 12.1197780364456, 12.148647760404296, 12.117346749485044, -13.784385163199817, -3.3129238205905467], time: 273.774
mmmaddpg vs mmmaddpg steps: 1974975, episodes: 79000, mean episode reward: 33.33574922524276, agent episode reward: [12.745343419231586, 12.679742788214472, 12.627146303011633, 12.667231791813926, -13.548493030281588, -3.835222046747277], time: 273.473
mmmaddpg vs mmmaddpg steps: 1999975, episodes: 80000, mean episode reward: 29.961997911027225, agent episode reward: [11.860752837846192, 11.783147117989085, 11.777778883897911, 11.757969229392419, -13.582892326242764, -3.63475783185562], time: 270.287
mmmaddpg vs mmmaddpg steps: 2024975, episodes: 81000, mean episode reward: 30.710248330478645, agent episode reward: [12.01578595277392, 11.902605071493051, 11.930146415579399, 11.930180252140895, -13.196177656771408, -3.872291704737215], time: 276.577
mmmaddpg vs mmmaddpg steps: 2049975, episodes: 82000, mean episode reward: 28.621256398839243, agent episode reward: [11.66734305987163, 11.567219533128355, 11.609024205839324, 11.552529457422576, -13.59333352512545, -4.181526332297195], time: 273.097
mmmaddpg vs mmmaddpg steps: 2074975, episodes: 83000, mean episode reward: 30.967309835954747, agent episode reward: [12.298746869664145, 12.164613406206747, 12.189055384979092, 12.188360471045682, -13.158611488585349, -4.714854807355566], time: 270.917
mmmaddpg vs mmmaddpg steps: 2099975, episodes: 84000, mean episode reward: 35.548218113486485, agent episode reward: [13.550815746888777, 13.455596290274219, 13.462314857174515, 13.433353297025674, -13.638832972570746, -4.715029105305948], time: 278.599
mmmaddpg vs mmmaddpg steps: 2124975, episodes: 85000, mean episode reward: 33.667476095456585, agent episode reward: [13.530653044867359, 13.407823602717635, 13.457198214695516, 13.45001893625944, -15.24534092362515, -4.932876779458206], time: 267.363
mmmaddpg vs mmmaddpg steps: 2149975, episodes: 86000, mean episode reward: 37.611152350534375, agent episode reward: [14.338272752103498, 14.227604388930628, 14.236295345222384, 14.265037619290027, -14.899869482941511, -4.55618827207065], time: 275.068
mmmaddpg vs mmmaddpg steps: 2174975, episodes: 87000, mean episode reward: 31.68172829745609, agent episode reward: [12.721049248093676, 12.649422737105244, 12.661636494582682, 12.648537331030061, -14.699182647971739, -4.2997348653838365], time: 270.695
mmmaddpg vs mmmaddpg steps: 2199975, episodes: 88000, mean episode reward: 30.524438164560987, agent episode reward: [12.204063482540837, 12.073583067315136, 12.183337483069101, 12.133133274815307, -13.368701954072664, -4.700977189106734], time: 270.32
mmmaddpg vs mmmaddpg steps: 2224975, episodes: 89000, mean episode reward: 29.18735311308301, agent episode reward: [11.881866166657012, 11.789501927609477, 11.801606404143742, 11.79293276341193, -13.753082014864475, -4.325472133874675], time: 265.293
mmmaddpg vs mmmaddpg steps: 2249975, episodes: 90000, mean episode reward: 31.950171122615394, agent episode reward: [12.574140577054548, 12.404746266405793, 12.486614394201501, 12.478844089747795, -13.832807918625466, -4.1613662861687715], time: 269.382
mmmaddpg vs mmmaddpg steps: 2274975, episodes: 91000, mean episode reward: 32.31748382095231, agent episode reward: [13.02726472884415, 12.880769957394227, 12.931563826644233, 12.947339878634601, -14.2495480247495, -5.219906545815398], time: 273.56
mmmaddpg vs mmmaddpg steps: 2299975, episodes: 92000, mean episode reward: 33.17619268919581, agent episode reward: [12.957561991776831, 12.857462622488297, 12.895831764570916, 12.888900598428426, -14.520026691367091, -3.9035375967015713], time: 267.77
mmmaddpg vs mmmaddpg steps: 2324975, episodes: 93000, mean episode reward: 33.830149302533215, agent episode reward: [13.119623698046812, 12.991794465265667, 13.024494858718477, 12.99680429672909, -14.097805235084953, -4.204762781141875], time: 275.885
mmmaddpg vs mmmaddpg steps: 2349975, episodes: 94000, mean episode reward: 35.728435772582046, agent episode reward: [13.680521636352443, 13.528221133214064, 13.572941498373707, 13.487883328453389, -13.855373092859265, -4.685758730952286], time: 272.817
mmmaddpg vs mmmaddpg steps: 2374975, episodes: 95000, mean episode reward: 35.15985484628982, agent episode reward: [13.828714696237178, 13.685200824396256, 13.715398027771776, 13.7098405980529, -14.889825426261762, -4.889473873906536], time: 269.91
mmmaddpg vs mmmaddpg steps: 2399975, episodes: 96000, mean episode reward: 34.90855077569335, agent episode reward: [13.592856767441098, 13.490881533102549, 13.420283264721213, 13.446355673794383, -14.16626630406242, -4.875560159303475], time: 263.341
mmmaddpg vs mmmaddpg steps: 2424975, episodes: 97000, mean episode reward: 33.62933888013967, agent episode reward: [13.121558044728157, 13.038363631701458, 13.041578788636805, 13.037566039125512, -13.739544738338044, -4.87018288571421], time: 267.571
mmmaddpg vs mmmaddpg steps: 2449975, episodes: 98000, mean episode reward: 34.80873672304911, agent episode reward: [13.379421852817785, 13.270044163168354, 13.27773935952081, 13.291795189508964, -14.205223862451952, -4.2050399795148525], time: 273.604
mmmaddpg vs mmmaddpg steps: 2474975, episodes: 99000, mean episode reward: 34.919752740958806, agent episode reward: [13.594292487205578, 13.489937982078548, 13.526530963699479, 13.48214011226488, -14.087338251997878, -5.0858105522918], time: 269.207
mmmaddpg vs mmmaddpg steps: 2499975, episodes: 100000, mean episode reward: 35.77740913413068, agent episode reward: [14.031085673126142, 13.980662876107857, 13.991690298328333, 13.9266319000658, -14.74574595854425, -5.406915654953205], time: 258.261
...Finished total of 100001 episodes.
