0 bad agents
      adv rate for q_index :  0 [1e-05, 0.001]
      adv rate for p_index :  0 [1e-05, 0.001]
1 good agents
      adv rate for q_index :  1 [0.001, 1e-05]
      adv rate for p_index :  1 [0.001, 1e-05]
Using good policy mmmaddpg and bad policy mmmaddpg with 1 adversaries
Starting iterations...
mmmaddpg vs mmmaddpg steps: 24975, episodes: 1000, mean episode reward: -26.490695321576773, agent episode reward: [0.6605873408890846, -27.151282662465857], time: 63.484
mmmaddpg vs mmmaddpg steps: 49975, episodes: 2000, mean episode reward: -23.957839865510437, agent episode reward: [-7.183535695157786, -16.77430417035265], time: 70.79
mmmaddpg vs mmmaddpg steps: 74975, episodes: 3000, mean episode reward: -11.994164597476232, agent episode reward: [-4.981187796394728, -7.0129768010815035], time: 68.0
mmmaddpg vs mmmaddpg steps: 99975, episodes: 4000, mean episode reward: -10.291718017180814, agent episode reward: [-3.462839429552783, -6.828878587628032], time: 65.202
mmmaddpg vs mmmaddpg steps: 124975, episodes: 5000, mean episode reward: -9.757658537862355, agent episode reward: [-3.115436543887874, -6.64222199397448], time: 60.765
mmmaddpg vs mmmaddpg steps: 149975, episodes: 6000, mean episode reward: -9.31647176934868, agent episode reward: [-2.4792832640647684, -6.837188505283912], time: 58.704
mmmaddpg vs mmmaddpg steps: 174975, episodes: 7000, mean episode reward: -9.017701345381184, agent episode reward: [-2.1393735300876826, -6.878327815293501], time: 78.655
mmmaddpg vs mmmaddpg steps: 199975, episodes: 8000, mean episode reward: -9.018143669951568, agent episode reward: [-2.422132890230627, -6.596010779720941], time: 74.519
mmmaddpg vs mmmaddpg steps: 224975, episodes: 9000, mean episode reward: -8.943435591790502, agent episode reward: [-2.332518045424782, -6.610917546365719], time: 60.385
mmmaddpg vs mmmaddpg steps: 249975, episodes: 10000, mean episode reward: -9.243490145373176, agent episode reward: [-2.423257904012147, -6.820232241361029], time: 44.878
mmmaddpg vs mmmaddpg steps: 274975, episodes: 11000, mean episode reward: -9.293995929690794, agent episode reward: [-2.309513379000149, -6.984482550690646], time: 45.358
mmmaddpg vs mmmaddpg steps: 299975, episodes: 12000, mean episode reward: -9.118534655989134, agent episode reward: [-1.9594354225568937, -7.159099233432241], time: 48.031
mmmaddpg vs mmmaddpg steps: 324975, episodes: 13000, mean episode reward: -9.039136451732398, agent episode reward: [-2.505782639827668, -6.533353811904732], time: 70.634
mmmaddpg vs mmmaddpg steps: 349975, episodes: 14000, mean episode reward: -8.963272708047203, agent episode reward: [-2.0602414530219093, -6.903031255025293], time: 70.069
mmmaddpg vs mmmaddpg steps: 374975, episodes: 15000, mean episode reward: -9.093500326013995, agent episode reward: [-2.4243756746488185, -6.669124651365175], time: 58.772
mmmaddpg vs mmmaddpg steps: 399975, episodes: 16000, mean episode reward: -8.886790054569685, agent episode reward: [-2.14260191389086, -6.744188140678825], time: 47.521
mmmaddpg vs mmmaddpg steps: 424975, episodes: 17000, mean episode reward: -8.967904973561602, agent episode reward: [-2.2405077671885056, -6.727397206373096], time: 45.767
mmmaddpg vs mmmaddpg steps: 449975, episodes: 18000, mean episode reward: -8.900936179462672, agent episode reward: [-2.2241965289250407, -6.6767396505376295], time: 44.731
mmmaddpg vs mmmaddpg steps: 474975, episodes: 19000, mean episode reward: -8.801091907791164, agent episode reward: [-2.0092264376103737, -6.791865470180792], time: 43.569
mmmaddpg vs mmmaddpg steps: 499975, episodes: 20000, mean episode reward: -9.120916764471353, agent episode reward: [-2.4197743181453717, -6.701142446325981], time: 44.048
mmmaddpg vs mmmaddpg steps: 524975, episodes: 21000, mean episode reward: -8.808386904869419, agent episode reward: [-1.9361562350197403, -6.872230669849682], time: 45.381
mmmaddpg vs mmmaddpg steps: 549975, episodes: 22000, mean episode reward: -8.427959779702803, agent episode reward: [-1.5695787144961, -6.858381065206704], time: 46.026
mmmaddpg vs mmmaddpg steps: 574975, episodes: 23000, mean episode reward: -8.739011092916659, agent episode reward: [-1.6550457387831257, -7.0839653541335315], time: 44.379
mmmaddpg vs mmmaddpg steps: 599975, episodes: 24000, mean episode reward: -9.095207854094438, agent episode reward: [-1.9870804961831072, -7.108127357911331], time: 44.474
mmmaddpg vs mmmaddpg steps: 624975, episodes: 25000, mean episode reward: -8.896404272918677, agent episode reward: [-1.592170096074029, -7.304234176844646], time: 44.64
mmmaddpg vs mmmaddpg steps: 649975, episodes: 26000, mean episode reward: -9.119958964333488, agent episode reward: [-1.2785375441452957, -7.84142142018819], time: 44.588
mmmaddpg vs mmmaddpg steps: 674975, episodes: 27000, mean episode reward: -8.849440561135417, agent episode reward: [-0.8191072299530434, -8.030333331182373], time: 45.046
mmmaddpg vs mmmaddpg steps: 699975, episodes: 28000, mean episode reward: -8.814689154898794, agent episode reward: [-0.6845439944528755, -8.130145160445917], time: 44.322
mmmaddpg vs mmmaddpg steps: 724975, episodes: 29000, mean episode reward: -9.065578930896969, agent episode reward: [-1.7219584096766118, -7.343620521220358], time: 44.248
mmmaddpg vs mmmaddpg steps: 749975, episodes: 30000, mean episode reward: -8.76891426078416, agent episode reward: [-2.119337235163048, -6.649577025621111], time: 44.514
mmmaddpg vs mmmaddpg steps: 774975, episodes: 31000, mean episode reward: -8.625457974383059, agent episode reward: [-1.7375663250254676, -6.887891649357591], time: 44.966
mmmaddpg vs mmmaddpg steps: 799975, episodes: 32000, mean episode reward: -8.942769909096155, agent episode reward: [-1.6561817079827785, -7.286588201113377], time: 48.623
mmmaddpg vs mmmaddpg steps: 824975, episodes: 33000, mean episode reward: -9.339919237523398, agent episode reward: [-1.5635839236208886, -7.77633531390251], time: 71.866
mmmaddpg vs mmmaddpg steps: 849975, episodes: 34000, mean episode reward: -8.868087451338747, agent episode reward: [-1.1751998934731966, -7.69288755786555], time: 70.772
mmmaddpg vs mmmaddpg steps: 874975, episodes: 35000, mean episode reward: -8.945033988661715, agent episode reward: [-2.1518100818929926, -6.793223906768723], time: 47.935
mmmaddpg vs mmmaddpg steps: 899975, episodes: 36000, mean episode reward: -8.607702229327302, agent episode reward: [-1.9192599066059166, -6.688442322721385], time: 44.696
mmmaddpg vs mmmaddpg steps: 924975, episodes: 37000, mean episode reward: -8.834574673768534, agent episode reward: [-1.8011716851609294, -7.033402988607605], time: 44.453
mmmaddpg vs mmmaddpg steps: 949975, episodes: 38000, mean episode reward: -9.091548940334636, agent episode reward: [-1.4936835186388087, -7.597865421695826], time: 45.02
mmmaddpg vs mmmaddpg steps: 974975, episodes: 39000, mean episode reward: -8.791006071334802, agent episode reward: [-0.3814336395797413, -8.409572431755063], time: 45.847
mmmaddpg vs mmmaddpg steps: 999975, episodes: 40000, mean episode reward: -8.907156280489069, agent episode reward: [-0.008267402270173705, -8.898888878218894], time: 45.629
mmmaddpg vs mmmaddpg steps: 1024975, episodes: 41000, mean episode reward: -9.182027177057316, agent episode reward: [0.26055507547168244, -9.442582252528998], time: 45.2
mmmaddpg vs mmmaddpg steps: 1049975, episodes: 42000, mean episode reward: -9.409770440955784, agent episode reward: [-0.7482328081619196, -8.661537632793866], time: 45.016
mmmaddpg vs mmmaddpg steps: 1074975, episodes: 43000, mean episode reward: -9.260064422619525, agent episode reward: [-1.1350580751911985, -8.125006347428327], time: 44.973
mmmaddpg vs mmmaddpg steps: 1099975, episodes: 44000, mean episode reward: -8.978396658041948, agent episode reward: [-1.2505262028225732, -7.7278704552193735], time: 46.907
mmmaddpg vs mmmaddpg steps: 1124975, episodes: 45000, mean episode reward: -9.322975935117007, agent episode reward: [-1.3467507208306866, -7.97622521428632], time: 44.634
mmmaddpg vs mmmaddpg steps: 1149975, episodes: 46000, mean episode reward: -9.364869559653743, agent episode reward: [-1.0246580938123457, -8.340211465841397], time: 44.719
mmmaddpg vs mmmaddpg steps: 1174975, episodes: 47000, mean episode reward: -9.337505473547695, agent episode reward: [-1.562050235637142, -7.775455237910555], time: 45.033
mmmaddpg vs mmmaddpg steps: 1199975, episodes: 48000, mean episode reward: -9.293426025930108, agent episode reward: [-2.3320634695828257, -6.961362556347281], time: 45.014
mmmaddpg vs mmmaddpg steps: 1224975, episodes: 49000, mean episode reward: -8.978691059726795, agent episode reward: [-1.9481215447927267, -7.03056951493407], time: 50.263
mmmaddpg vs mmmaddpg steps: 1249975, episodes: 50000, mean episode reward: -8.645171776414529, agent episode reward: [-1.1774503158203948, -7.4677214605941336], time: 55.133
mmmaddpg vs mmmaddpg steps: 1274975, episodes: 51000, mean episode reward: -8.921155696582627, agent episode reward: [-1.4126408624768634, -7.508514834105763], time: 44.847
mmmaddpg vs mmmaddpg steps: 1299975, episodes: 52000, mean episode reward: -8.979665230530289, agent episode reward: [-1.2124405762117234, -7.767224654318564], time: 44.702
mmmaddpg vs mmmaddpg steps: 1324975, episodes: 53000, mean episode reward: -8.943067987388984, agent episode reward: [-0.651105161953357, -8.291962825435629], time: 44.301
mmmaddpg vs mmmaddpg steps: 1349975, episodes: 54000, mean episode reward: -8.714243995807145, agent episode reward: [-0.8794581221487302, -7.834785873658413], time: 45.333
mmmaddpg vs mmmaddpg steps: 1374975, episodes: 55000, mean episode reward: -8.618372735791022, agent episode reward: [-0.9778042127519243, -7.640568523039096], time: 45.257
mmmaddpg vs mmmaddpg steps: 1399975, episodes: 56000, mean episode reward: -8.359708558923606, agent episode reward: [-1.2063510100540766, -7.153357548869527], time: 46.563
mmmaddpg vs mmmaddpg steps: 1424975, episodes: 57000, mean episode reward: -8.453970130821425, agent episode reward: [-1.0706650884833526, -7.383305042338073], time: 45.797
mmmaddpg vs mmmaddpg steps: 1449975, episodes: 58000, mean episode reward: -8.409280735086238, agent episode reward: [-0.7828031805260284, -7.626477554560212], time: 44.098
mmmaddpg vs mmmaddpg steps: 1474975, episodes: 59000, mean episode reward: -8.488927545722305, agent episode reward: [-0.7186426027055925, -7.770284943016712], time: 44.111
mmmaddpg vs mmmaddpg steps: 1499975, episodes: 60000, mean episode reward: -8.518865911938901, agent episode reward: [-0.42659806686946494, -8.092267845069438], time: 44.106
mmmaddpg vs mmmaddpg steps: 1524975, episodes: 61000, mean episode reward: -8.508199804422867, agent episode reward: [-0.8100916491965079, -7.69810815522636], time: 43.851
mmmaddpg vs mmmaddpg steps: 1549975, episodes: 62000, mean episode reward: -8.443442604687407, agent episode reward: [-1.3201645898448182, -7.1232780148425885], time: 45.368
mmmaddpg vs mmmaddpg steps: 1574975, episodes: 63000, mean episode reward: -8.409062758347762, agent episode reward: [-1.4446403721474748, -6.964422386200287], time: 45.694
mmmaddpg vs mmmaddpg steps: 1599975, episodes: 64000, mean episode reward: -8.530812299576313, agent episode reward: [-1.6067925984598774, -6.9240197011164355], time: 45.345
mmmaddpg vs mmmaddpg steps: 1624975, episodes: 65000, mean episode reward: -8.084467055423126, agent episode reward: [-1.513111152526485, -6.571355902896641], time: 46.481
mmmaddpg vs mmmaddpg steps: 1649975, episodes: 66000, mean episode reward: -8.502202839111948, agent episode reward: [-1.7070532880865443, -6.795149551025404], time: 44.853
mmmaddpg vs mmmaddpg steps: 1674975, episodes: 67000, mean episode reward: -8.667604512690957, agent episode reward: [-1.8731425808601658, -6.794461931830792], time: 45.031
mmmaddpg vs mmmaddpg steps: 1699975, episodes: 68000, mean episode reward: -8.566149067963345, agent episode reward: [-1.5184894027167084, -7.047659665246636], time: 44.653
mmmaddpg vs mmmaddpg steps: 1724975, episodes: 69000, mean episode reward: -8.59588072227229, agent episode reward: [-1.5641458830921178, -7.0317348391801735], time: 45.02
mmmaddpg vs mmmaddpg steps: 1749975, episodes: 70000, mean episode reward: -8.800359544917116, agent episode reward: [-1.9858489742104768, -6.814510570706639], time: 46.766
mmmaddpg vs mmmaddpg steps: 1774975, episodes: 71000, mean episode reward: -8.677366499177216, agent episode reward: [-2.0407673959592674, -6.63659910321795], time: 44.24
mmmaddpg vs mmmaddpg steps: 1799975, episodes: 72000, mean episode reward: -8.31131268901543, agent episode reward: [-1.5372664453878575, -6.774046243627575], time: 44.647
mmmaddpg vs mmmaddpg steps: 1824975, episodes: 73000, mean episode reward: -8.786111075964957, agent episode reward: [-1.286591463007931, -7.499519612957025], time: 45.466
mmmaddpg vs mmmaddpg steps: 1849975, episodes: 74000, mean episode reward: -8.455564155981152, agent episode reward: [-1.1438788120115524, -7.311685343969598], time: 44.563
mmmaddpg vs mmmaddpg steps: 1874975, episodes: 75000, mean episode reward: -8.698675374915016, agent episode reward: [-1.236660746997006, -7.462014627918009], time: 44.612
mmmaddpg vs mmmaddpg steps: 1899975, episodes: 76000, mean episode reward: -8.677665169362973, agent episode reward: [-1.6887463560783658, -6.988918813284606], time: 45.09
mmmaddpg vs mmmaddpg steps: 1924975, episodes: 77000, mean episode reward: -8.43110077984369, agent episode reward: [-1.7127019352499684, -6.718398844593722], time: 43.91
mmmaddpg vs mmmaddpg steps: 1949975, episodes: 78000, mean episode reward: -8.430030605080315, agent episode reward: [-1.5108450777353128, -6.919185527345004], time: 44.435
mmmaddpg vs mmmaddpg steps: 1974975, episodes: 79000, mean episode reward: -8.373991113829783, agent episode reward: [-2.02178088557991, -6.3522102282498745], time: 44.664
mmmaddpg vs mmmaddpg steps: 1999975, episodes: 80000, mean episode reward: -8.505737724642804, agent episode reward: [-1.5307348956650821, -6.97500282897772], time: 44.632
mmmaddpg vs mmmaddpg steps: 2024975, episodes: 81000, mean episode reward: -8.43870759580502, agent episode reward: [-1.837830190777578, -6.600877405027442], time: 44.179
mmmaddpg vs mmmaddpg steps: 2049975, episodes: 82000, mean episode reward: -8.491895911805376, agent episode reward: [-1.5859203009729599, -6.905975610832416], time: 69.166
mmmaddpg vs mmmaddpg steps: 2074975, episodes: 83000, mean episode reward: -8.61766593752173, agent episode reward: [-1.2386777440399601, -7.37898819348177], time: 60.546
mmmaddpg vs mmmaddpg steps: 2099975, episodes: 84000, mean episode reward: -8.28469670118504, agent episode reward: [-1.327449639602513, -6.957247061582527], time: 44.445
mmmaddpg vs mmmaddpg steps: 2124975, episodes: 85000, mean episode reward: -8.678010578644077, agent episode reward: [-1.7140509796522314, -6.963959598991844], time: 44.475
mmmaddpg vs mmmaddpg steps: 2149975, episodes: 86000, mean episode reward: -8.64066231056911, agent episode reward: [-2.120788910032599, -6.519873400536512], time: 45.084
mmmaddpg vs mmmaddpg steps: 2174975, episodes: 87000, mean episode reward: -8.713710123038233, agent episode reward: [-2.1201232804985386, -6.593586842539695], time: 44.867
mmmaddpg vs mmmaddpg steps: 2199975, episodes: 88000, mean episode reward: -8.267826652940583, agent episode reward: [-1.44741915670913, -6.820407496231454], time: 45.051
mmmaddpg vs mmmaddpg steps: 2224975, episodes: 89000, mean episode reward: -8.219097940127046, agent episode reward: [-1.0622661965029658, -7.15683174362408], time: 49.374
mmmaddpg vs mmmaddpg steps: 2249975, episodes: 90000, mean episode reward: -8.528456807779145, agent episode reward: [-1.002084828273674, -7.5263719795054715], time: 70.951
mmmaddpg vs mmmaddpg steps: 2274975, episodes: 91000, mean episode reward: -8.776180492346967, agent episode reward: [-1.1500455530509226, -7.626134939296044], time: 66.753
mmmaddpg vs mmmaddpg steps: 2299975, episodes: 92000, mean episode reward: -8.779266638786138, agent episode reward: [-1.3949892931502714, -7.3842773456358675], time: 47.135
mmmaddpg vs mmmaddpg steps: 2324975, episodes: 93000, mean episode reward: -9.051096450872755, agent episode reward: [-1.8610158733187727, -7.190080577553983], time: 44.546
mmmaddpg vs mmmaddpg steps: 2349975, episodes: 94000, mean episode reward: -8.73905746741045, agent episode reward: [-1.5522032659791913, -7.186854201431259], time: 44.381
mmmaddpg vs mmmaddpg steps: 2374975, episodes: 95000, mean episode reward: -8.52273043917628, agent episode reward: [-1.37790178182398, -7.144828657352302], time: 44.535
mmmaddpg vs mmmaddpg steps: 2399975, episodes: 96000, mean episode reward: -8.83653291799708, agent episode reward: [-1.8275317561160578, -7.00900116188102], time: 44.444
mmmaddpg vs mmmaddpg steps: 2424975, episodes: 97000, mean episode reward: -8.69590337421321, agent episode reward: [-1.866772708262376, -6.829130665950833], time: 45.303
mmmaddpg vs mmmaddpg steps: 2449975, episodes: 98000, mean episode reward: -8.395556604586421, agent episode reward: [-1.6760021605626385, -6.7195544440237835], time: 46.84
mmmaddpg vs mmmaddpg steps: 2474975, episodes: 99000, mean episode reward: -8.845347291649931, agent episode reward: [-1.4641449928739714, -7.381202298775958], time: 78.276
mmmaddpg vs mmmaddpg steps: 2499975, episodes: 100000, mean episode reward: -8.82405378529074, agent episode reward: [-1.4915526202471132, -7.332501165043626], time: 83.296
...Finished total of 100001 episodes.
