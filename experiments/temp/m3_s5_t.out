0 bad agents
      adv rate for q_index :  0 [1e-05, 0.001]
      adv rate for p_index :  0 [1e-05, 0.001]
1 good agents
      adv rate for q_index :  1 [0.001, 1e-05]
      adv rate for p_index :  1 [0.001, 1e-05]
Using good policy mmmaddpg and bad policy mmmaddpg with 1 adversaries
Starting iterations...
mmmaddpg vs mmmaddpg steps: 24975, episodes: 1000, mean episode reward: -26.63469029283713, agent episode reward: [1.1124063442146437, -27.747096637051776], time: 38.201
mmmaddpg vs mmmaddpg steps: 49975, episodes: 2000, mean episode reward: -23.66189420759993, agent episode reward: [-1.9113359010257491, -21.750558306574174], time: 45.95
mmmaddpg vs mmmaddpg steps: 74975, episodes: 3000, mean episode reward: -10.988903445252472, agent episode reward: [-4.132272273278726, -6.856631171973746], time: 45.862
mmmaddpg vs mmmaddpg steps: 99975, episodes: 4000, mean episode reward: -9.354430404784976, agent episode reward: [-2.4886638015003, -6.865766603284675], time: 45.694
mmmaddpg vs mmmaddpg steps: 124975, episodes: 5000, mean episode reward: -9.1333179480205, agent episode reward: [-2.387350887240383, -6.745967060780116], time: 46.144
mmmaddpg vs mmmaddpg steps: 149975, episodes: 6000, mean episode reward: -9.13720714061656, agent episode reward: [-2.416428250235904, -6.7207788903806565], time: 46.388
mmmaddpg vs mmmaddpg steps: 174975, episodes: 7000, mean episode reward: -8.966033914063441, agent episode reward: [-2.511696462326412, -6.454337451737029], time: 46.793
mmmaddpg vs mmmaddpg steps: 199975, episodes: 8000, mean episode reward: -9.12876746618508, agent episode reward: [-2.6002695340436492, -6.528497932141429], time: 47.182
mmmaddpg vs mmmaddpg steps: 224975, episodes: 9000, mean episode reward: -9.084786108984249, agent episode reward: [-2.4469316544379214, -6.637854454546327], time: 47.233
mmmaddpg vs mmmaddpg steps: 249975, episodes: 10000, mean episode reward: -9.014311952383348, agent episode reward: [-2.3322857510679116, -6.682026201315437], time: 47.44
mmmaddpg vs mmmaddpg steps: 274975, episodes: 11000, mean episode reward: -8.879797302521093, agent episode reward: [-2.3040794404830303, -6.575717862038063], time: 47.379
mmmaddpg vs mmmaddpg steps: 299975, episodes: 12000, mean episode reward: -9.07056987962053, agent episode reward: [-2.251663832449226, -6.818906047171304], time: 47.796
mmmaddpg vs mmmaddpg steps: 324975, episodes: 13000, mean episode reward: -9.125263686345356, agent episode reward: [-2.4174708600096704, -6.7077928263356865], time: 47.239
mmmaddpg vs mmmaddpg steps: 349975, episodes: 14000, mean episode reward: -8.881172545219313, agent episode reward: [-2.0209162081383782, -6.860256337080935], time: 47.023
mmmaddpg vs mmmaddpg steps: 374975, episodes: 15000, mean episode reward: -8.870053303970536, agent episode reward: [-1.898375249782244, -6.971678054188293], time: 47.429
mmmaddpg vs mmmaddpg steps: 399975, episodes: 16000, mean episode reward: -8.746306072287625, agent episode reward: [-2.060856598793302, -6.685449473494322], time: 47.404
mmmaddpg vs mmmaddpg steps: 424975, episodes: 17000, mean episode reward: -8.596640869435422, agent episode reward: [-1.8983578835252704, -6.698282985910152], time: 46.46
mmmaddpg vs mmmaddpg steps: 449975, episodes: 18000, mean episode reward: -9.21227068946688, agent episode reward: [-2.294518578763843, -6.917752110703039], time: 46.747
mmmaddpg vs mmmaddpg steps: 474975, episodes: 19000, mean episode reward: -8.793311722492307, agent episode reward: [-2.033280380496732, -6.760031341995573], time: 46.912
mmmaddpg vs mmmaddpg steps: 499975, episodes: 20000, mean episode reward: -8.791727796436586, agent episode reward: [-1.946742367847281, -6.844985428589305], time: 46.974
mmmaddpg vs mmmaddpg steps: 524975, episodes: 21000, mean episode reward: -8.527212472796796, agent episode reward: [-1.859760070071377, -6.667452402725419], time: 47.094
mmmaddpg vs mmmaddpg steps: 549975, episodes: 22000, mean episode reward: -8.848180011632483, agent episode reward: [-2.1109289314737603, -6.737251080158723], time: 47.439
mmmaddpg vs mmmaddpg steps: 574975, episodes: 23000, mean episode reward: -8.551722791066041, agent episode reward: [-1.7137878286298334, -6.837934962436206], time: 47.249
mmmaddpg vs mmmaddpg steps: 599975, episodes: 24000, mean episode reward: -8.600238243092601, agent episode reward: [-1.6178162574754835, -6.982421985617116], time: 47.094
mmmaddpg vs mmmaddpg steps: 624975, episodes: 25000, mean episode reward: -8.950356703119157, agent episode reward: [-1.6763488776745816, -7.274007825444574], time: 47.231
mmmaddpg vs mmmaddpg steps: 649975, episodes: 26000, mean episode reward: -8.796931382311216, agent episode reward: [-1.640150367211771, -7.156781015099445], time: 47.298
mmmaddpg vs mmmaddpg steps: 674975, episodes: 27000, mean episode reward: -8.577654528277629, agent episode reward: [-1.3382158719832808, -7.239438656294347], time: 47.137
mmmaddpg vs mmmaddpg steps: 699975, episodes: 28000, mean episode reward: -8.654836216541645, agent episode reward: [-1.0511764690919447, -7.6036597474497], time: 47.546
mmmaddpg vs mmmaddpg steps: 724975, episodes: 29000, mean episode reward: -8.944977248156045, agent episode reward: [-1.4785040992694773, -7.466473148886568], time: 47.43
mmmaddpg vs mmmaddpg steps: 749975, episodes: 30000, mean episode reward: -8.974815290873055, agent episode reward: [-1.9217237652354209, -7.053091525637633], time: 47.029
mmmaddpg vs mmmaddpg steps: 774975, episodes: 31000, mean episode reward: -8.615835550741828, agent episode reward: [-1.6040030896514537, -7.011832461090373], time: 47.468
mmmaddpg vs mmmaddpg steps: 799975, episodes: 32000, mean episode reward: -8.811900826443289, agent episode reward: [-1.5970177060785657, -7.21488312036472], time: 46.902
mmmaddpg vs mmmaddpg steps: 824975, episodes: 33000, mean episode reward: -8.957226304251616, agent episode reward: [-1.9161891121201569, -7.04103719213146], time: 47.559
mmmaddpg vs mmmaddpg steps: 849975, episodes: 34000, mean episode reward: -9.017075450309942, agent episode reward: [-2.1340287794149853, -6.883046670894955], time: 46.956
mmmaddpg vs mmmaddpg steps: 874975, episodes: 35000, mean episode reward: -8.960514314861655, agent episode reward: [-2.297901428365068, -6.6626128864965874], time: 46.745
mmmaddpg vs mmmaddpg steps: 899975, episodes: 36000, mean episode reward: -9.32094134677751, agent episode reward: [-2.703583475437846, -6.617357871339663], time: 47.515
mmmaddpg vs mmmaddpg steps: 924975, episodes: 37000, mean episode reward: -8.983695743493763, agent episode reward: [-2.291581837187101, -6.692113906306662], time: 46.888
mmmaddpg vs mmmaddpg steps: 949975, episodes: 38000, mean episode reward: -9.12751582521699, agent episode reward: [-2.3172894531223744, -6.810226372094616], time: 47.385
mmmaddpg vs mmmaddpg steps: 974975, episodes: 39000, mean episode reward: -9.036032653547723, agent episode reward: [-2.0189914673892098, -7.017041186158513], time: 46.946
mmmaddpg vs mmmaddpg steps: 999975, episodes: 40000, mean episode reward: -8.972712520161267, agent episode reward: [-2.0284837608636663, -6.944228759297599], time: 47.25
mmmaddpg vs mmmaddpg steps: 1024975, episodes: 41000, mean episode reward: -8.969907303943216, agent episode reward: [-2.0742697882615055, -6.895637515681712], time: 47.446
mmmaddpg vs mmmaddpg steps: 1049975, episodes: 42000, mean episode reward: -8.660963781930453, agent episode reward: [-2.1207284686473034, -6.5402353132831506], time: 47.213
mmmaddpg vs mmmaddpg steps: 1074975, episodes: 43000, mean episode reward: -8.868076397313853, agent episode reward: [-1.8733018969107451, -6.994774500403108], time: 47.263
mmmaddpg vs mmmaddpg steps: 1099975, episodes: 44000, mean episode reward: -8.830119113897814, agent episode reward: [-1.9073960712735685, -6.922723042624246], time: 47.942
mmmaddpg vs mmmaddpg steps: 1124975, episodes: 45000, mean episode reward: -8.740885646751117, agent episode reward: [-1.3826275351599677, -7.35825811159115], time: 47.973
mmmaddpg vs mmmaddpg steps: 1149975, episodes: 46000, mean episode reward: -8.780306813100458, agent episode reward: [-1.5780887433487654, -7.202218069751693], time: 47.759
mmmaddpg vs mmmaddpg steps: 1174975, episodes: 47000, mean episode reward: -8.673790678468112, agent episode reward: [-1.096294453007898, -7.577496225460216], time: 47.507
mmmaddpg vs mmmaddpg steps: 1199975, episodes: 48000, mean episode reward: -8.783248940127317, agent episode reward: [-1.0294966786996347, -7.753752261427683], time: 47.213
mmmaddpg vs mmmaddpg steps: 1224975, episodes: 49000, mean episode reward: -8.988546778610132, agent episode reward: [-1.0179760582418043, -7.97057072036833], time: 47.068
mmmaddpg vs mmmaddpg steps: 1249975, episodes: 50000, mean episode reward: -9.10594999893468, agent episode reward: [-0.9011035210425592, -8.204846477892122], time: 47.709
mmmaddpg vs mmmaddpg steps: 1274975, episodes: 51000, mean episode reward: -8.696428895907836, agent episode reward: [-0.02581613612724272, -8.670612759780598], time: 47.008
mmmaddpg vs mmmaddpg steps: 1299975, episodes: 52000, mean episode reward: -8.852479522070869, agent episode reward: [-0.13926272511854496, -8.713216796952322], time: 46.501
mmmaddpg vs mmmaddpg steps: 1324975, episodes: 53000, mean episode reward: -8.620362110768337, agent episode reward: [0.16010890144313664, -8.780471012211473], time: 46.825
mmmaddpg vs mmmaddpg steps: 1349975, episodes: 54000, mean episode reward: -8.780150862060351, agent episode reward: [-0.4216266053145812, -8.358524256745769], time: 47.082
mmmaddpg vs mmmaddpg steps: 1374975, episodes: 55000, mean episode reward: -8.705272999517712, agent episode reward: [-0.42171572593705603, -8.283557273580657], time: 46.321
mmmaddpg vs mmmaddpg steps: 1399975, episodes: 56000, mean episode reward: -8.687678249011514, agent episode reward: [-0.5301828969037029, -8.15749535210781], time: 47.27
mmmaddpg vs mmmaddpg steps: 1424975, episodes: 57000, mean episode reward: -8.921879847997328, agent episode reward: [-0.7425504545488449, -8.179329393448484], time: 46.734
mmmaddpg vs mmmaddpg steps: 1449975, episodes: 58000, mean episode reward: -8.750780021384987, agent episode reward: [-0.07856957423480534, -8.672210447150182], time: 46.375
mmmaddpg vs mmmaddpg steps: 1474975, episodes: 59000, mean episode reward: -8.762468518284946, agent episode reward: [-0.08268914044424548, -8.679779377840699], time: 46.41
mmmaddpg vs mmmaddpg steps: 1499975, episodes: 60000, mean episode reward: -9.183284619227274, agent episode reward: [-0.986808711639267, -8.196475907588004], time: 46.688
mmmaddpg vs mmmaddpg steps: 1524975, episodes: 61000, mean episode reward: -9.113099626541745, agent episode reward: [-0.5822222205246623, -8.530877406017083], time: 46.56
mmmaddpg vs mmmaddpg steps: 1549975, episodes: 62000, mean episode reward: -9.019604123966841, agent episode reward: [-0.4795159771769504, -8.540088146789891], time: 46.218
mmmaddpg vs mmmaddpg steps: 1574975, episodes: 63000, mean episode reward: -9.065346963887004, agent episode reward: [0.03772252664752361, -9.103069490534528], time: 45.921
mmmaddpg vs mmmaddpg steps: 1599975, episodes: 64000, mean episode reward: -8.778928534072245, agent episode reward: [-0.22269645845898986, -8.556232075613256], time: 45.491
mmmaddpg vs mmmaddpg steps: 1624975, episodes: 65000, mean episode reward: -9.108185807264494, agent episode reward: [-0.24209795659374317, -8.866087850670748], time: 44.959
mmmaddpg vs mmmaddpg steps: 1649975, episodes: 66000, mean episode reward: -9.525590906138895, agent episode reward: [-0.4985017718848328, -9.02708913425406], time: 44.879
mmmaddpg vs mmmaddpg steps: 1674975, episodes: 67000, mean episode reward: -8.999045738339461, agent episode reward: [-0.016940501547766884, -8.982105236791693], time: 45.499
mmmaddpg vs mmmaddpg steps: 1699975, episodes: 68000, mean episode reward: -8.880115693448007, agent episode reward: [0.21680103571083476, -9.09691672915884], time: 46.049
mmmaddpg vs mmmaddpg steps: 1724975, episodes: 69000, mean episode reward: -9.055934310572011, agent episode reward: [0.3416472833913524, -9.397581593963363], time: 46.57
mmmaddpg vs mmmaddpg steps: 1749975, episodes: 70000, mean episode reward: -8.750275734910291, agent episode reward: [0.5230415715156075, -9.273317306425895], time: 45.711
mmmaddpg vs mmmaddpg steps: 1774975, episodes: 71000, mean episode reward: -8.643781969996194, agent episode reward: [-0.09880939245201861, -8.544972577544177], time: 40.992
mmmaddpg vs mmmaddpg steps: 1799975, episodes: 72000, mean episode reward: -8.37009414623815, agent episode reward: [-0.49722177803858564, -7.872872368199563], time: 40.876
mmmaddpg vs mmmaddpg steps: 1824975, episodes: 73000, mean episode reward: -8.282458179924367, agent episode reward: [-0.644526132641822, -7.637932047282546], time: 40.719
mmmaddpg vs mmmaddpg steps: 1849975, episodes: 74000, mean episode reward: -8.670524878827138, agent episode reward: [-0.795965917488287, -7.8745589613388525], time: 40.555
mmmaddpg vs mmmaddpg steps: 1874975, episodes: 75000, mean episode reward: -8.771691714142612, agent episode reward: [-1.0111965933981752, -7.7604951207444355], time: 40.978
mmmaddpg vs mmmaddpg steps: 1899975, episodes: 76000, mean episode reward: -8.694348605215374, agent episode reward: [-1.4306367727662628, -7.263711832449113], time: 41.16
mmmaddpg vs mmmaddpg steps: 1924975, episodes: 77000, mean episode reward: -8.857829248037183, agent episode reward: [-1.3289758781035865, -7.528853369933595], time: 40.668
mmmaddpg vs mmmaddpg steps: 1949975, episodes: 78000, mean episode reward: -8.39445475786656, agent episode reward: [-0.40208470114067996, -7.992370056725881], time: 40.882
mmmaddpg vs mmmaddpg steps: 1974975, episodes: 79000, mean episode reward: -8.352486400738456, agent episode reward: [-0.19087117597485662, -8.161615224763601], time: 40.186
mmmaddpg vs mmmaddpg steps: 1999975, episodes: 80000, mean episode reward: -8.571074680364182, agent episode reward: [-0.2307141715841909, -8.340360508779987], time: 40.332
mmmaddpg vs mmmaddpg steps: 2024975, episodes: 81000, mean episode reward: -9.407793279470548, agent episode reward: [0.7623109835532044, -10.170104263023752], time: 40.573
mmmaddpg vs mmmaddpg steps: 2049975, episodes: 82000, mean episode reward: -9.102265996459893, agent episode reward: [0.8383090071605279, -9.94057500362042], time: 40.531
mmmaddpg vs mmmaddpg steps: 2074975, episodes: 83000, mean episode reward: -9.0432774635977, agent episode reward: [1.1909686770866241, -10.234246140684325], time: 40.59
mmmaddpg vs mmmaddpg steps: 2099975, episodes: 84000, mean episode reward: -8.913259942009313, agent episode reward: [1.6630936857562908, -10.576353627765604], time: 40.614
mmmaddpg vs mmmaddpg steps: 2124975, episodes: 85000, mean episode reward: -8.669117266006564, agent episode reward: [0.9520577001235595, -9.621174966130122], time: 40.321
mmmaddpg vs mmmaddpg steps: 2149975, episodes: 86000, mean episode reward: -8.699883347665553, agent episode reward: [-0.25669363157080627, -8.443189716094748], time: 40.9
mmmaddpg vs mmmaddpg steps: 2174975, episodes: 87000, mean episode reward: -8.858975254813306, agent episode reward: [0.2551591181221808, -9.114134372935485], time: 40.232
mmmaddpg vs mmmaddpg steps: 2199975, episodes: 88000, mean episode reward: -8.636969159689782, agent episode reward: [0.5245286000944744, -9.161497759784258], time: 40.395
mmmaddpg vs mmmaddpg steps: 2224975, episodes: 89000, mean episode reward: -8.726493805200828, agent episode reward: [-0.28349150028612297, -8.443002304914703], time: 40.902
mmmaddpg vs mmmaddpg steps: 2249975, episodes: 90000, mean episode reward: -8.528447321860492, agent episode reward: [-0.8580343281478767, -7.670412993712614], time: 42.911
mmmaddpg vs mmmaddpg steps: 2274975, episodes: 91000, mean episode reward: -8.707838338592603, agent episode reward: [-1.6501646059971427, -7.05767373259546], time: 42.597
mmmaddpg vs mmmaddpg steps: 2299975, episodes: 92000, mean episode reward: -8.603231318542093, agent episode reward: [-1.8537847623671901, -6.749446556174902], time: 42.927
mmmaddpg vs mmmaddpg steps: 2324975, episodes: 93000, mean episode reward: -8.439266992274705, agent episode reward: [-1.3527321286893594, -7.086534863585346], time: 42.232
mmmaddpg vs mmmaddpg steps: 2349975, episodes: 94000, mean episode reward: -8.596559272476336, agent episode reward: [-0.8375811800163271, -7.7589780924600085], time: 42.151
mmmaddpg vs mmmaddpg steps: 2374975, episodes: 95000, mean episode reward: -8.443980883511955, agent episode reward: [-0.3291406279938405, -8.114840255518114], time: 40.974
mmmaddpg vs mmmaddpg steps: 2399975, episodes: 96000, mean episode reward: -8.912382387779171, agent episode reward: [-0.3669066328845881, -8.545475754894584], time: 40.88
mmmaddpg vs mmmaddpg steps: 2424975, episodes: 97000, mean episode reward: -8.978475758985365, agent episode reward: [-0.06672946368370507, -8.911746295301658], time: 40.741
mmmaddpg vs mmmaddpg steps: 2449975, episodes: 98000, mean episode reward: -8.387658727615937, agent episode reward: [1.1528607243960172, -9.540519452011955], time: 40.854
mmmaddpg vs mmmaddpg steps: 2474975, episodes: 99000, mean episode reward: -8.73611084370072, agent episode reward: [0.9091992353393437, -9.645310079040062], time: 40.704
mmmaddpg vs mmmaddpg steps: 2499975, episodes: 100000, mean episode reward: -8.835590047380927, agent episode reward: [0.5681073308527854, -9.403697378233712], time: 40.525
...Finished total of 100001 episodes.
