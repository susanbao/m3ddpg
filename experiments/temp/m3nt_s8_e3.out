0 bad agents
      adv rate for q_index :  0 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
      adv rate for p_index :  0 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
1 bad agents
      adv rate for q_index :  1 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
      adv rate for p_index :  1 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
2 bad agents
      adv rate for q_index :  2 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
      adv rate for p_index :  2 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
3 bad agents
      adv rate for q_index :  3 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
      adv rate for p_index :  3 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
4 good agents
      adv rate for q_index :  4 [0.001, 0.001, 0.001, 0.001, 1e-05, 1e-05]
      adv rate for p_index :  4 [0.001, 0.001, 0.001, 0.001, 1e-05, 1e-05]
5 good agents
      adv rate for q_index :  5 [0.001, 0.001, 0.001, 0.001, 1e-05, 1e-05]
      adv rate for p_index :  5 [0.001, 0.001, 0.001, 0.001, 1e-05, 1e-05]
Using good policy mmmaddpg and bad policy mmmaddpg with 4 adversaries
Starting iterations...
mmmaddpg vs mmmaddpg steps: 24975, episodes: 1000, mean episode reward: -26.744057271359996, agent episode reward: [1.1147668900532866, 1.102671957123483, 1.202888253714416, 1.093030065686153, -12.870385030050802, -18.387029407886534], time: 150.527
mmmaddpg vs mmmaddpg steps: 49975, episodes: 2000, mean episode reward: -25.722087283495206, agent episode reward: [2.698626851982025, 2.3423904149075, 2.6190921514757872, 2.2677294060822812, -18.303922989715613, -17.34600311822719], time: 248.804
mmmaddpg vs mmmaddpg steps: 74975, episodes: 3000, mean episode reward: 13.76655926168264, agent episode reward: [5.068484143881093, 4.2909942771313965, 4.346397465740842, 4.776015025582541, -2.2374936364863838, -2.4778380141668466], time: 250.451
mmmaddpg vs mmmaddpg steps: 99975, episodes: 4000, mean episode reward: 18.14880813100252, agent episode reward: [6.443921981726826, 5.572401877057062, 5.763123230445237, 6.042687575653619, -2.5576106800515364, -3.1157158538286858], time: 252.289
mmmaddpg vs mmmaddpg steps: 124975, episodes: 5000, mean episode reward: 26.386198190710562, agent episode reward: [8.961356459175445, 8.501491653345195, 8.669805402903734, 8.303362109286217, -3.9685011257588614, -4.081316308241164], time: 255.497
mmmaddpg vs mmmaddpg steps: 149975, episodes: 6000, mean episode reward: 32.78852208821459, agent episode reward: [10.958943664795225, 10.528190499183198, 10.667572158188523, 10.366298061736444, -4.556928862898178, -5.175553432790616], time: 254.733
mmmaddpg vs mmmaddpg steps: 174975, episodes: 7000, mean episode reward: 40.54628721667032, agent episode reward: [13.623199007179512, 13.151697448866736, 13.205788660852049, 13.111756831548421, -5.683295620294584, -6.862859111481809], time: 256.814
mmmaddpg vs mmmaddpg steps: 199975, episodes: 8000, mean episode reward: 45.96081750960217, agent episode reward: [15.522618223970836, 15.312150597813739, 15.235788829684887, 14.95481341314503, -7.17821510980609, -7.886338445206231], time: 255.592
mmmaddpg vs mmmaddpg steps: 224975, episodes: 9000, mean episode reward: 50.30456802316261, agent episode reward: [16.77509883733827, 16.600743687868047, 16.599756872517908, 16.136282088373616, -6.6577414831538, -9.149571979781426], time: 256.411
mmmaddpg vs mmmaddpg steps: 249975, episodes: 10000, mean episode reward: 43.79537809098149, agent episode reward: [14.624236592340344, 14.427097024073316, 14.345809263814743, 14.155267034668556, -4.202181534709265, -9.554850289206204], time: 255.078
mmmaddpg vs mmmaddpg steps: 274975, episodes: 11000, mean episode reward: 41.92383308457557, agent episode reward: [13.961746950477455, 13.716207839391613, 13.781594350971213, 13.534666319577779, -4.47588162286843, -8.594500752974058], time: 260.864
mmmaddpg vs mmmaddpg steps: 299975, episodes: 12000, mean episode reward: 28.858024521209025, agent episode reward: [9.96137229335594, 9.794778367315528, 9.885212533541095, 9.680966833355443, -4.38357199503173, -6.0807335113272565], time: 260.176
mmmaddpg vs mmmaddpg steps: 324975, episodes: 13000, mean episode reward: 27.974799574472076, agent episode reward: [9.869360140129292, 9.84181961517041, 9.839910011052762, 9.511306534452496, -5.2179045407472096, -5.8696921855856745], time: 260.536
mmmaddpg vs mmmaddpg steps: 349975, episodes: 14000, mean episode reward: 22.037520588810576, agent episode reward: [7.988740246242579, 7.976394301775757, 7.810849083272167, 7.709129131013849, -4.8329756424703225, -4.614616531023455], time: 253.694
mmmaddpg vs mmmaddpg steps: 374975, episodes: 15000, mean episode reward: 19.44190936952046, agent episode reward: [7.497564608885289, 7.437634808578238, 7.282490261983887, 7.320016756925752, -4.8501120566784035, -5.245685010174304], time: 260.16
mmmaddpg vs mmmaddpg steps: 399975, episodes: 16000, mean episode reward: 15.085527117339709, agent episode reward: [6.3247612533201, 6.310231813100118, 6.136445735069409, 6.263104624608293, -4.4420164630517505, -5.50699984570646], time: 258.698
mmmaddpg vs mmmaddpg steps: 424975, episodes: 17000, mean episode reward: 9.864180549840643, agent episode reward: [4.863517497682187, 4.7815554899578165, 4.712845517302149, 4.753937353239047, -3.950490576888654, -5.297184731451903], time: 254.021
mmmaddpg vs mmmaddpg steps: 449975, episodes: 18000, mean episode reward: 7.407376554809571, agent episode reward: [4.5335007183950005, 4.485751038200986, 4.394144433905138, 4.428519565335266, -4.357253521626308, -6.077285679400511], time: 257.604
mmmaddpg vs mmmaddpg steps: 474975, episodes: 19000, mean episode reward: 12.89315822107045, agent episode reward: [5.798897860486612, 5.703021798138065, 5.590782707783657, 5.63355283130873, -4.545658382142256, -5.287438594504358], time: 257.763
mmmaddpg vs mmmaddpg steps: 499975, episodes: 20000, mean episode reward: 11.777420843635856, agent episode reward: [5.08476750422976, 5.015785633195195, 4.944031975001693, 4.958753746693532, -3.7905456662797707, -4.435372349204555], time: 258.913
mmmaddpg vs mmmaddpg steps: 524975, episodes: 21000, mean episode reward: 19.713262488016895, agent episode reward: [7.668321113108837, 7.5386290879215005, 7.538425226836342, 7.472953219655979, -5.37956745618038, -5.125498703325382], time: 260.017
mmmaddpg vs mmmaddpg steps: 549975, episodes: 22000, mean episode reward: 21.188876601579548, agent episode reward: [8.027882186889784, 7.945785086948348, 7.9619223441662, 7.883462978142762, -5.071649679105854, -5.55852631546169], time: 265.298
mmmaddpg vs mmmaddpg steps: 574975, episodes: 23000, mean episode reward: 19.979751200241516, agent episode reward: [7.539402163663439, 7.401851446142866, 7.441948587183003, 7.350807353753887, -5.213774407103157, -4.540483943398522], time: 264.7
mmmaddpg vs mmmaddpg steps: 599975, episodes: 24000, mean episode reward: 18.499041131920375, agent episode reward: [7.170396429224537, 6.895769145365125, 7.099903661035579, 6.936302340331033, -4.913073577518866, -4.690256866517035], time: 261.984
mmmaddpg vs mmmaddpg steps: 624975, episodes: 25000, mean episode reward: 20.144795348654736, agent episode reward: [7.791940034653373, 7.470940460360239, 7.61974710629047, 7.464688503779477, -5.397174231138078, -4.805346525290744], time: 264.141
mmmaddpg vs mmmaddpg steps: 649975, episodes: 26000, mean episode reward: 19.53514331099237, agent episode reward: [7.417160124639037, 7.120920462090656, 7.249997468805686, 7.128358065068069, -4.672055749035584, -4.70923706057549], time: 267.772
mmmaddpg vs mmmaddpg steps: 674975, episodes: 27000, mean episode reward: 21.4102640395501, agent episode reward: [7.994639850287329, 7.786015479096182, 7.804671499033941, 7.704078203767485, -5.191473443781971, -4.6876675488528665], time: 261.808
mmmaddpg vs mmmaddpg steps: 699975, episodes: 28000, mean episode reward: 26.86999911464819, agent episode reward: [9.908394181463892, 9.608277439445185, 9.585620377607443, 9.529060697073838, -5.220668051792558, -6.540685529149612], time: 268.781
mmmaddpg vs mmmaddpg steps: 724975, episodes: 29000, mean episode reward: 25.76925363362704, agent episode reward: [9.514506809535943, 9.223412461084282, 9.224092489333998, 9.235201444113233, -4.888744808913829, -6.539214761526587], time: 267.028
mmmaddpg vs mmmaddpg steps: 749975, episodes: 30000, mean episode reward: 26.271804474662602, agent episode reward: [9.424906140374256, 9.318481430181757, 9.177363355743354, 9.237060968459453, -5.508341938138228, -5.377665481957988], time: 261.828
mmmaddpg vs mmmaddpg steps: 774975, episodes: 31000, mean episode reward: 32.65258661185369, agent episode reward: [11.73313657904945, 11.483010939049112, 11.380065091933574, 11.351955430533735, -5.819983063852496, -7.475598364859683], time: 266.213
mmmaddpg vs mmmaddpg steps: 799975, episodes: 32000, mean episode reward: 30.97350074135683, agent episode reward: [11.303170717173026, 11.098673371978043, 10.980791005244821, 11.026226967208524, -6.338329181166999, -7.097032139080586], time: 261.236
mmmaddpg vs mmmaddpg steps: 824975, episodes: 33000, mean episode reward: 29.195916132373075, agent episode reward: [10.725145644437188, 10.547653263260237, 10.420737333687086, 10.558119363989691, -6.681448659349612, -6.374290813651521], time: 263.527
mmmaddpg vs mmmaddpg steps: 849975, episodes: 34000, mean episode reward: 33.621282952442975, agent episode reward: [12.124440571867515, 11.90127367106128, 11.744336256819578, 11.758732905397261, -6.596475191806375, -7.311025260896274], time: 265.57
mmmaddpg vs mmmaddpg steps: 874975, episodes: 35000, mean episode reward: 35.03127970043711, agent episode reward: [12.53330831243581, 12.358407567126207, 12.127789681579946, 12.217165599557244, -6.761772590021844, -7.443618870240255], time: 273.093
mmmaddpg vs mmmaddpg steps: 899975, episodes: 36000, mean episode reward: 31.635483448771957, agent episode reward: [11.404644157390752, 11.189923328866609, 11.020117029552635, 11.081326389365891, -5.998365585232523, -7.062161871171408], time: 265.485
mmmaddpg vs mmmaddpg steps: 924975, episodes: 37000, mean episode reward: 36.13060280535646, agent episode reward: [12.915060870511478, 12.77643898768202, 12.499528813688082, 12.604551554625388, -7.584593097098885, -7.080384324051624], time: 266.959
mmmaddpg vs mmmaddpg steps: 949975, episodes: 38000, mean episode reward: 35.353447060478764, agent episode reward: [12.8872435122871, 12.708969665705455, 12.466381879354088, 12.683233047927478, -7.989478536925751, -7.402902507869613], time: 271.009
mmmaddpg vs mmmaddpg steps: 974975, episodes: 39000, mean episode reward: 40.860846340835245, agent episode reward: [14.398341262300173, 14.277053048024298, 13.981588899933186, 14.183026312766472, -8.679384396349578, -7.299778785839305], time: 272.105
mmmaddpg vs mmmaddpg steps: 999975, episodes: 40000, mean episode reward: 38.49042159892124, agent episode reward: [14.045550404555888, 13.914193005022632, 13.648497945363308, 13.790401469515361, -8.778201347773944, -8.130019877762006], time: 275.673
mmmaddpg vs mmmaddpg steps: 1024975, episodes: 41000, mean episode reward: 39.08246705130032, agent episode reward: [14.162443471056504, 14.066827686511886, 13.726785174609326, 13.963521347953538, -8.662523213546189, -8.174587415284748], time: 272.028
mmmaddpg vs mmmaddpg steps: 1049975, episodes: 42000, mean episode reward: 34.69355889690982, agent episode reward: [12.845247993979708, 12.799221888276508, 12.457961125489177, 12.718798196254276, -7.891524200468546, -8.2361461066213], time: 269.617
mmmaddpg vs mmmaddpg steps: 1074975, episodes: 43000, mean episode reward: 31.324132940608173, agent episode reward: [12.24532556081032, 12.147791546417636, 11.806574100793572, 12.00718533169042, -8.454025133614682, -8.42871846548909], time: 273.544
mmmaddpg vs mmmaddpg steps: 1099975, episodes: 44000, mean episode reward: 29.597017359718606, agent episode reward: [11.969476012595281, 11.848257769072578, 11.442205273475684, 11.817872946851114, -7.9141836414720474, -9.566611000804006], time: 273.537
mmmaddpg vs mmmaddpg steps: 1124975, episodes: 45000, mean episode reward: 39.54285626184513, agent episode reward: [14.998890094551374, 14.86070471295693, 14.604842737680592, 14.714751175092859, -8.85091860429095, -10.785413854145677], time: 260.819
mmmaddpg vs mmmaddpg steps: 1149975, episodes: 46000, mean episode reward: 32.582082383823526, agent episode reward: [12.725763814074133, 12.586597233840934, 12.354553998208765, 12.407845761826145, -8.028021711159816, -9.464656712966633], time: 259.127
mmmaddpg vs mmmaddpg steps: 1174975, episodes: 47000, mean episode reward: 33.14393938372613, agent episode reward: [13.206260693629225, 13.033971949962563, 12.839308997090303, 12.834101989398519, -8.087742845406384, -10.681961400948094], time: 256.176
mmmaddpg vs mmmaddpg steps: 1199975, episodes: 48000, mean episode reward: 28.629236539166268, agent episode reward: [11.766749367092721, 11.603956977275349, 11.351077015236667, 11.554291411797719, -7.760045544337672, -9.88679268789852], time: 262.977
mmmaddpg vs mmmaddpg steps: 1224975, episodes: 49000, mean episode reward: 27.490202987358956, agent episode reward: [11.421466530618481, 11.27319168676126, 11.045284980868525, 11.145787838159526, -7.280866238027834, -10.114661811021003], time: 259.49
mmmaddpg vs mmmaddpg steps: 1249975, episodes: 50000, mean episode reward: 30.89195910272241, agent episode reward: [12.144152826415493, 11.927553208157235, 11.756443390228414, 11.832193833856026, -7.001256944909488, -9.76712721102528], time: 264.289
mmmaddpg vs mmmaddpg steps: 1274975, episodes: 51000, mean episode reward: 29.21145282045893, agent episode reward: [11.65650459020998, 11.36590127679599, 11.252756892900623, 11.365501621282872, -6.984296030376745, -9.444915530353795], time: 263.982
mmmaddpg vs mmmaddpg steps: 1299975, episodes: 52000, mean episode reward: 24.507641140131668, agent episode reward: [10.471684519351873, 10.221866318565118, 10.020013360724686, 10.204252773594035, -8.082221542552496, -8.327954289551544], time: 262.427
mmmaddpg vs mmmaddpg steps: 1324975, episodes: 53000, mean episode reward: 23.680407773938807, agent episode reward: [10.338108851608798, 10.130207124696055, 9.872432044405228, 10.076415724839, -8.321932332788686, -8.414823638821588], time: 270.722
mmmaddpg vs mmmaddpg steps: 1349975, episodes: 54000, mean episode reward: 24.741985958606573, agent episode reward: [10.366918919386142, 10.01501235821849, 9.794033040953341, 10.074278549632298, -7.744466950880305, -7.763789958703397], time: 268.267
mmmaddpg vs mmmaddpg steps: 1374975, episodes: 55000, mean episode reward: 21.480483970873493, agent episode reward: [9.660096400963736, 9.191125251110595, 9.029810110867821, 9.248041406476156, -7.583670260635736, -8.064918937909084], time: 259.762
mmmaddpg vs mmmaddpg steps: 1399975, episodes: 56000, mean episode reward: 23.45242886164273, agent episode reward: [9.444505531442857, 9.001408160247845, 8.916335990018718, 9.0035149092524, -5.261903830261751, -7.651431899057339], time: 274.795
mmmaddpg vs mmmaddpg steps: 1424975, episodes: 57000, mean episode reward: 26.90275334450897, agent episode reward: [10.617125051820798, 10.20546481707248, 10.116482957645301, 10.201973583744072, -4.991187662385939, -9.247105403387748], time: 264.006
mmmaddpg vs mmmaddpg steps: 1449975, episodes: 58000, mean episode reward: 26.87147732135927, agent episode reward: [10.551940043736986, 10.174586879239241, 9.96702208105097, 10.061390621899903, -4.464805390719907, -9.418656913847927], time: 267.34
mmmaddpg vs mmmaddpg steps: 1474975, episodes: 59000, mean episode reward: 30.409822611436397, agent episode reward: [11.60925885139863, 11.293641539697317, 11.086694475656403, 11.177070731808396, -5.6144923295214, -9.14235065760295], time: 263.954
mmmaddpg vs mmmaddpg steps: 1499975, episodes: 60000, mean episode reward: 29.13367291770216, agent episode reward: [10.976901930698775, 10.696403231186391, 10.471698838729852, 10.67522732258531, -5.164617153981746, -8.521941251516422], time: 268.816
mmmaddpg vs mmmaddpg steps: 1524975, episodes: 61000, mean episode reward: 29.185513841622218, agent episode reward: [11.111805368929552, 10.67945254804555, 10.504274857178432, 10.699825800829247, -4.785213807790024, -9.024630925570545], time: 274.452
mmmaddpg vs mmmaddpg steps: 1549975, episodes: 62000, mean episode reward: 25.523502655320495, agent episode reward: [10.260857111210425, 9.77962808961247, 9.76839031624674, 9.753392273942216, -5.197693871842077, -8.841071263849278], time: 278.211
mmmaddpg vs mmmaddpg steps: 1574975, episodes: 63000, mean episode reward: 26.61092160883986, agent episode reward: [10.457076932450459, 10.029265590359852, 9.721642641667176, 10.095817693757319, -5.034990841076701, -8.657890408318242], time: 264.823
mmmaddpg vs mmmaddpg steps: 1599975, episodes: 64000, mean episode reward: 22.14801350703118, agent episode reward: [9.054930824021568, 8.611346098298721, 8.554447426242213, 8.604278892024835, -5.692474853168801, -6.9845148803873585], time: 273.111
mmmaddpg vs mmmaddpg steps: 1624975, episodes: 65000, mean episode reward: 24.558977093946428, agent episode reward: [10.375605610220449, 9.944330423026278, 10.008370990254974, 10.09696658802222, -5.708705065933835, -10.157591451643658], time: 265.555
mmmaddpg vs mmmaddpg steps: 1649975, episodes: 66000, mean episode reward: 21.659594349863568, agent episode reward: [9.831029163467624, 9.435428572312853, 9.479075998192307, 9.480155143820728, -5.914973381358197, -10.65112114657175], time: 276.791
mmmaddpg vs mmmaddpg steps: 1674975, episodes: 67000, mean episode reward: 26.054289069054292, agent episode reward: [10.73061126463833, 10.333467298009117, 10.304666583343213, 10.321957631871843, -6.474139670494565, -9.162274038313644], time: 274.461
mmmaddpg vs mmmaddpg steps: 1699975, episodes: 68000, mean episode reward: 27.113532826488488, agent episode reward: [10.878287690923019, 10.47659965655708, 10.36526707535998, 10.538447094450758, -6.153626436266816, -8.99144225453553], time: 270.47
mmmaddpg vs mmmaddpg steps: 1724975, episodes: 69000, mean episode reward: 27.493192898228312, agent episode reward: [10.811899298865312, 10.526750315463948, 10.346890083017138, 10.43773017561631, -5.202399099599453, -9.427677875134945], time: 263.158
mmmaddpg vs mmmaddpg steps: 1749975, episodes: 70000, mean episode reward: 28.636268999061603, agent episode reward: [10.975029949396028, 10.693323170259907, 10.595143812537184, 10.738323672997703, -5.021406269489829, -9.344145336639393], time: 264.576
mmmaddpg vs mmmaddpg steps: 1774975, episodes: 71000, mean episode reward: 31.556869367428888, agent episode reward: [11.892544853431868, 11.6507894310095, 11.441927324064123, 11.75066266395666, -5.856115798216632, -9.322939106816632], time: 271.845
mmmaddpg vs mmmaddpg steps: 1799975, episodes: 72000, mean episode reward: 35.6580133088298, agent episode reward: [13.206585190394572, 12.916133212616755, 12.758250314410537, 13.059183152323437, -7.256797742189228, -9.025340818726265], time: 261.067
mmmaddpg vs mmmaddpg steps: 1824975, episodes: 73000, mean episode reward: 32.851612865672784, agent episode reward: [12.427836410135319, 12.268386875166765, 12.069985494858186, 12.268810597244773, -7.094517957541757, -9.088888554190508], time: 266.8
mmmaddpg vs mmmaddpg steps: 1849975, episodes: 74000, mean episode reward: 36.95331869188453, agent episode reward: [13.590981553797347, 13.421659497078071, 13.318838091702178, 13.404832422041647, -7.709097912914086, -9.073894959820622], time: 268.277
mmmaddpg vs mmmaddpg steps: 1874975, episodes: 75000, mean episode reward: 29.05853476839292, agent episode reward: [11.081944564758334, 10.884077746229476, 10.735895557959676, 10.868951127081495, -5.761651472140378, -8.750682755495683], time: 274.107
mmmaddpg vs mmmaddpg steps: 1899975, episodes: 76000, mean episode reward: 23.04377218014198, agent episode reward: [9.127676300321715, 8.831051659177202, 8.766212999516524, 8.905080785312904, -4.8723215079481665, -7.713928056238201], time: 265.757
mmmaddpg vs mmmaddpg steps: 1924975, episodes: 77000, mean episode reward: 27.174132573818365, agent episode reward: [10.38341613898681, 10.129723962886535, 10.147696117836523, 10.185292367217205, -5.745419597807235, -7.9265764153014695], time: 266.384
mmmaddpg vs mmmaddpg steps: 1949975, episodes: 78000, mean episode reward: 27.27296986617698, agent episode reward: [10.333955196775463, 10.151318034476645, 10.105529528675259, 10.126370333022296, -6.489788615496949, -6.954414611275734], time: 264.724
mmmaddpg vs mmmaddpg steps: 1974975, episodes: 79000, mean episode reward: 27.038222004444023, agent episode reward: [10.230935793469296, 10.096946263652974, 9.901224884460783, 10.058389340429464, -6.585843264984456, -6.663431012584035], time: 267.304
mmmaddpg vs mmmaddpg steps: 1999975, episodes: 80000, mean episode reward: 24.649393573290652, agent episode reward: [9.477254713566177, 9.31662927907254, 9.101289994370305, 9.303543089267427, -5.958826276183769, -6.590497226802023], time: 274.376
mmmaddpg vs mmmaddpg steps: 2024975, episodes: 81000, mean episode reward: 25.90749556105631, agent episode reward: [10.095137933140053, 9.88652562579745, 9.565915939594735, 9.904710766605291, -6.334381394945224, -7.210413309135993], time: 273.255
mmmaddpg vs mmmaddpg steps: 2049975, episodes: 82000, mean episode reward: 24.009973869217138, agent episode reward: [9.550215614738963, 9.408321133797722, 9.189770792299926, 9.327878134952543, -6.42005754665114, -7.046154259920878], time: 265.548
mmmaddpg vs mmmaddpg steps: 2074975, episodes: 83000, mean episode reward: 24.862019249731187, agent episode reward: [9.77526507182391, 9.602603143480664, 9.430364696274195, 9.549976277422859, -6.309620497237474, -7.186569442032966], time: 266.036
mmmaddpg vs mmmaddpg steps: 2099975, episodes: 84000, mean episode reward: 24.185906176482646, agent episode reward: [9.692340768802469, 9.47441336384655, 9.149747997733966, 9.471715875545655, -5.826339614215644, -7.775972215230349], time: 273.771
mmmaddpg vs mmmaddpg steps: 2124975, episodes: 85000, mean episode reward: 18.771409886424102, agent episode reward: [8.100561950926274, 7.766898064687915, 7.658956842673652, 7.777285451886406, -5.650365915852423, -6.881926507897722], time: 270.54
mmmaddpg vs mmmaddpg steps: 2149975, episodes: 86000, mean episode reward: 24.54536853831799, agent episode reward: [9.64271987208074, 9.404588319309566, 9.268465209282141, 9.413222151628691, -6.28460448750238, -6.8990225264807705], time: 269.74
mmmaddpg vs mmmaddpg steps: 2174975, episodes: 87000, mean episode reward: 26.39090289555696, agent episode reward: [10.398639231626024, 10.136719723115606, 9.90214790889015, 10.086788615601396, -5.951973550023671, -8.181419033652547], time: 269.893
mmmaddpg vs mmmaddpg steps: 2199975, episodes: 88000, mean episode reward: 28.625303933259666, agent episode reward: [10.919350362181207, 10.61147605163149, 10.431494520423302, 10.622545027459335, -5.701743147890922, -8.257818880544743], time: 273.779
mmmaddpg vs mmmaddpg steps: 2224975, episodes: 89000, mean episode reward: 26.696439271489915, agent episode reward: [10.351087025439963, 10.084490156787327, 10.000042011592711, 10.063548305367858, -5.756130075398617, -8.04659815229933], time: 266.244
mmmaddpg vs mmmaddpg steps: 2249975, episodes: 90000, mean episode reward: 32.32157879672533, agent episode reward: [11.792970879331055, 11.539222456253416, 11.457319914927997, 11.526183451401849, -6.600190105683883, -7.3939277995051045], time: 274.384
mmmaddpg vs mmmaddpg steps: 2274975, episodes: 91000, mean episode reward: 32.850175054746856, agent episode reward: [12.19363315742491, 12.01266807581071, 11.951867276432642, 11.957539501324437, -8.033242882676252, -7.232290073569593], time: 270.609
mmmaddpg vs mmmaddpg steps: 2299975, episodes: 92000, mean episode reward: 30.045684085272516, agent episode reward: [11.266329889160824, 11.097029832136935, 11.01578298963327, 11.08336581121014, -7.9474712316259035, -6.469353205242752], time: 276.66
mmmaddpg vs mmmaddpg steps: 2324975, episodes: 93000, mean episode reward: 31.101020810465606, agent episode reward: [11.6697659743383, 11.47839485750589, 11.351217583832659, 11.431072479014894, -7.6249679741135905, -7.204462110112547], time: 267.916
mmmaddpg vs mmmaddpg steps: 2349975, episodes: 94000, mean episode reward: 28.63930163871033, agent episode reward: [10.891274775439769, 10.714157857057803, 10.571837546533533, 10.661308201654563, -7.796380729381506, -6.402896012593831], time: 266.845
mmmaddpg vs mmmaddpg steps: 2374975, episodes: 95000, mean episode reward: 26.433752441411844, agent episode reward: [10.279908072735267, 9.920928337145826, 10.040018733638957, 9.897792317492245, -6.032016970739758, -7.672878048860691], time: 268.71
mmmaddpg vs mmmaddpg steps: 2399975, episodes: 96000, mean episode reward: 28.52354744212152, agent episode reward: [11.146916888702696, 10.853371329638223, 10.918590061195479, 10.902794998351899, -7.582778687300261, -7.715347148466512], time: 274.577
mmmaddpg vs mmmaddpg steps: 2424975, episodes: 97000, mean episode reward: 29.293856525191682, agent episode reward: [11.370258153229324, 11.11761667051272, 11.061275029046097, 11.06295569306596, -7.54991956814958, -7.76832945251284], time: 269.246
mmmaddpg vs mmmaddpg steps: 2449975, episodes: 98000, mean episode reward: 27.974911884269627, agent episode reward: [10.849297052954551, 10.598463963735433, 10.523180059472496, 10.573198460687793, -7.188511061929623, -7.380716590651024], time: 272.839
mmmaddpg vs mmmaddpg steps: 2474975, episodes: 99000, mean episode reward: 30.610821949487008, agent episode reward: [11.408662623885318, 11.147098485772807, 11.124153880054365, 11.18568660182866, -6.477360539086752, -7.777419102967393], time: 274.972
mmmaddpg vs mmmaddpg steps: 2499975, episodes: 100000, mean episode reward: 28.517696916868204, agent episode reward: [10.829451595384246, 10.526570474003238, 10.427855600345548, 10.536447620817052, -6.34883690474498, -7.4537914689369025], time: 268.79
...Finished total of 100001 episodes.
