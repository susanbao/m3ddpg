0 bad agents
      adv rate for q_index :  0 [1e-05, 0.001]
      adv rate for p_index :  0 [1e-05, 0.001]
1 good agents
      adv rate for q_index :  1 [0.001, 1e-05]
      adv rate for p_index :  1 [0.001, 1e-05]
Using good policy mmmaddpg and bad policy mmmaddpg with 1 adversaries
Starting iterations...
mmmaddpg vs mmmaddpg steps: 24975, episodes: 1000, mean episode reward: -26.529973969086978, agent episode reward: [1.8017089688107752, -28.331682937897757], time: 27.435
mmmaddpg vs mmmaddpg steps: 49975, episodes: 2000, mean episode reward: -19.510321131283074, agent episode reward: [-5.424898845694022, -14.085422285589052], time: 45.743
mmmaddpg vs mmmaddpg steps: 74975, episodes: 3000, mean episode reward: -10.32923707130416, agent episode reward: [-3.4811692941503445, -6.848067777153815], time: 46.662
mmmaddpg vs mmmaddpg steps: 99975, episodes: 4000, mean episode reward: -9.43331645503692, agent episode reward: [-2.6251325221239967, -6.8081839329129235], time: 47.22
mmmaddpg vs mmmaddpg steps: 124975, episodes: 5000, mean episode reward: -9.301508754189621, agent episode reward: [-2.6259897257699585, -6.675519028419662], time: 46.843
mmmaddpg vs mmmaddpg steps: 149975, episodes: 6000, mean episode reward: -8.907421229219628, agent episode reward: [-2.4338455360587523, -6.473575693160876], time: 45.259
mmmaddpg vs mmmaddpg steps: 174975, episodes: 7000, mean episode reward: -8.932477744710221, agent episode reward: [-2.24591271232287, -6.6865650323873504], time: 46.73
mmmaddpg vs mmmaddpg steps: 199975, episodes: 8000, mean episode reward: -8.54797320165875, agent episode reward: [-1.915207046257288, -6.632766155401463], time: 45.879
mmmaddpg vs mmmaddpg steps: 224975, episodes: 9000, mean episode reward: -8.89643049376728, agent episode reward: [-2.4229505440920476, -6.473479949675232], time: 46.355
mmmaddpg vs mmmaddpg steps: 249975, episodes: 10000, mean episode reward: -8.746834061998022, agent episode reward: [-2.237579893029875, -6.509254168968147], time: 47.231
mmmaddpg vs mmmaddpg steps: 274975, episodes: 11000, mean episode reward: -8.778413482417603, agent episode reward: [-1.9873807994470005, -6.791032682970604], time: 46.573
mmmaddpg vs mmmaddpg steps: 299975, episodes: 12000, mean episode reward: -8.998236254879298, agent episode reward: [-2.2385103999728986, -6.7597258549064], time: 47.186
mmmaddpg vs mmmaddpg steps: 324975, episodes: 13000, mean episode reward: -8.778232887413685, agent episode reward: [-2.0600467208048676, -6.718186166608817], time: 46.831
mmmaddpg vs mmmaddpg steps: 349975, episodes: 14000, mean episode reward: -8.729301269737277, agent episode reward: [-1.9572579657090745, -6.7720433040282035], time: 46.953
mmmaddpg vs mmmaddpg steps: 374975, episodes: 15000, mean episode reward: -8.843065740935025, agent episode reward: [-2.4042814107602344, -6.438784330174791], time: 46.706
mmmaddpg vs mmmaddpg steps: 399975, episodes: 16000, mean episode reward: -8.66219337588911, agent episode reward: [-2.1533600034956972, -6.508833372393414], time: 47.319
mmmaddpg vs mmmaddpg steps: 424975, episodes: 17000, mean episode reward: -8.811420111303807, agent episode reward: [-2.043430865835718, -6.7679892454680886], time: 46.779
mmmaddpg vs mmmaddpg steps: 449975, episodes: 18000, mean episode reward: -9.063488862980336, agent episode reward: [-1.9445976611059954, -7.118891201874339], time: 47.1
mmmaddpg vs mmmaddpg steps: 474975, episodes: 19000, mean episode reward: -8.815580007264664, agent episode reward: [-1.6749353326622054, -7.140644674602459], time: 46.822
mmmaddpg vs mmmaddpg steps: 499975, episodes: 20000, mean episode reward: -8.84711295712669, agent episode reward: [-1.994181360454106, -6.852931596672584], time: 46.861
mmmaddpg vs mmmaddpg steps: 524975, episodes: 21000, mean episode reward: -8.869874816251935, agent episode reward: [-1.9019844041580045, -6.96789041209393], time: 47.42
mmmaddpg vs mmmaddpg steps: 549975, episodes: 22000, mean episode reward: -8.981177563109172, agent episode reward: [-2.1884438955503684, -6.792733667558806], time: 46.538
mmmaddpg vs mmmaddpg steps: 574975, episodes: 23000, mean episode reward: -8.9610787957017, agent episode reward: [-2.038128758756936, -6.922950036944763], time: 46.97
mmmaddpg vs mmmaddpg steps: 599975, episodes: 24000, mean episode reward: -9.31681452944935, agent episode reward: [-2.430628452098016, -6.886186077351335], time: 46.397
mmmaddpg vs mmmaddpg steps: 624975, episodes: 25000, mean episode reward: -9.174479898182824, agent episode reward: [-2.590060560265508, -6.584419337917317], time: 46.961
mmmaddpg vs mmmaddpg steps: 649975, episodes: 26000, mean episode reward: -9.35898741057635, agent episode reward: [-2.730873744473623, -6.628113666102728], time: 46.93
mmmaddpg vs mmmaddpg steps: 674975, episodes: 27000, mean episode reward: -9.331752832465531, agent episode reward: [-2.638176009465684, -6.693576822999846], time: 46.721
mmmaddpg vs mmmaddpg steps: 699975, episodes: 28000, mean episode reward: -9.167015902123287, agent episode reward: [-2.930016871449836, -6.23699903067345], time: 47.039
mmmaddpg vs mmmaddpg steps: 724975, episodes: 29000, mean episode reward: -9.267963879488459, agent episode reward: [-2.46104658892092, -6.806917290567541], time: 47.177
mmmaddpg vs mmmaddpg steps: 749975, episodes: 30000, mean episode reward: -9.014624185403354, agent episode reward: [-2.6608556333410553, -6.3537685520623], time: 46.473
mmmaddpg vs mmmaddpg steps: 774975, episodes: 31000, mean episode reward: -9.324170593013841, agent episode reward: [-2.512626191946991, -6.81154440106685], time: 46.557
mmmaddpg vs mmmaddpg steps: 799975, episodes: 32000, mean episode reward: -9.390839423414516, agent episode reward: [-2.7698393620404214, -6.621000061374094], time: 47.264
mmmaddpg vs mmmaddpg steps: 824975, episodes: 33000, mean episode reward: -9.271149303802105, agent episode reward: [-2.8188795355229335, -6.452269768279172], time: 47.024
mmmaddpg vs mmmaddpg steps: 849975, episodes: 34000, mean episode reward: -9.15926751793505, agent episode reward: [-2.3789313501853795, -6.78033616774967], time: 46.64
mmmaddpg vs mmmaddpg steps: 874975, episodes: 35000, mean episode reward: -8.831206097284609, agent episode reward: [-1.7775615532954683, -7.0536445439891375], time: 46.823
mmmaddpg vs mmmaddpg steps: 899975, episodes: 36000, mean episode reward: -8.828541157420306, agent episode reward: [-2.002562941634019, -6.8259782157862885], time: 47.12
mmmaddpg vs mmmaddpg steps: 924975, episodes: 37000, mean episode reward: -8.807028957902348, agent episode reward: [-1.5393448332682287, -7.267684124634119], time: 46.581
mmmaddpg vs mmmaddpg steps: 949975, episodes: 38000, mean episode reward: -9.039024714159732, agent episode reward: [-1.052878338880151, -7.986146375279579], time: 46.461
mmmaddpg vs mmmaddpg steps: 974975, episodes: 39000, mean episode reward: -8.858172062489597, agent episode reward: [-0.3486105826544286, -8.509561479835169], time: 46.39
mmmaddpg vs mmmaddpg steps: 999975, episodes: 40000, mean episode reward: -8.913428950110374, agent episode reward: [-0.16374159340276462, -8.74968735670761], time: 47.055
mmmaddpg vs mmmaddpg steps: 1024975, episodes: 41000, mean episode reward: -8.862276506515386, agent episode reward: [-0.6189947320312886, -8.243281774484098], time: 47.658
mmmaddpg vs mmmaddpg steps: 1049975, episodes: 42000, mean episode reward: -8.864513705589088, agent episode reward: [-0.9309672964938835, -7.933546409095206], time: 46.908
mmmaddpg vs mmmaddpg steps: 1074975, episodes: 43000, mean episode reward: -8.806377492111515, agent episode reward: [-1.7067182137602717, -7.099659278351244], time: 46.695
mmmaddpg vs mmmaddpg steps: 1099975, episodes: 44000, mean episode reward: -8.855688210049099, agent episode reward: [-1.561787750166946, -7.293900459882152], time: 45.977
mmmaddpg vs mmmaddpg steps: 1124975, episodes: 45000, mean episode reward: -8.757301442958832, agent episode reward: [-1.5511887124817125, -7.20611273047712], time: 45.717
mmmaddpg vs mmmaddpg steps: 1149975, episodes: 46000, mean episode reward: -8.800978516650357, agent episode reward: [-1.5258770455317427, -7.275101471118615], time: 46.181
mmmaddpg vs mmmaddpg steps: 1174975, episodes: 47000, mean episode reward: -8.956044047779644, agent episode reward: [-1.1850757989702048, -7.77096824880944], time: 45.915
mmmaddpg vs mmmaddpg steps: 1199975, episodes: 48000, mean episode reward: -8.853536529954763, agent episode reward: [0.0005106095386425693, -8.854047139493407], time: 46.135
mmmaddpg vs mmmaddpg steps: 1224975, episodes: 49000, mean episode reward: -9.070546418100118, agent episode reward: [0.6992706270275965, -9.769817045127716], time: 46.335
mmmaddpg vs mmmaddpg steps: 1249975, episodes: 50000, mean episode reward: -8.933165710080972, agent episode reward: [0.09765810581762503, -9.030823815898597], time: 46.324
mmmaddpg vs mmmaddpg steps: 1274975, episodes: 51000, mean episode reward: -8.776689355687859, agent episode reward: [0.14134219834106412, -8.918031554028923], time: 46.33
mmmaddpg vs mmmaddpg steps: 1299975, episodes: 52000, mean episode reward: -9.137753129661702, agent episode reward: [0.6740218347566274, -9.811774964418328], time: 45.886
mmmaddpg vs mmmaddpg steps: 1324975, episodes: 53000, mean episode reward: -9.244201151905733, agent episode reward: [1.2896342770132843, -10.533835428919017], time: 46.078
mmmaddpg vs mmmaddpg steps: 1349975, episodes: 54000, mean episode reward: -8.895710359393993, agent episode reward: [1.5264239798937864, -10.42213433928778], time: 45.787
mmmaddpg vs mmmaddpg steps: 1374975, episodes: 55000, mean episode reward: -8.530115545473349, agent episode reward: [1.2584542532043883, -9.788569798677738], time: 46.555
mmmaddpg vs mmmaddpg steps: 1399975, episodes: 56000, mean episode reward: -8.466380250973781, agent episode reward: [-0.8449207831452652, -7.621459467828517], time: 46.414
mmmaddpg vs mmmaddpg steps: 1424975, episodes: 57000, mean episode reward: -8.501436096919239, agent episode reward: [-0.848671362931505, -7.652764733987734], time: 45.427
mmmaddpg vs mmmaddpg steps: 1449975, episodes: 58000, mean episode reward: -8.863828167330565, agent episode reward: [-1.5094946057474095, -7.3543335615831555], time: 45.308
mmmaddpg vs mmmaddpg steps: 1474975, episodes: 59000, mean episode reward: -8.800493180353428, agent episode reward: [-0.6099801055479048, -8.190513074805523], time: 45.609
mmmaddpg vs mmmaddpg steps: 1499975, episodes: 60000, mean episode reward: -8.592455625423836, agent episode reward: [0.8220148729586035, -9.414470498382439], time: 46.383
mmmaddpg vs mmmaddpg steps: 1524975, episodes: 61000, mean episode reward: -8.76100511162721, agent episode reward: [0.2780941228151099, -9.03909923444232], time: 46.006
mmmaddpg vs mmmaddpg steps: 1549975, episodes: 62000, mean episode reward: -8.902237873540445, agent episode reward: [0.29090660403617197, -9.193144477576618], time: 44.945
mmmaddpg vs mmmaddpg steps: 1574975, episodes: 63000, mean episode reward: -8.847321086359258, agent episode reward: [0.63674235661189, -9.484063442971147], time: 45.28
mmmaddpg vs mmmaddpg steps: 1599975, episodes: 64000, mean episode reward: -9.115470728129075, agent episode reward: [0.6353503083958174, -9.750821036524892], time: 45.679
mmmaddpg vs mmmaddpg steps: 1624975, episodes: 65000, mean episode reward: -9.115535150919623, agent episode reward: [-0.22710850359399984, -8.888426647325625], time: 45.986
mmmaddpg vs mmmaddpg steps: 1649975, episodes: 66000, mean episode reward: -8.658116651523004, agent episode reward: [-0.7777159262839077, -7.880400725239094], time: 46.205
mmmaddpg vs mmmaddpg steps: 1674975, episodes: 67000, mean episode reward: -8.834020113126668, agent episode reward: [-1.7688468370881052, -7.065173276038563], time: 46.212
mmmaddpg vs mmmaddpg steps: 1699975, episodes: 68000, mean episode reward: -8.454396715001055, agent episode reward: [-1.063314375612911, -7.3910823393881415], time: 46.285
mmmaddpg vs mmmaddpg steps: 1724975, episodes: 69000, mean episode reward: -8.354320226863612, agent episode reward: [-1.1649376828764153, -7.189382543987198], time: 46.228
mmmaddpg vs mmmaddpg steps: 1749975, episodes: 70000, mean episode reward: -8.507265958496879, agent episode reward: [-1.3318272774563689, -7.17543868104051], time: 46.633
mmmaddpg vs mmmaddpg steps: 1774975, episodes: 71000, mean episode reward: -8.584554851491902, agent episode reward: [-1.4010437389643557, -7.183511112527544], time: 45.61
mmmaddpg vs mmmaddpg steps: 1799975, episodes: 72000, mean episode reward: -8.679588339481935, agent episode reward: [-1.351882980307087, -7.327705359174848], time: 45.48
mmmaddpg vs mmmaddpg steps: 1824975, episodes: 73000, mean episode reward: -8.307975703198842, agent episode reward: [-0.9845598353932729, -7.323415867805571], time: 46.195
mmmaddpg vs mmmaddpg steps: 1849975, episodes: 74000, mean episode reward: -8.329158356920267, agent episode reward: [-0.8171536241520787, -7.5120047327681885], time: 46.038
mmmaddpg vs mmmaddpg steps: 1874975, episodes: 75000, mean episode reward: -8.37934273035128, agent episode reward: [-0.7441830884186764, -7.635159641932604], time: 46.912
mmmaddpg vs mmmaddpg steps: 1899975, episodes: 76000, mean episode reward: -8.461083958329686, agent episode reward: [-1.2694918850064572, -7.191592073323228], time: 46.113
mmmaddpg vs mmmaddpg steps: 1924975, episodes: 77000, mean episode reward: -8.386684640778475, agent episode reward: [-1.449589754900246, -6.937094885878229], time: 46.003
mmmaddpg vs mmmaddpg steps: 1949975, episodes: 78000, mean episode reward: -8.405294145742639, agent episode reward: [-1.0843650560764277, -7.320929089666212], time: 46.09
mmmaddpg vs mmmaddpg steps: 1974975, episodes: 79000, mean episode reward: -8.667678283524314, agent episode reward: [-0.8705330556560693, -7.797145227868245], time: 46.034
mmmaddpg vs mmmaddpg steps: 1999975, episodes: 80000, mean episode reward: -8.275989870030733, agent episode reward: [-0.6604762906167787, -7.615513579413953], time: 46.035
mmmaddpg vs mmmaddpg steps: 2024975, episodes: 81000, mean episode reward: -8.514291530570883, agent episode reward: [-1.0636399395547296, -7.450651591016152], time: 45.706
mmmaddpg vs mmmaddpg steps: 2049975, episodes: 82000, mean episode reward: -8.681820732818673, agent episode reward: [-1.4176292864414526, -7.264191446377221], time: 46.141
mmmaddpg vs mmmaddpg steps: 2074975, episodes: 83000, mean episode reward: -8.416909462082419, agent episode reward: [-1.2119352778382106, -7.204974184244209], time: 45.882
mmmaddpg vs mmmaddpg steps: 2099975, episodes: 84000, mean episode reward: -8.166492730982089, agent episode reward: [-0.580758651487373, -7.585734079494716], time: 45.87
mmmaddpg vs mmmaddpg steps: 2124975, episodes: 85000, mean episode reward: -8.416893098500372, agent episode reward: [0.25517808615399123, -8.672071184654362], time: 44.932
mmmaddpg vs mmmaddpg steps: 2149975, episodes: 86000, mean episode reward: -8.607254334655252, agent episode reward: [0.006843839093436784, -8.614098173748689], time: 45.733
mmmaddpg vs mmmaddpg steps: 2174975, episodes: 87000, mean episode reward: -8.528879265888294, agent episode reward: [0.3608631194941152, -8.889742385382409], time: 46.297
mmmaddpg vs mmmaddpg steps: 2199975, episodes: 88000, mean episode reward: -8.504326233786632, agent episode reward: [0.23872302776068802, -8.74304926154732], time: 45.593
mmmaddpg vs mmmaddpg steps: 2224975, episodes: 89000, mean episode reward: -8.440076876843202, agent episode reward: [0.12081098956836642, -8.56088786641157], time: 45.304
mmmaddpg vs mmmaddpg steps: 2249975, episodes: 90000, mean episode reward: -8.562917556437565, agent episode reward: [-0.0035117905647743973, -8.559405765872791], time: 45.958
mmmaddpg vs mmmaddpg steps: 2274975, episodes: 91000, mean episode reward: -8.422709016387932, agent episode reward: [0.4649719856697278, -8.88768100205766], time: 46.02
mmmaddpg vs mmmaddpg steps: 2299975, episodes: 92000, mean episode reward: -8.640854662121496, agent episode reward: [0.2710326183387503, -8.911887280460247], time: 46.184
mmmaddpg vs mmmaddpg steps: 2324975, episodes: 93000, mean episode reward: -8.647049480077998, agent episode reward: [0.14749522297750625, -8.794544703055504], time: 46.36
mmmaddpg vs mmmaddpg steps: 2349975, episodes: 94000, mean episode reward: -8.676112036842431, agent episode reward: [-0.01833019801713377, -8.657781838825297], time: 46.004
mmmaddpg vs mmmaddpg steps: 2374975, episodes: 95000, mean episode reward: -8.767659620430884, agent episode reward: [-0.9395574776598601, -7.828102142771024], time: 46.347
mmmaddpg vs mmmaddpg steps: 2399975, episodes: 96000, mean episode reward: -8.75670267215345, agent episode reward: [-1.428827947876075, -7.3278747242773745], time: 46.44
mmmaddpg vs mmmaddpg steps: 2424975, episodes: 97000, mean episode reward: -9.078872690146044, agent episode reward: [-1.9116985352104725, -7.16717415493557], time: 46.137
mmmaddpg vs mmmaddpg steps: 2449975, episodes: 98000, mean episode reward: -8.734374461616088, agent episode reward: [-1.2327230631090256, -7.501651398507062], time: 46.294
mmmaddpg vs mmmaddpg steps: 2474975, episodes: 99000, mean episode reward: -8.884824016160051, agent episode reward: [-1.1617285272203264, -7.723095488939723], time: 46.206
mmmaddpg vs mmmaddpg steps: 2499975, episodes: 100000, mean episode reward: -8.849498430313261, agent episode reward: [-1.1968142629870488, -7.65268416732621], time: 46.188
...Finished total of 100001 episodes.
