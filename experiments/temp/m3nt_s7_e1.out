0 bad agents
      adv rate for q_index :  0 [1e-05, 1e-05, 1e-05, 0.001]
      adv rate for p_index :  0 [1e-05, 1e-05, 1e-05, 0.001]
1 bad agents
      adv rate for q_index :  1 [1e-05, 1e-05, 1e-05, 0.001]
      adv rate for p_index :  1 [1e-05, 1e-05, 1e-05, 0.001]
2 bad agents
      adv rate for q_index :  2 [1e-05, 1e-05, 1e-05, 0.001]
      adv rate for p_index :  2 [1e-05, 1e-05, 1e-05, 0.001]
3 good agents
      adv rate for q_index :  3 [0.001, 0.001, 0.001, 1e-05]
      adv rate for p_index :  3 [0.001, 0.001, 0.001, 1e-05]
Using good policy mmmaddpg and bad policy mmmaddpg with 3 adversaries
Starting iterations...
mmmaddpg vs mmmaddpg steps: 24975, episodes: 1000, mean episode reward: -3.3523349973906362, agent episode reward: [2.11, 2.11, 2.11, -9.682334997390637], time: 80.532
mmmaddpg vs mmmaddpg steps: 49975, episodes: 2000, mean episode reward: -3.9266419718191665, agent episode reward: [4.77, 4.77, 4.77, -18.236641971819168], time: 118.275
mmmaddpg vs mmmaddpg steps: 74975, episodes: 3000, mean episode reward: 11.438561684104755, agent episode reward: [6.1, 6.1, 6.1, -6.861438315895244], time: 117.526
mmmaddpg vs mmmaddpg steps: 99975, episodes: 4000, mean episode reward: 9.014885156382752, agent episode reward: [4.94, 4.94, 4.94, -5.805114843617249], time: 117.984
mmmaddpg vs mmmaddpg steps: 124975, episodes: 5000, mean episode reward: 6.680729800044004, agent episode reward: [3.79, 3.79, 3.79, -4.689270199955997], time: 117.663
mmmaddpg vs mmmaddpg steps: 149975, episodes: 6000, mean episode reward: 6.333286948975397, agent episode reward: [3.64, 3.64, 3.64, -4.586713051024602], time: 119.266
mmmaddpg vs mmmaddpg steps: 174975, episodes: 7000, mean episode reward: 8.151072362478542, agent episode reward: [4.78, 4.78, 4.78, -6.1889276375214575], time: 119.577
mmmaddpg vs mmmaddpg steps: 199975, episodes: 8000, mean episode reward: 11.21382356259619, agent episode reward: [6.24, 6.24, 6.24, -7.50617643740381], time: 120.002
mmmaddpg vs mmmaddpg steps: 224975, episodes: 9000, mean episode reward: 10.238182184041717, agent episode reward: [6.33, 6.33, 6.33, -8.751817815958281], time: 124.615
mmmaddpg vs mmmaddpg steps: 249975, episodes: 10000, mean episode reward: 8.671755356897515, agent episode reward: [5.64, 5.64, 5.64, -8.248244643102485], time: 124.529
mmmaddpg vs mmmaddpg steps: 274975, episodes: 11000, mean episode reward: 8.731976771880598, agent episode reward: [6.33, 6.33, 6.33, -10.2580232281194], time: 120.292
mmmaddpg vs mmmaddpg steps: 299975, episodes: 12000, mean episode reward: 10.293824652100751, agent episode reward: [7.78, 7.78, 7.78, -13.04617534789925], time: 119.061
mmmaddpg vs mmmaddpg steps: 324975, episodes: 13000, mean episode reward: 8.613037098011816, agent episode reward: [8.11, 8.11, 8.11, -15.716962901988184], time: 122.005
mmmaddpg vs mmmaddpg steps: 349975, episodes: 14000, mean episode reward: 8.373335482698273, agent episode reward: [8.02, 8.02, 8.02, -15.686664517301724], time: 123.358
mmmaddpg vs mmmaddpg steps: 374975, episodes: 15000, mean episode reward: 9.831508198922382, agent episode reward: [8.12, 8.12, 8.12, -14.528491801077617], time: 118.681
mmmaddpg vs mmmaddpg steps: 399975, episodes: 16000, mean episode reward: 6.930282137162484, agent episode reward: [7.91, 7.91, 7.91, -16.799717862837518], time: 119.606
mmmaddpg vs mmmaddpg steps: 424975, episodes: 17000, mean episode reward: 12.831113043533325, agent episode reward: [10.28, 10.28, 10.28, -18.008886956466675], time: 120.668
mmmaddpg vs mmmaddpg steps: 449975, episodes: 18000, mean episode reward: 15.629723929379473, agent episode reward: [10.54, 10.54, 10.54, -15.990276070620528], time: 121.12
mmmaddpg vs mmmaddpg steps: 474975, episodes: 19000, mean episode reward: 13.531388176255103, agent episode reward: [9.15, 9.15, 9.15, -13.918611823744897], time: 120.416
mmmaddpg vs mmmaddpg steps: 499975, episodes: 20000, mean episode reward: 7.907241206675835, agent episode reward: [7.67, 7.67, 7.67, -15.102758793324167], time: 120.273
mmmaddpg vs mmmaddpg steps: 524975, episodes: 21000, mean episode reward: 12.340554877730375, agent episode reward: [9.17, 9.17, 9.17, -15.16944512226963], time: 121.886
mmmaddpg vs mmmaddpg steps: 549975, episodes: 22000, mean episode reward: 16.50616706571972, agent episode reward: [11.11, 11.11, 11.11, -16.823832934280283], time: 120.272
mmmaddpg vs mmmaddpg steps: 574975, episodes: 23000, mean episode reward: 14.817958992069876, agent episode reward: [11.06, 11.06, 11.06, -18.36204100793012], time: 120.465
mmmaddpg vs mmmaddpg steps: 599975, episodes: 24000, mean episode reward: 15.350420414190495, agent episode reward: [11.77, 11.77, 11.77, -19.9595795858095], time: 125.595
mmmaddpg vs mmmaddpg steps: 624975, episodes: 25000, mean episode reward: 17.990531850601776, agent episode reward: [12.25, 12.25, 12.25, -18.759468149398224], time: 122.941
mmmaddpg vs mmmaddpg steps: 649975, episodes: 26000, mean episode reward: 14.671203702178014, agent episode reward: [10.87, 10.87, 10.87, -17.938796297821987], time: 123.814
mmmaddpg vs mmmaddpg steps: 674975, episodes: 27000, mean episode reward: 20.074669221998775, agent episode reward: [13.21, 13.21, 13.21, -19.555330778001224], time: 122.179
mmmaddpg vs mmmaddpg steps: 699975, episodes: 28000, mean episode reward: 17.17156273179727, agent episode reward: [12.59, 12.59, 12.59, -20.59843726820273], time: 122.571
mmmaddpg vs mmmaddpg steps: 724975, episodes: 29000, mean episode reward: 17.529763425463994, agent episode reward: [12.97, 12.97, 12.97, -21.38023657453601], time: 120.342
mmmaddpg vs mmmaddpg steps: 749975, episodes: 30000, mean episode reward: 23.669567717214974, agent episode reward: [15.44, 15.44, 15.44, -22.650432282785026], time: 124.17
mmmaddpg vs mmmaddpg steps: 774975, episodes: 31000, mean episode reward: 20.742041962081572, agent episode reward: [13.88, 13.88, 13.88, -20.89795803791842], time: 124.467
mmmaddpg vs mmmaddpg steps: 799975, episodes: 32000, mean episode reward: 20.638095826617704, agent episode reward: [14.51, 14.51, 14.51, -22.891904173382297], time: 122.373
mmmaddpg vs mmmaddpg steps: 824975, episodes: 33000, mean episode reward: 16.569333853851944, agent episode reward: [12.56, 12.56, 12.56, -21.110666146148052], time: 124.683
mmmaddpg vs mmmaddpg steps: 849975, episodes: 34000, mean episode reward: 16.23900931702257, agent episode reward: [12.04, 12.04, 12.04, -19.88099068297743], time: 124.589
mmmaddpg vs mmmaddpg steps: 874975, episodes: 35000, mean episode reward: 16.09304692815494, agent episode reward: [11.99, 11.99, 11.99, -19.876953071845058], time: 124.315
mmmaddpg vs mmmaddpg steps: 899975, episodes: 36000, mean episode reward: 16.31655464708755, agent episode reward: [12.32, 12.32, 12.32, -20.64344535291245], time: 123.332
mmmaddpg vs mmmaddpg steps: 924975, episodes: 37000, mean episode reward: 17.135645397199557, agent episode reward: [12.6, 12.6, 12.6, -20.664354602800444], time: 124.79
mmmaddpg vs mmmaddpg steps: 949975, episodes: 38000, mean episode reward: 16.989701665464658, agent episode reward: [12.6, 12.6, 12.6, -20.810298334535343], time: 125.255
mmmaddpg vs mmmaddpg steps: 974975, episodes: 39000, mean episode reward: 14.63877935721029, agent episode reward: [11.43, 11.43, 11.43, -19.65122064278971], time: 124.463
mmmaddpg vs mmmaddpg steps: 999975, episodes: 40000, mean episode reward: 15.2662037276868, agent episode reward: [11.64, 11.64, 11.64, -19.653796272313198], time: 107.141
mmmaddpg vs mmmaddpg steps: 1024975, episodes: 41000, mean episode reward: 16.73183637321263, agent episode reward: [12.67, 12.67, 12.67, -21.278163626787368], time: 106.443
mmmaddpg vs mmmaddpg steps: 1049975, episodes: 42000, mean episode reward: 16.45705544138247, agent episode reward: [12.16, 12.16, 12.16, -20.022944558617528], time: 107.046
mmmaddpg vs mmmaddpg steps: 1074975, episodes: 43000, mean episode reward: 15.423662245735743, agent episode reward: [12.05, 12.05, 12.05, -20.726337754264257], time: 107.169
mmmaddpg vs mmmaddpg steps: 1099975, episodes: 44000, mean episode reward: 19.212606564307713, agent episode reward: [13.2, 13.2, 13.2, -20.38739343569229], time: 105.566
mmmaddpg vs mmmaddpg steps: 1124975, episodes: 45000, mean episode reward: 16.849159105444663, agent episode reward: [13.05, 13.05, 13.05, -22.30084089455534], time: 105.783
mmmaddpg vs mmmaddpg steps: 1149975, episodes: 46000, mean episode reward: 21.952344452143308, agent episode reward: [15.09, 15.09, 15.09, -23.31765554785669], time: 107.414
mmmaddpg vs mmmaddpg steps: 1174975, episodes: 47000, mean episode reward: 15.272819756030731, agent episode reward: [11.92, 11.92, 11.92, -20.48718024396927], time: 105.43
mmmaddpg vs mmmaddpg steps: 1199975, episodes: 48000, mean episode reward: 19.238763193757332, agent episode reward: [13.9, 13.9, 13.9, -22.461236806242667], time: 105.038
mmmaddpg vs mmmaddpg steps: 1224975, episodes: 49000, mean episode reward: 19.788893855581286, agent episode reward: [13.63, 13.63, 13.63, -21.101106144418715], time: 105.481
mmmaddpg vs mmmaddpg steps: 1249975, episodes: 50000, mean episode reward: 19.55209947808731, agent episode reward: [13.37, 13.37, 13.37, -20.557900521912693], time: 107.559
mmmaddpg vs mmmaddpg steps: 1274975, episodes: 51000, mean episode reward: 19.772062980454567, agent episode reward: [14.04, 14.04, 14.04, -22.347937019545434], time: 104.836
mmmaddpg vs mmmaddpg steps: 1299975, episodes: 52000, mean episode reward: 20.853881210462013, agent episode reward: [14.18, 14.18, 14.18, -21.686118789537993], time: 108.006
mmmaddpg vs mmmaddpg steps: 1324975, episodes: 53000, mean episode reward: 23.876551649634305, agent episode reward: [15.03, 15.03, 15.03, -21.213448350365695], time: 109.19
mmmaddpg vs mmmaddpg steps: 1349975, episodes: 54000, mean episode reward: 20.51605147567448, agent episode reward: [13.55, 13.55, 13.55, -20.13394852432552], time: 110.347
mmmaddpg vs mmmaddpg steps: 1374975, episodes: 55000, mean episode reward: 21.161647731357, agent episode reward: [14.4, 14.4, 14.4, -22.038352268643], time: 129.162
mmmaddpg vs mmmaddpg steps: 1399975, episodes: 56000, mean episode reward: 16.38186760733985, agent episode reward: [12.5, 12.5, 12.5, -21.11813239266015], time: 128.691
mmmaddpg vs mmmaddpg steps: 1424975, episodes: 57000, mean episode reward: 20.386980622005467, agent episode reward: [13.34, 13.34, 13.34, -19.633019377994533], time: 127.531
mmmaddpg vs mmmaddpg steps: 1449975, episodes: 58000, mean episode reward: 21.412292388055135, agent episode reward: [14.13, 14.13, 14.13, -20.97770761194487], time: 132.453
mmmaddpg vs mmmaddpg steps: 1474975, episodes: 59000, mean episode reward: 18.161137679033885, agent episode reward: [13.39, 13.39, 13.39, -22.008862320966113], time: 130.987
mmmaddpg vs mmmaddpg steps: 1499975, episodes: 60000, mean episode reward: 18.7533458076732, agent episode reward: [12.84, 12.84, 12.84, -19.7666541923268], time: 128.365
mmmaddpg vs mmmaddpg steps: 1524975, episodes: 61000, mean episode reward: 18.848770984247395, agent episode reward: [13.07, 13.07, 13.07, -20.361229015752603], time: 125.907
mmmaddpg vs mmmaddpg steps: 1549975, episodes: 62000, mean episode reward: 20.83170244479958, agent episode reward: [13.9, 13.9, 13.9, -20.86829755520042], time: 122.141
mmmaddpg vs mmmaddpg steps: 1574975, episodes: 63000, mean episode reward: 17.596422530750637, agent episode reward: [12.48, 12.48, 12.48, -19.84357746924936], time: 130.44
mmmaddpg vs mmmaddpg steps: 1599975, episodes: 64000, mean episode reward: 13.966681967045588, agent episode reward: [11.44, 11.44, 11.44, -20.353318032954412], time: 130.611
mmmaddpg vs mmmaddpg steps: 1624975, episodes: 65000, mean episode reward: 15.449705654343214, agent episode reward: [11.85, 11.85, 11.85, -20.10029434565679], time: 128.338
mmmaddpg vs mmmaddpg steps: 1649975, episodes: 66000, mean episode reward: 18.62730188484898, agent episode reward: [12.42, 12.42, 12.42, -18.632698115151022], time: 129.396
mmmaddpg vs mmmaddpg steps: 1674975, episodes: 67000, mean episode reward: 15.812347388369165, agent episode reward: [11.96, 11.96, 11.96, -20.067652611630834], time: 126.261
mmmaddpg vs mmmaddpg steps: 1699975, episodes: 68000, mean episode reward: 19.113745950175936, agent episode reward: [12.7, 12.7, 12.7, -18.98625404982406], time: 131.092
mmmaddpg vs mmmaddpg steps: 1724975, episodes: 69000, mean episode reward: 20.69479382750448, agent episode reward: [13.44, 13.44, 13.44, -19.62520617249552], time: 132.499
mmmaddpg vs mmmaddpg steps: 1749975, episodes: 70000, mean episode reward: 17.125354163768836, agent episode reward: [12.18, 12.18, 12.18, -19.414645836231166], time: 128.67
mmmaddpg vs mmmaddpg steps: 1774975, episodes: 71000, mean episode reward: 18.451097918899503, agent episode reward: [12.51, 12.51, 12.51, -19.078902081100495], time: 123.41
mmmaddpg vs mmmaddpg steps: 1799975, episodes: 72000, mean episode reward: 16.91958449800111, agent episode reward: [12.0, 12.0, 12.0, -19.08041550199889], time: 127.326
mmmaddpg vs mmmaddpg steps: 1824975, episodes: 73000, mean episode reward: 15.452933143464989, agent episode reward: [11.62, 11.62, 11.62, -19.407066856535014], time: 129.613
mmmaddpg vs mmmaddpg steps: 1849975, episodes: 74000, mean episode reward: 19.61645408927177, agent episode reward: [12.67, 12.67, 12.67, -18.39354591072823], time: 126.873
mmmaddpg vs mmmaddpg steps: 1874975, episodes: 75000, mean episode reward: 18.75434517798185, agent episode reward: [12.73, 12.73, 12.73, -19.435654822018154], time: 129.682
mmmaddpg vs mmmaddpg steps: 1899975, episodes: 76000, mean episode reward: 20.546994750175617, agent episode reward: [13.39, 13.39, 13.39, -19.62300524982438], time: 124.91
mmmaddpg vs mmmaddpg steps: 1924975, episodes: 77000, mean episode reward: 20.102580142609828, agent episode reward: [13.21, 13.21, 13.21, -19.527419857390175], time: 125.498
mmmaddpg vs mmmaddpg steps: 1949975, episodes: 78000, mean episode reward: 20.256793341204407, agent episode reward: [13.3, 13.3, 13.3, -19.64320665879559], time: 127.453
mmmaddpg vs mmmaddpg steps: 1974975, episodes: 79000, mean episode reward: 20.944819405748287, agent episode reward: [13.64, 13.64, 13.64, -19.975180594251714], time: 129.642
mmmaddpg vs mmmaddpg steps: 1999975, episodes: 80000, mean episode reward: 19.32521609569465, agent episode reward: [12.55, 12.55, 12.55, -18.32478390430535], time: 132.259
mmmaddpg vs mmmaddpg steps: 2024975, episodes: 81000, mean episode reward: 21.00930387469306, agent episode reward: [13.48, 13.48, 13.48, -19.430696125306937], time: 130.344
mmmaddpg vs mmmaddpg steps: 2049975, episodes: 82000, mean episode reward: 20.216369485166037, agent episode reward: [13.11, 13.11, 13.11, -19.113630514833964], time: 131.336
mmmaddpg vs mmmaddpg steps: 2074975, episodes: 83000, mean episode reward: 23.096199618443062, agent episode reward: [14.82, 14.82, 14.82, -21.36380038155694], time: 130.694
mmmaddpg vs mmmaddpg steps: 2099975, episodes: 84000, mean episode reward: 14.69792950792635, agent episode reward: [11.34, 11.34, 11.34, -19.322070492073653], time: 129.447
mmmaddpg vs mmmaddpg steps: 2124975, episodes: 85000, mean episode reward: 15.912408840270892, agent episode reward: [12.16, 12.16, 12.16, -20.56759115972911], time: 133.75
mmmaddpg vs mmmaddpg steps: 2149975, episodes: 86000, mean episode reward: 18.024669766310918, agent episode reward: [12.39, 12.39, 12.39, -19.14533023368908], time: 130.534
mmmaddpg vs mmmaddpg steps: 2174975, episodes: 87000, mean episode reward: 18.88587971527638, agent episode reward: [12.89, 12.89, 12.89, -19.78412028472362], time: 130.973
mmmaddpg vs mmmaddpg steps: 2199975, episodes: 88000, mean episode reward: 18.71575579630262, agent episode reward: [12.6, 12.6, 12.6, -19.08424420369738], time: 126.895
mmmaddpg vs mmmaddpg steps: 2224975, episodes: 89000, mean episode reward: 18.905423156754722, agent episode reward: [12.3, 12.3, 12.3, -17.994576843245277], time: 129.528
mmmaddpg vs mmmaddpg steps: 2249975, episodes: 90000, mean episode reward: 19.23535626263792, agent episode reward: [12.72, 12.72, 12.72, -18.92464373736208], time: 131.318
mmmaddpg vs mmmaddpg steps: 2274975, episodes: 91000, mean episode reward: 20.269367709434984, agent episode reward: [13.22, 13.22, 13.22, -19.390632290565016], time: 129.948
mmmaddpg vs mmmaddpg steps: 2299975, episodes: 92000, mean episode reward: 17.58413429883602, agent episode reward: [12.55, 12.55, 12.55, -20.065865701163975], time: 131.122
mmmaddpg vs mmmaddpg steps: 2324975, episodes: 93000, mean episode reward: 20.304282474175604, agent episode reward: [13.68, 13.68, 13.68, -20.735717525824395], time: 131.916
mmmaddpg vs mmmaddpg steps: 2349975, episodes: 94000, mean episode reward: 19.014427682947, agent episode reward: [12.92, 12.92, 12.92, -19.745572317052996], time: 133.496
mmmaddpg vs mmmaddpg steps: 2374975, episodes: 95000, mean episode reward: 20.585158819303892, agent episode reward: [13.46, 13.46, 13.46, -19.794841180696107], time: 127.389
mmmaddpg vs mmmaddpg steps: 2399975, episodes: 96000, mean episode reward: 18.66294431136574, agent episode reward: [13.06, 13.06, 13.06, -20.51705568863426], time: 128.212
mmmaddpg vs mmmaddpg steps: 2424975, episodes: 97000, mean episode reward: 17.911391102454697, agent episode reward: [12.41, 12.41, 12.41, -19.318608897545303], time: 129.073
mmmaddpg vs mmmaddpg steps: 2449975, episodes: 98000, mean episode reward: 15.82579753433469, agent episode reward: [11.64, 11.64, 11.64, -19.09420246566531], time: 130.441
mmmaddpg vs mmmaddpg steps: 2474975, episodes: 99000, mean episode reward: 19.401182107580507, agent episode reward: [12.95, 12.95, 12.95, -19.448817892419495], time: 131.62
mmmaddpg vs mmmaddpg steps: 2499975, episodes: 100000, mean episode reward: 16.265475408536883, agent episode reward: [12.55, 12.55, 12.55, -21.384524591463116], time: 127.577
...Finished total of 100001 episodes.
