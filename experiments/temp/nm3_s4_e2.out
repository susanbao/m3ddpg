0 bad agents
      adv rate for q_index :  0 [1e-05, 0.001, 0.001]
      adv rate for p_index :  0 [1e-05, 0.001, 0.001]
1 good agents
      adv rate for q_index :  1 [0.001, 1e-05, 1e-05]
      adv rate for p_index :  1 [0.001, 1e-05, 1e-05]
2 good agents
      adv rate for q_index :  2 [0.001, 1e-05, 1e-05]
      adv rate for p_index :  2 [0.001, 1e-05, 1e-05]
Using good policy mmmaddpg and bad policy mmmaddpg with 1 adversaries
Starting iterations...
mmmaddpg vs mmmaddpg steps: 24975, episodes: 1000, mean episode reward: -22.60594165943136, agent episode reward: [-34.92211519887707, 6.158086769722855, 6.158086769722855], time: 104.152
mmmaddpg vs mmmaddpg steps: 49975, episodes: 2000, mean episode reward: -19.518123828161308, agent episode reward: [-33.302918704169294, 6.892397438003992, 6.892397438003992], time: 128.554
mmmaddpg vs mmmaddpg steps: 74975, episodes: 3000, mean episode reward: 4.8808773434610195, agent episode reward: [-10.188174227998747, 7.534525785729883, 7.534525785729883], time: 123.949
mmmaddpg vs mmmaddpg steps: 99975, episodes: 4000, mean episode reward: 4.177805203572638, agent episode reward: [-8.99226684501259, 6.585036024292615, 6.585036024292615], time: 126.514
mmmaddpg vs mmmaddpg steps: 124975, episodes: 5000, mean episode reward: 3.7138611850434127, agent episode reward: [-10.22206244286888, 6.967961813956145, 6.967961813956145], time: 121.72
mmmaddpg vs mmmaddpg steps: 149975, episodes: 6000, mean episode reward: 4.199101638250266, agent episode reward: [-10.62381914633602, 7.411460392293144, 7.411460392293144], time: 122.826
mmmaddpg vs mmmaddpg steps: 174975, episodes: 7000, mean episode reward: 4.008048996959925, agent episode reward: [-10.788896749209531, 7.398472873084729, 7.398472873084729], time: 125.35
mmmaddpg vs mmmaddpg steps: 199975, episodes: 8000, mean episode reward: 3.6189056980857788, agent episode reward: [-10.877037068802538, 7.247971383444158, 7.247971383444158], time: 124.368
mmmaddpg vs mmmaddpg steps: 224975, episodes: 9000, mean episode reward: 2.9509683411943146, agent episode reward: [-11.422295447955117, 7.186631894574715, 7.186631894574715], time: 122.648
mmmaddpg vs mmmaddpg steps: 249975, episodes: 10000, mean episode reward: 3.3665548379581556, agent episode reward: [-11.090817907916737, 7.228686372937446, 7.228686372937446], time: 124.029
mmmaddpg vs mmmaddpg steps: 274975, episodes: 11000, mean episode reward: 2.5828751676846666, agent episode reward: [-11.651841275332462, 7.117358221508565, 7.117358221508565], time: 124.36
mmmaddpg vs mmmaddpg steps: 299975, episodes: 12000, mean episode reward: 2.341206536556842, agent episode reward: [-11.387856528173034, 6.864531532364937, 6.864531532364937], time: 124.403
mmmaddpg vs mmmaddpg steps: 324975, episodes: 13000, mean episode reward: 2.2686776050423996, agent episode reward: [-10.96979082257995, 6.6192342138111755, 6.6192342138111755], time: 124.964
mmmaddpg vs mmmaddpg steps: 349975, episodes: 14000, mean episode reward: 2.4158695059061976, agent episode reward: [-11.543954776163602, 6.979912141034901, 6.979912141034901], time: 123.346
mmmaddpg vs mmmaddpg steps: 374975, episodes: 15000, mean episode reward: 1.5491713179169644, agent episode reward: [-12.048933602345441, 6.799052460131203, 6.799052460131203], time: 124.689
mmmaddpg vs mmmaddpg steps: 399975, episodes: 16000, mean episode reward: 1.6265276999397729, agent episode reward: [-11.43729419680043, 6.531910948370101, 6.531910948370101], time: 123.725
mmmaddpg vs mmmaddpg steps: 424975, episodes: 17000, mean episode reward: 1.3041998696872183, agent episode reward: [-11.694074249208322, 6.49913705944777, 6.49913705944777], time: 124.125
mmmaddpg vs mmmaddpg steps: 449975, episodes: 18000, mean episode reward: 1.7891402734254769, agent episode reward: [-12.010278974859409, 6.899709624142443, 6.899709624142443], time: 123.217
mmmaddpg vs mmmaddpg steps: 474975, episodes: 19000, mean episode reward: 1.7922631269722442, agent episode reward: [-12.240809019882578, 7.016536073427411, 7.016536073427411], time: 123.477
mmmaddpg vs mmmaddpg steps: 499975, episodes: 20000, mean episode reward: 1.8835081646994658, agent episode reward: [-12.747773726291582, 7.315640945495524, 7.315640945495524], time: 123.202
mmmaddpg vs mmmaddpg steps: 524975, episodes: 21000, mean episode reward: 1.883149068809621, agent episode reward: [-11.768643139200329, 6.8258961040049755, 6.8258961040049755], time: 125.596
mmmaddpg vs mmmaddpg steps: 549975, episodes: 22000, mean episode reward: 2.8265948790643023, agent episode reward: [-12.75910598075635, 7.792850429910326, 7.792850429910326], time: 124.2
mmmaddpg vs mmmaddpg steps: 574975, episodes: 23000, mean episode reward: 2.111593955974907, agent episode reward: [-11.825379981313633, 6.968486968644269, 6.968486968644269], time: 125.727
mmmaddpg vs mmmaddpg steps: 599975, episodes: 24000, mean episode reward: 2.2040551771178007, agent episode reward: [-12.267588933788211, 7.2358220554530055, 7.2358220554530055], time: 125.162
mmmaddpg vs mmmaddpg steps: 624975, episodes: 25000, mean episode reward: 3.046409623227058, agent episode reward: [-12.150563258327479, 7.598486440777268, 7.598486440777268], time: 125.408
mmmaddpg vs mmmaddpg steps: 649975, episodes: 26000, mean episode reward: 3.206035962300377, agent episode reward: [-12.654716065125907, 7.9303760137131425, 7.9303760137131425], time: 125.188
mmmaddpg vs mmmaddpg steps: 674975, episodes: 27000, mean episode reward: 3.017234996475019, agent episode reward: [-12.641944244402305, 7.829589620438661, 7.829589620438661], time: 124.224
mmmaddpg vs mmmaddpg steps: 699975, episodes: 28000, mean episode reward: 2.9808836837103607, agent episode reward: [-12.452785343710005, 7.716834513710184, 7.716834513710184], time: 123.85
mmmaddpg vs mmmaddpg steps: 724975, episodes: 29000, mean episode reward: 3.026933864424629, agent episode reward: [-12.60357353568613, 7.815253700055378, 7.815253700055378], time: 124.887
mmmaddpg vs mmmaddpg steps: 749975, episodes: 30000, mean episode reward: 2.960215322574108, agent episode reward: [-13.055347941308163, 8.007781631941135, 8.007781631941135], time: 123.951
mmmaddpg vs mmmaddpg steps: 774975, episodes: 31000, mean episode reward: 3.007413734113498, agent episode reward: [-13.16222854295393, 8.084821138533714, 8.084821138533714], time: 123.68
mmmaddpg vs mmmaddpg steps: 799975, episodes: 32000, mean episode reward: 3.654886640696015, agent episode reward: [-13.046467698388383, 8.350677169542202, 8.350677169542202], time: 123.709
mmmaddpg vs mmmaddpg steps: 824975, episodes: 33000, mean episode reward: 2.951941815309402, agent episode reward: [-13.238752906033527, 8.095347360671465, 8.095347360671465], time: 124.167
mmmaddpg vs mmmaddpg steps: 849975, episodes: 34000, mean episode reward: 3.8239790415407633, agent episode reward: [-12.62560014689147, 8.224789594216118, 8.224789594216118], time: 123.211
mmmaddpg vs mmmaddpg steps: 874975, episodes: 35000, mean episode reward: 4.055966040853159, agent episode reward: [-12.842547777670207, 8.449256909261683, 8.449256909261683], time: 123.691
mmmaddpg vs mmmaddpg steps: 899975, episodes: 36000, mean episode reward: 3.8560475248950823, agent episode reward: [-12.939130164092596, 8.39758884449384, 8.39758884449384], time: 126.382
mmmaddpg vs mmmaddpg steps: 924975, episodes: 37000, mean episode reward: 3.869657664269177, agent episode reward: [-13.323111886748546, 8.596384775508861, 8.596384775508861], time: 125.233
mmmaddpg vs mmmaddpg steps: 949975, episodes: 38000, mean episode reward: 4.196459605299948, agent episode reward: [-12.973013279346107, 8.584736442323027, 8.584736442323027], time: 122.802
mmmaddpg vs mmmaddpg steps: 974975, episodes: 39000, mean episode reward: 4.4674557928055565, agent episode reward: [-12.856035406260617, 8.661745599533086, 8.661745599533086], time: 123.185
mmmaddpg vs mmmaddpg steps: 999975, episodes: 40000, mean episode reward: 5.045040533826905, agent episode reward: [-13.35619625778998, 9.200618395808442, 9.200618395808442], time: 125.761
mmmaddpg vs mmmaddpg steps: 1024975, episodes: 41000, mean episode reward: 4.377683011419624, agent episode reward: [-13.229322421240848, 8.803502716330236, 8.803502716330236], time: 126.286
mmmaddpg vs mmmaddpg steps: 1049975, episodes: 42000, mean episode reward: 4.479587239088266, agent episode reward: [-13.62446488389657, 9.052026061492418, 9.052026061492418], time: 125.146
mmmaddpg vs mmmaddpg steps: 1074975, episodes: 43000, mean episode reward: 4.8197537702546525, agent episode reward: [-13.00470910650448, 8.912231438379568, 8.912231438379568], time: 126.142
mmmaddpg vs mmmaddpg steps: 1099975, episodes: 44000, mean episode reward: 4.838120399378194, agent episode reward: [-13.101965476863837, 8.970042938121017, 8.970042938121017], time: 127.1
mmmaddpg vs mmmaddpg steps: 1124975, episodes: 45000, mean episode reward: 4.988205269454745, agent episode reward: [-13.222224203955582, 9.105214736705163, 9.105214736705163], time: 126.03
mmmaddpg vs mmmaddpg steps: 1149975, episodes: 46000, mean episode reward: 4.9508440434418155, agent episode reward: [-12.179642104680344, 8.56524307406108, 8.56524307406108], time: 125.2
mmmaddpg vs mmmaddpg steps: 1174975, episodes: 47000, mean episode reward: 4.508884702827607, agent episode reward: [-13.558550467357374, 9.033717585092491, 9.033717585092491], time: 127.018
mmmaddpg vs mmmaddpg steps: 1199975, episodes: 48000, mean episode reward: 4.443744939208552, agent episode reward: [-13.199664429193035, 8.821704684200794, 8.821704684200794], time: 126.197
mmmaddpg vs mmmaddpg steps: 1224975, episodes: 49000, mean episode reward: 5.077143431434155, agent episode reward: [-13.221685722265773, 9.149414576849964, 9.149414576849964], time: 125.111
mmmaddpg vs mmmaddpg steps: 1249975, episodes: 50000, mean episode reward: 4.614200788015989, agent episode reward: [-12.819470198513608, 8.716835493264798, 8.716835493264798], time: 125.097
mmmaddpg vs mmmaddpg steps: 1274975, episodes: 51000, mean episode reward: 4.134391409340874, agent episode reward: [-13.22121180515576, 8.677801607248316, 8.677801607248316], time: 125.655
mmmaddpg vs mmmaddpg steps: 1299975, episodes: 52000, mean episode reward: 4.058932363666646, agent episode reward: [-13.48243637230527, 8.770684367985956, 8.770684367985956], time: 127.278
mmmaddpg vs mmmaddpg steps: 1324975, episodes: 53000, mean episode reward: 3.4902634339951, agent episode reward: [-12.986272439127518, 8.23826793656131, 8.23826793656131], time: 126.36
mmmaddpg vs mmmaddpg steps: 1349975, episodes: 54000, mean episode reward: 3.8963430476837813, agent episode reward: [-13.18099182062745, 8.538667434155615, 8.538667434155615], time: 125.77
mmmaddpg vs mmmaddpg steps: 1374975, episodes: 55000, mean episode reward: 4.251736484452466, agent episode reward: [-13.252932296322214, 8.75233439038734, 8.75233439038734], time: 126.568
mmmaddpg vs mmmaddpg steps: 1399975, episodes: 56000, mean episode reward: 4.4040996623170745, agent episode reward: [-13.672934794011766, 9.038517228164421, 9.038517228164421], time: 127.208
mmmaddpg vs mmmaddpg steps: 1424975, episodes: 57000, mean episode reward: 3.945944909452565, agent episode reward: [-13.682255521439107, 8.814100215445837, 8.814100215445837], time: 125.788
mmmaddpg vs mmmaddpg steps: 1449975, episodes: 58000, mean episode reward: 4.276217580131125, agent episode reward: [-13.666620926890976, 8.971419253511053, 8.971419253511053], time: 124.732
mmmaddpg vs mmmaddpg steps: 1474975, episodes: 59000, mean episode reward: 4.6022568444126755, agent episode reward: [-13.683669821153703, 9.142963332783191, 9.142963332783191], time: 125.603
mmmaddpg vs mmmaddpg steps: 1499975, episodes: 60000, mean episode reward: 4.70756240271272, agent episode reward: [-13.07075067747528, 8.889156540094001, 8.889156540094001], time: 125.721
mmmaddpg vs mmmaddpg steps: 1524975, episodes: 61000, mean episode reward: 4.597683895212716, agent episode reward: [-13.739007596950305, 9.16834574608151, 9.16834574608151], time: 126.704
mmmaddpg vs mmmaddpg steps: 1549975, episodes: 62000, mean episode reward: 4.292631393790878, agent episode reward: [-13.705974875069707, 8.999303134430292, 8.999303134430292], time: 125.411
mmmaddpg vs mmmaddpg steps: 1574975, episodes: 63000, mean episode reward: 4.176798976650494, agent episode reward: [-13.485812759644165, 8.83130586814733, 8.83130586814733], time: 127.696
mmmaddpg vs mmmaddpg steps: 1599975, episodes: 64000, mean episode reward: 4.011537893038905, agent episode reward: [-13.355905305232353, 8.68372159913563, 8.68372159913563], time: 126.876
mmmaddpg vs mmmaddpg steps: 1624975, episodes: 65000, mean episode reward: 3.967468183986114, agent episode reward: [-13.338193582316508, 8.65283088315131, 8.65283088315131], time: 108.694
mmmaddpg vs mmmaddpg steps: 1649975, episodes: 66000, mean episode reward: 3.91562090184575, agent episode reward: [-13.68015985545305, 8.7978903786494, 8.7978903786494], time: 96.763
mmmaddpg vs mmmaddpg steps: 1674975, episodes: 67000, mean episode reward: 3.590339133455378, agent episode reward: [-13.67561192372996, 8.63297552859267, 8.63297552859267], time: 98.725
mmmaddpg vs mmmaddpg steps: 1699975, episodes: 68000, mean episode reward: 4.025246203961614, agent episode reward: [-13.522569752977764, 8.77390797846969, 8.77390797846969], time: 96.714
mmmaddpg vs mmmaddpg steps: 1724975, episodes: 69000, mean episode reward: 3.8068103063317786, agent episode reward: [-13.856050291101859, 8.831430298716818, 8.831430298716818], time: 99.897
mmmaddpg vs mmmaddpg steps: 1749975, episodes: 70000, mean episode reward: 3.6116727618024123, agent episode reward: [-13.457132104716539, 8.534402433259475, 8.534402433259475], time: 97.224
mmmaddpg vs mmmaddpg steps: 1774975, episodes: 71000, mean episode reward: 3.617676363943565, agent episode reward: [-13.46760538243005, 8.542640873186807, 8.542640873186807], time: 97.375
mmmaddpg vs mmmaddpg steps: 1799975, episodes: 72000, mean episode reward: 3.10790593699459, agent episode reward: [-13.146254220836822, 8.127080078915705, 8.127080078915705], time: 96.761
mmmaddpg vs mmmaddpg steps: 1824975, episodes: 73000, mean episode reward: 3.66886744456432, agent episode reward: [-13.793384008127118, 8.73112572634572, 8.73112572634572], time: 96.398
mmmaddpg vs mmmaddpg steps: 1849975, episodes: 74000, mean episode reward: 3.6566697745876424, agent episode reward: [-13.956542917739322, 8.806606346163484, 8.806606346163484], time: 96.21
mmmaddpg vs mmmaddpg steps: 1874975, episodes: 75000, mean episode reward: 3.3694821886189428, agent episode reward: [-13.32581640311991, 8.347649295869426, 8.347649295869426], time: 96.288
mmmaddpg vs mmmaddpg steps: 1899975, episodes: 76000, mean episode reward: 3.2305889638468654, agent episode reward: [-13.238804400059456, 8.23469668195316, 8.23469668195316], time: 96.419
mmmaddpg vs mmmaddpg steps: 1924975, episodes: 77000, mean episode reward: 2.8774019669621103, agent episode reward: [-13.229795276102983, 8.053598621532547, 8.053598621532547], time: 96.374
mmmaddpg vs mmmaddpg steps: 1949975, episodes: 78000, mean episode reward: 3.011888428769704, agent episode reward: [-13.475540245115607, 8.243714336942656, 8.243714336942656], time: 97.123
mmmaddpg vs mmmaddpg steps: 1974975, episodes: 79000, mean episode reward: 2.998955842645906, agent episode reward: [-13.368265389693345, 8.183610616169624, 8.183610616169624], time: 95.789
mmmaddpg vs mmmaddpg steps: 1999975, episodes: 80000, mean episode reward: 2.9674274019901894, agent episode reward: [-13.623383224175955, 8.295405313083071, 8.295405313083071], time: 97.398
mmmaddpg vs mmmaddpg steps: 2024975, episodes: 81000, mean episode reward: 3.5841960597654596, agent episode reward: [-13.66943924782064, 8.626817653793049, 8.626817653793049], time: 98.438
mmmaddpg vs mmmaddpg steps: 2049975, episodes: 82000, mean episode reward: 3.590200874939763, agent episode reward: [-14.252464215964743, 8.921332545452254, 8.921332545452254], time: 98.895
mmmaddpg vs mmmaddpg steps: 2074975, episodes: 83000, mean episode reward: 3.8160144567572702, agent episode reward: [-13.403229005796872, 8.609621731277072, 8.609621731277072], time: 96.2
mmmaddpg vs mmmaddpg steps: 2099975, episodes: 84000, mean episode reward: 3.6477962792943783, agent episode reward: [-13.836648145139566, 8.742222212216973, 8.742222212216973], time: 96.501
mmmaddpg vs mmmaddpg steps: 2124975, episodes: 85000, mean episode reward: 3.870463144425774, agent episode reward: [-13.40943602153055, 8.639949582978163, 8.639949582978163], time: 97.893
mmmaddpg vs mmmaddpg steps: 2149975, episodes: 86000, mean episode reward: 3.9237728153511444, agent episode reward: [-13.65961588645923, 8.791694350905189, 8.791694350905189], time: 96.575
mmmaddpg vs mmmaddpg steps: 2174975, episodes: 87000, mean episode reward: 4.434424580366377, agent episode reward: [-13.504738644850512, 8.969581612608447, 8.969581612608447], time: 96.4
mmmaddpg vs mmmaddpg steps: 2199975, episodes: 88000, mean episode reward: 4.725554737397386, agent episode reward: [-13.912673837479256, 9.31911428743832, 9.31911428743832], time: 98.957
mmmaddpg vs mmmaddpg steps: 2224975, episodes: 89000, mean episode reward: 4.7037074139393, agent episode reward: [-13.909508042061287, 9.306607728000294, 9.306607728000294], time: 99.211
mmmaddpg vs mmmaddpg steps: 2249975, episodes: 90000, mean episode reward: 5.076448725171585, agent episode reward: [-14.404279691744163, 9.740364208457875, 9.740364208457875], time: 101.787
mmmaddpg vs mmmaddpg steps: 2274975, episodes: 91000, mean episode reward: 4.608582003091367, agent episode reward: [-13.905958801266694, 9.25727040217903, 9.25727040217903], time: 100.527
mmmaddpg vs mmmaddpg steps: 2299975, episodes: 92000, mean episode reward: 4.852721123384274, agent episode reward: [-13.483939350558577, 9.168330236971425, 9.168330236971425], time: 97.318
mmmaddpg vs mmmaddpg steps: 2324975, episodes: 93000, mean episode reward: 4.553639206725189, agent episode reward: [-14.125144456484344, 9.339391831604768, 9.339391831604768], time: 95.78
mmmaddpg vs mmmaddpg steps: 2349975, episodes: 94000, mean episode reward: 4.909859087851336, agent episode reward: [-14.11568133613011, 9.512770211990723, 9.512770211990723], time: 97.734
mmmaddpg vs mmmaddpg steps: 2374975, episodes: 95000, mean episode reward: 4.305852099209026, agent episode reward: [-13.302245721464896, 8.80404891033696, 8.80404891033696], time: 98.825
mmmaddpg vs mmmaddpg steps: 2399975, episodes: 96000, mean episode reward: 3.8727275045555154, agent episode reward: [-12.844212941251975, 8.358470222903742, 8.358470222903742], time: 97.358
mmmaddpg vs mmmaddpg steps: 2424975, episodes: 97000, mean episode reward: 4.138860845998791, agent episode reward: [-13.657643924027976, 8.898252385013382, 8.898252385013382], time: 98.754
mmmaddpg vs mmmaddpg steps: 2449975, episodes: 98000, mean episode reward: 4.185198939234424, agent episode reward: [-12.92894571661385, 8.557072327924137, 8.557072327924137], time: 98.585
mmmaddpg vs mmmaddpg steps: 2474975, episodes: 99000, mean episode reward: 3.7046549003012195, agent episode reward: [-12.78108075169357, 8.242867825997395, 8.242867825997395], time: 98.197
mmmaddpg vs mmmaddpg steps: 2499975, episodes: 100000, mean episode reward: 3.895264784790498, agent episode reward: [-13.20889475981421, 8.552079772302354, 8.552079772302354], time: 97.691
...Finished total of 100001 episodes.
