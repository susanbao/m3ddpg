0 bad agents
      adv rate for q_index :  0 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
      adv rate for p_index :  0 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
1 bad agents
      adv rate for q_index :  1 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
      adv rate for p_index :  1 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
2 bad agents
      adv rate for q_index :  2 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
      adv rate for p_index :  2 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
3 bad agents
      adv rate for q_index :  3 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
      adv rate for p_index :  3 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
4 good agents
      adv rate for q_index :  4 [0.001, 0.001, 0.001, 0.001, 1e-05, 1e-05]
      adv rate for p_index :  4 [0.001, 0.001, 0.001, 0.001, 1e-05, 1e-05]
5 good agents
      adv rate for q_index :  5 [0.001, 0.001, 0.001, 0.001, 1e-05, 1e-05]
      adv rate for p_index :  5 [0.001, 0.001, 0.001, 0.001, 1e-05, 1e-05]
Using good policy mmmaddpg and bad policy mmmaddpg with 4 adversaries
Starting iterations...
mmmaddpg vs mmmaddpg steps: 24975, episodes: 1000, mean episode reward: -27.12154900073992, agent episode reward: [1.1338773534531947, 1.1157169937841644, 1.0696110376170453, 0.9970908350280888, -19.30293110900711, -12.134914111615304], time: 156.559
mmmaddpg vs mmmaddpg steps: 49975, episodes: 2000, mean episode reward: -43.64599171949948, agent episode reward: [2.6297492469820747, 2.806739225939178, 2.9802106287871073, 2.3496889434872337, -32.9948622587432, -21.417517505951867], time: 207.756
mmmaddpg vs mmmaddpg steps: 74975, episodes: 3000, mean episode reward: 19.624387868361126, agent episode reward: [6.269158582977672, 6.5716011903658105, 6.40496031352701, 6.347515120747755, -3.2702287721509316, -2.698618567106195], time: 203.217
mmmaddpg vs mmmaddpg steps: 99975, episodes: 4000, mean episode reward: 21.481645992145534, agent episode reward: [6.990906716601789, 7.2552142276232265, 6.736542434545759, 7.090474435960466, -3.5834787692861108, -3.0080130532995972], time: 203.178
mmmaddpg vs mmmaddpg steps: 124975, episodes: 5000, mean episode reward: 26.973279569079807, agent episode reward: [9.142770114887975, 9.02226194159779, 8.367946677323067, 9.152517218288798, -4.692630078178662, -4.0195863048391605], time: 201.116
mmmaddpg vs mmmaddpg steps: 149975, episodes: 6000, mean episode reward: 32.75094747100686, agent episode reward: [11.11189588900673, 10.754353748232624, 10.458846201311939, 10.859598399442966, -5.35082954947001, -5.082917217517388], time: 195.532
mmmaddpg vs mmmaddpg steps: 174975, episodes: 7000, mean episode reward: 33.906791182125076, agent episode reward: [11.34812314415172, 11.057647857332086, 10.895427187874661, 11.188335906853691, -6.190427487620917, -4.392315426466169], time: 203.802
mmmaddpg vs mmmaddpg steps: 199975, episodes: 8000, mean episode reward: 33.95103700565753, agent episode reward: [11.316276710640564, 11.211776178155747, 11.060883794351366, 11.278915897437454, -6.7165272255154065, -4.200288349412187], time: 205.342
mmmaddpg vs mmmaddpg steps: 224975, episodes: 9000, mean episode reward: 27.48169209784817, agent episode reward: [9.25591497166664, 9.242740020845035, 9.03813901632504, 9.28589015942124, -4.951647218532433, -4.389344851877351], time: 197.185
mmmaddpg vs mmmaddpg steps: 249975, episodes: 10000, mean episode reward: 30.01745065135067, agent episode reward: [10.170646424972093, 10.231412326410807, 10.07173031166515, 10.251489124032549, -6.121725320977013, -4.586102214752913], time: 198.36
mmmaddpg vs mmmaddpg steps: 274975, episodes: 11000, mean episode reward: 28.31154277168747, agent episode reward: [9.819979888492332, 9.861970624111779, 9.78364468185276, 9.913265750697882, -5.962948376410593, -5.10436979705669], time: 199.2
mmmaddpg vs mmmaddpg steps: 299975, episodes: 12000, mean episode reward: 21.773496993693584, agent episode reward: [7.905364825232721, 7.9199307433112285, 7.81260105170254, 7.943488836731982, -5.90544294724219, -3.9024455160426967], time: 200.396
mmmaddpg vs mmmaddpg steps: 324975, episodes: 13000, mean episode reward: 22.850413835052137, agent episode reward: [8.399317335034358, 8.39075562339525, 8.357597125339828, 8.489685839192527, -6.812543947040125, -3.974398140869698], time: 200.9
mmmaddpg vs mmmaddpg steps: 349975, episodes: 14000, mean episode reward: 23.79730561156945, agent episode reward: [8.944966862049984, 8.9341546212238, 8.902665743527992, 9.007872759930116, -7.246637613046498, -4.7457167621159515], time: 200.578
mmmaddpg vs mmmaddpg steps: 374975, episodes: 15000, mean episode reward: 21.181639346338667, agent episode reward: [7.7500038040678, 7.694671252443173, 7.704449340976735, 7.859878455320757, -5.000452353684026, -4.826911152785772], time: 196.93
mmmaddpg vs mmmaddpg steps: 399975, episodes: 16000, mean episode reward: 20.46583100884132, agent episode reward: [7.3306667431722765, 7.333184405705863, 7.303968952832133, 7.4847168300918705, -4.690683470418281, -4.296022452542543], time: 192.804
mmmaddpg vs mmmaddpg steps: 424975, episodes: 17000, mean episode reward: 21.173031594919276, agent episode reward: [7.619589745221953, 7.655007656813217, 7.6892395538645575, 7.896613896542932, -4.375877709448235, -5.311541548075145], time: 195.878
mmmaddpg vs mmmaddpg steps: 449975, episodes: 18000, mean episode reward: 21.600094093976615, agent episode reward: [7.571189734490153, 7.550072147044712, 7.52257563402137, 7.735980650844704, -4.122893213539814, -4.656830858884512], time: 199.838
mmmaddpg vs mmmaddpg steps: 474975, episodes: 19000, mean episode reward: 20.635538763278205, agent episode reward: [7.394552022881483, 7.469222230692719, 7.497471579095167, 7.575941409111533, -4.3530699089463925, -4.9485785695563065], time: 202.029
mmmaddpg vs mmmaddpg steps: 499975, episodes: 20000, mean episode reward: 22.18842889376605, agent episode reward: [7.542537927972186, 7.680149517155526, 7.595870337482082, 7.647773198796731, -4.193178769509615, -4.084723318130854], time: 201.627
mmmaddpg vs mmmaddpg steps: 524975, episodes: 21000, mean episode reward: 20.641814180588167, agent episode reward: [6.956565548650335, 7.071134783193387, 6.942869400980566, 7.000535971754512, -3.8648478651569222, -3.464443658833712], time: 205.817
mmmaddpg vs mmmaddpg steps: 549975, episodes: 22000, mean episode reward: 19.950988470828815, agent episode reward: [6.843312510092422, 6.974229155329536, 6.900926103629004, 6.900837724960085, -3.894637728243539, -3.7736792949386944], time: 205.365
mmmaddpg vs mmmaddpg steps: 574975, episodes: 23000, mean episode reward: 21.025141951297496, agent episode reward: [7.172235332213298, 7.341970706308159, 7.263929174315645, 7.288586211741138, -3.8632518769611432, -4.178327596319603], time: 198.777
mmmaddpg vs mmmaddpg steps: 599975, episodes: 24000, mean episode reward: 19.135753237431963, agent episode reward: [6.239633925770162, 6.438542954831335, 6.377387197570693, 6.35827594907592, -3.3388788509508824, -2.9392079388652665], time: 205.051
mmmaddpg vs mmmaddpg steps: 624975, episodes: 25000, mean episode reward: 17.081971873412776, agent episode reward: [5.79584372455865, 5.975268170442906, 5.915576853626583, 5.930270494737466, -3.274431407220338, -3.260555962732493], time: 208.612
mmmaddpg vs mmmaddpg steps: 649975, episodes: 26000, mean episode reward: 17.182164917305034, agent episode reward: [5.908900268192825, 6.157470471709192, 6.107209349896811, 6.208346810553777, -3.9302107202288883, -3.269551262818679], time: 201.074
mmmaddpg vs mmmaddpg steps: 674975, episodes: 27000, mean episode reward: 15.42491943506049, agent episode reward: [5.367262303376702, 5.693748847558706, 5.590351268443774, 5.744873458255451, -3.9577200986151917, -3.0135963439589495], time: 204.195
mmmaddpg vs mmmaddpg steps: 699975, episodes: 28000, mean episode reward: 15.557155811662208, agent episode reward: [5.367398904213782, 5.746658332706775, 5.630888456785497, 5.75460719134036, -3.6963498408033413, -3.2460472325808634], time: 199.844
mmmaddpg vs mmmaddpg steps: 724975, episodes: 29000, mean episode reward: 12.31644809521912, agent episode reward: [4.2686240895345, 4.718920834540333, 4.630347224925808, 4.747757139866298, -3.166895372830787, -2.8823058208170287], time: 204.444
mmmaddpg vs mmmaddpg steps: 749975, episodes: 30000, mean episode reward: 12.316143310126705, agent episode reward: [4.321539350523143, 4.995416589010987, 4.798323623900085, 5.003162863860531, -3.394867868739142, -3.4074312484289013], time: 204.411
mmmaddpg vs mmmaddpg steps: 774975, episodes: 31000, mean episode reward: 9.90337515499096, agent episode reward: [3.5853982922790353, 4.400529225558717, 4.239129520772638, 4.483265737634095, -2.297797255794934, -4.507150365458594], time: 204.529
mmmaddpg vs mmmaddpg steps: 799975, episodes: 32000, mean episode reward: 11.187165595176495, agent episode reward: [3.6168150400110304, 4.730232581404527, 4.480933488144659, 4.717825541340981, -2.4097885066095985, -3.948852549115103], time: 205.072
mmmaddpg vs mmmaddpg steps: 824975, episodes: 33000, mean episode reward: 13.859795181759704, agent episode reward: [4.141259310848035, 5.37450293071598, 5.208373370860615, 5.318585369635874, -2.6188330782701694, -3.564092722030631], time: 203.381
mmmaddpg vs mmmaddpg steps: 849975, episodes: 34000, mean episode reward: 15.902544249597405, agent episode reward: [4.70017127067121, 5.942895952057322, 5.954365212090914, 5.910756557201673, -3.4024843089053, -3.2031604335184136], time: 204.299
mmmaddpg vs mmmaddpg steps: 874975, episodes: 35000, mean episode reward: 16.490280522841392, agent episode reward: [4.88089367559532, 6.293395669509843, 6.325891005970612, 6.294242979660734, -4.054085383967186, -3.250057423927933], time: 200.065
mmmaddpg vs mmmaddpg steps: 899975, episodes: 36000, mean episode reward: 15.753478100513087, agent episode reward: [4.705384374200368, 6.127461602435076, 6.108769879158542, 6.112155940361298, -4.087160169442517, -3.2131335261996807], time: 198.329
mmmaddpg vs mmmaddpg steps: 924975, episodes: 37000, mean episode reward: 15.53278842240468, agent episode reward: [4.429409105525934, 5.781371346098968, 5.79132421228058, 5.904879609914673, -3.775115498356245, -2.5990803530592292], time: 199.541
mmmaddpg vs mmmaddpg steps: 949975, episodes: 38000, mean episode reward: 18.235337936177746, agent episode reward: [5.440528242296605, 6.808889327193413, 6.780905699497614, 6.935541707540814, -4.592318556217457, -3.1382084841332403], time: 200.707
mmmaddpg vs mmmaddpg steps: 974975, episodes: 39000, mean episode reward: 17.206339504381596, agent episode reward: [5.097054824952864, 6.427914895475471, 6.3786060908054045, 6.600165383130081, -4.0718137359196565, -3.2255879540625725], time: 204.047
mmmaddpg vs mmmaddpg steps: 999975, episodes: 40000, mean episode reward: 17.069459328094883, agent episode reward: [4.989654231316797, 6.235259878430624, 6.121455338721495, 6.260003941686777, -3.7447591658404145, -2.792154896220396], time: 202.246
mmmaddpg vs mmmaddpg steps: 1024975, episodes: 41000, mean episode reward: 17.56608092605305, agent episode reward: [5.4388241422257035, 6.657031162577291, 6.5838025298957, 6.709419304853624, -4.285878758186938, -3.5371174553123277], time: 199.507
mmmaddpg vs mmmaddpg steps: 1049975, episodes: 42000, mean episode reward: 16.51666433934763, agent episode reward: [5.00471341338278, 5.804349054520957, 5.7316649140543205, 5.902564371966288, -3.1717877987502394, -2.7548396158264747], time: 196.838
mmmaddpg vs mmmaddpg steps: 1074975, episodes: 43000, mean episode reward: 21.68536935259722, agent episode reward: [6.623207455065556, 7.457006861305819, 7.3386186150644095, 7.493432534661764, -3.581355400913221, -3.645540712587106], time: 196.796
mmmaddpg vs mmmaddpg steps: 1099975, episodes: 44000, mean episode reward: 24.21435645961985, agent episode reward: [7.6513214459954995, 8.110456751327844, 8.102804625057832, 8.261666901578446, -3.9501082475075693, -3.9617850168322093], time: 203.56
mmmaddpg vs mmmaddpg steps: 1124975, episodes: 45000, mean episode reward: 26.00441951488053, agent episode reward: [8.494314500266453, 8.75913767174517, 8.72840742597639, 8.842814048276923, -4.240225900212084, -4.580028231172319], time: 199.097
mmmaddpg vs mmmaddpg steps: 1149975, episodes: 46000, mean episode reward: 27.751869295133975, agent episode reward: [9.070846271170337, 9.234776460521406, 9.280190563316687, 9.509713936554377, -4.677422518662849, -4.666235417765982], time: 205.613
mmmaddpg vs mmmaddpg steps: 1174975, episodes: 47000, mean episode reward: 31.66520441033227, agent episode reward: [10.513252759765775, 10.614070288263273, 10.609623683458896, 10.86246164594004, -4.676032849682915, -6.258171117412803], time: 202.664
mmmaddpg vs mmmaddpg steps: 1199975, episodes: 48000, mean episode reward: 32.914435451148385, agent episode reward: [10.911490339112829, 10.956591977180917, 10.985696539181747, 11.25853622526625, -4.564306563253819, -6.633573066339542], time: 200.171
mmmaddpg vs mmmaddpg steps: 1224975, episodes: 49000, mean episode reward: 30.625647709346865, agent episode reward: [10.137779242875446, 10.086014128232321, 10.077350735486338, 10.34314065066119, -3.9671799357745416, -6.0514571121338925], time: 204.439
mmmaddpg vs mmmaddpg steps: 1249975, episodes: 50000, mean episode reward: 30.85705153910496, agent episode reward: [10.599874917486705, 10.616510257470335, 10.609576410826165, 10.7891689911383, -5.2392290489323985, -6.518849988884147], time: 182.723
mmmaddpg vs mmmaddpg steps: 1274975, episodes: 51000, mean episode reward: 32.70234788586793, agent episode reward: [11.061968772309902, 11.028143666796899, 11.078021718972709, 11.262793248199086, -4.779411705132605, -6.949167815278053], time: 180.725
mmmaddpg vs mmmaddpg steps: 1299975, episodes: 52000, mean episode reward: 33.63123190203894, agent episode reward: [11.539392425413979, 11.457517166844125, 11.573741616978804, 11.726114677708159, -5.543031324143668, -7.122502660762458], time: 180.007
mmmaddpg vs mmmaddpg steps: 1324975, episodes: 53000, mean episode reward: 27.900529815069213, agent episode reward: [9.687503481587639, 9.415280558446735, 9.612531530500947, 9.76829718808036, -4.157115403927259, -6.4259675396192115], time: 180.556
mmmaddpg vs mmmaddpg steps: 1349975, episodes: 54000, mean episode reward: 29.549012780013847, agent episode reward: [10.088547181987874, 9.81252561713568, 10.029493671926836, 10.17796643441672, -4.003573653198142, -6.555946472255119], time: 187.508
mmmaddpg vs mmmaddpg steps: 1374975, episodes: 55000, mean episode reward: 32.741406999821514, agent episode reward: [11.449394254885503, 11.029921197080998, 11.23685443154135, 11.420866318871719, -4.961742104151319, -7.4338870984067364], time: 191.274
mmmaddpg vs mmmaddpg steps: 1399975, episodes: 56000, mean episode reward: 30.489907942016703, agent episode reward: [11.116446187228236, 10.67175989463091, 10.907878333543685, 10.98440811827071, -5.60066581196114, -7.589918779695697], time: 184.1
mmmaddpg vs mmmaddpg steps: 1424975, episodes: 57000, mean episode reward: 29.259486957305096, agent episode reward: [10.683307035552826, 10.207468266699603, 10.464877155423848, 10.534816333281563, -6.089625338882069, -6.541356494770678], time: 188.616
mmmaddpg vs mmmaddpg steps: 1449975, episodes: 58000, mean episode reward: 30.11993208221966, agent episode reward: [11.08894166747105, 10.541230548399927, 10.810271004311424, 10.813040418927711, -7.293473846943639, -5.840077709946811], time: 184.343
mmmaddpg vs mmmaddpg steps: 1474975, episodes: 59000, mean episode reward: 32.45312025307398, agent episode reward: [11.662608230545874, 11.170784085585868, 11.47115925963575, 11.379448833167395, -7.574262525967006, -5.656617629893897], time: 179.527
mmmaddpg vs mmmaddpg steps: 1499975, episodes: 60000, mean episode reward: 33.346969731984835, agent episode reward: [11.755874969442287, 11.333899645386376, 11.6736061636269, 11.530666225188275, -8.025403951070341, -4.921673320588655], time: 179.999
mmmaddpg vs mmmaddpg steps: 1524975, episodes: 61000, mean episode reward: 36.32071976615634, agent episode reward: [12.79787800631145, 12.350341727795003, 12.71014031729626, 12.602171102301705, -9.026860108825455, -5.11295127872263], time: 186.877
mmmaddpg vs mmmaddpg steps: 1549975, episodes: 62000, mean episode reward: 34.73227049768401, agent episode reward: [12.24126290202809, 11.720797147915404, 12.063525870400149, 11.981907548301995, -8.313386354687616, -4.961836616274017], time: 182.006
mmmaddpg vs mmmaddpg steps: 1574975, episodes: 63000, mean episode reward: 35.05935718295968, agent episode reward: [12.389001005603516, 12.056374942870839, 12.292440757725291, 12.168589030874967, -9.117493083162, -4.72955547095294], time: 183.657
mmmaddpg vs mmmaddpg steps: 1599975, episodes: 64000, mean episode reward: 36.757577345626736, agent episode reward: [12.991432753066888, 12.698030379980725, 12.975657548010709, 12.784620922730166, -9.644000330691748, -5.048163927470014], time: 191.705
mmmaddpg vs mmmaddpg steps: 1624975, episodes: 65000, mean episode reward: 34.622234718926414, agent episode reward: [12.255157015140743, 11.996740006757642, 12.112342539270077, 12.003512280372497, -8.75268684297942, -4.992830279635136], time: 181.515
mmmaddpg vs mmmaddpg steps: 1649975, episodes: 66000, mean episode reward: 32.147842865491526, agent episode reward: [11.460894937284177, 11.193763847323606, 11.35314623021657, 11.170611446338075, -8.210513295085185, -4.820060300585715], time: 177.798
mmmaddpg vs mmmaddpg steps: 1674975, episodes: 67000, mean episode reward: 32.38379483082191, agent episode reward: [11.342422392121804, 11.04146180766571, 11.225454108686867, 11.103539601715584, -7.806928110341985, -4.522154969026065], time: 182.045
mmmaddpg vs mmmaddpg steps: 1699975, episodes: 68000, mean episode reward: 29.53266639742822, agent episode reward: [10.566494657986343, 10.293230461260332, 10.378651773134767, 10.318583547710817, -7.217505629370047, -4.80678841329399], time: 183.558
mmmaddpg vs mmmaddpg steps: 1724975, episodes: 69000, mean episode reward: 28.709614929709627, agent episode reward: [10.239230303355336, 9.973597089553037, 10.05925691239659, 10.008763072327339, -6.732440409581925, -4.838792038340749], time: 184.712
mmmaddpg vs mmmaddpg steps: 1749975, episodes: 70000, mean episode reward: 27.494290765498537, agent episode reward: [9.852357304650766, 9.64420039701599, 9.740072451938234, 9.7041187444144, -6.43028306246048, -5.016175070060375], time: 186.303
mmmaddpg vs mmmaddpg steps: 1774975, episodes: 71000, mean episode reward: 29.052344917847975, agent episode reward: [10.314164509747252, 10.080666310711946, 10.12718333813662, 10.177834450023985, -6.975911898778912, -4.671591791992919], time: 187.943
mmmaddpg vs mmmaddpg steps: 1799975, episodes: 72000, mean episode reward: 27.715489156587317, agent episode reward: [9.64545194769171, 9.435627018613086, 9.46384332632152, 9.579769987084479, -5.766114320374757, -4.643088802748718], time: 189.825
mmmaddpg vs mmmaddpg steps: 1824975, episodes: 73000, mean episode reward: 28.749672079610995, agent episode reward: [10.085960175161377, 9.773983589075625, 9.787569575926229, 9.923358613225668, -5.429997038350411, -5.391202835427493], time: 187.677
mmmaddpg vs mmmaddpg steps: 1849975, episodes: 74000, mean episode reward: 26.56196267743018, agent episode reward: [9.399722307088151, 9.16133561971112, 9.129654595134557, 9.282111679659467, -5.789305819646019, -4.621555704517099], time: 189.203
mmmaddpg vs mmmaddpg steps: 1874975, episodes: 75000, mean episode reward: 23.139933407540905, agent episode reward: [8.151533426818355, 7.890368871435674, 7.810737024674469, 7.93273387454689, -4.25091460330237, -4.394525186632114], time: 189.98
mmmaddpg vs mmmaddpg steps: 1899975, episodes: 76000, mean episode reward: 26.859899865945273, agent episode reward: [9.760040253527722, 9.448592038290888, 9.411091853686568, 9.525813996501746, -5.351493062853256, -5.934145213208395], time: 179.386
mmmaddpg vs mmmaddpg steps: 1924975, episodes: 77000, mean episode reward: 29.53440754903497, agent episode reward: [10.5302559392542, 10.21510838957811, 10.238294889200336, 10.227078522211713, -5.1152408392692585, -6.561089351940123], time: 178.596
mmmaddpg vs mmmaddpg steps: 1949975, episodes: 78000, mean episode reward: 26.339704233812494, agent episode reward: [9.409442909001005, 9.11979584367068, 9.102076926144035, 9.071900152994129, -4.400682084819745, -5.962829513177603], time: 181.532
mmmaddpg vs mmmaddpg steps: 1974975, episodes: 79000, mean episode reward: 29.213833674903697, agent episode reward: [10.367237688010519, 9.97917611069659, 10.074093763970813, 10.040071147621363, -4.467655684535548, -6.7790893508600405], time: 180.739
mmmaddpg vs mmmaddpg steps: 1999975, episodes: 80000, mean episode reward: 29.13069010600261, agent episode reward: [10.426474762702943, 10.009621636926791, 10.118201167781237, 10.088551071272152, -4.277645997269352, -7.234512535411157], time: 186.231
mmmaddpg vs mmmaddpg steps: 2024975, episodes: 81000, mean episode reward: 31.348540985308333, agent episode reward: [11.227011895134098, 10.818033199281915, 10.949660729989835, 10.869386026053458, -4.138636308388474, -8.376914556762499], time: 182.941
mmmaddpg vs mmmaddpg steps: 2049975, episodes: 82000, mean episode reward: 35.06367775850184, agent episode reward: [12.544175797531164, 12.028232599530405, 12.273238159025434, 12.178468729493742, -4.702082542537411, -9.258354984541489], time: 186.091
mmmaddpg vs mmmaddpg steps: 2074975, episodes: 83000, mean episode reward: 35.00392729737886, agent episode reward: [12.479234635671292, 12.110230309350387, 12.150046152926425, 12.03702583638277, -4.534592174689642, -9.238017462262366], time: 185.178
mmmaddpg vs mmmaddpg steps: 2099975, episodes: 84000, mean episode reward: 36.710106087543274, agent episode reward: [13.15198493147819, 12.71364535642843, 12.818315178424152, 12.633037080989409, -4.366908581564548, -10.239967878212356], time: 187.57
mmmaddpg vs mmmaddpg steps: 2124975, episodes: 85000, mean episode reward: 35.42537004628663, agent episode reward: [12.731805582997602, 12.315181267145501, 12.36531371225339, 12.308060186497631, -4.98123210313523, -9.313758599472262], time: 189.493
mmmaddpg vs mmmaddpg steps: 2149975, episodes: 86000, mean episode reward: 36.14076503341365, agent episode reward: [12.964288866130017, 12.509947894129224, 12.63271330417258, 12.525071402662967, -4.7424593271123525, -9.748797106568778], time: 187.569
mmmaddpg vs mmmaddpg steps: 2174975, episodes: 87000, mean episode reward: 34.35019907468403, agent episode reward: [12.252917531527167, 11.921318626904489, 12.013344226504525, 11.91057706202858, -4.138671760326272, -9.60928661195446], time: 180.791
mmmaddpg vs mmmaddpg steps: 2199975, episodes: 88000, mean episode reward: 30.93210562510827, agent episode reward: [11.17937423629824, 10.76308355445578, 10.913781204994807, 10.968419327853534, -4.02537247209876, -8.867180226395332], time: 182.986
mmmaddpg vs mmmaddpg steps: 2224975, episodes: 89000, mean episode reward: 31.26001086654528, agent episode reward: [11.420416136237153, 11.025557519863163, 11.131178464563346, 11.265269812567015, -4.4304541875784285, -9.151956879106969], time: 188.816
mmmaddpg vs mmmaddpg steps: 2249975, episodes: 90000, mean episode reward: 33.518974726634184, agent episode reward: [11.936462659294481, 11.66260368818044, 11.643060800343251, 11.84428055684922, -4.349110848662585, -9.21832212937062], time: 190.303
mmmaddpg vs mmmaddpg steps: 2274975, episodes: 91000, mean episode reward: 32.87970752857302, agent episode reward: [11.76646199919687, 11.463608316248182, 11.42781105232532, 11.698672507414496, -3.9549562080494622, -9.521890138562384], time: 184.95
mmmaddpg vs mmmaddpg steps: 2299975, episodes: 92000, mean episode reward: 29.9915033681751, agent episode reward: [10.903043209291841, 10.506152652002632, 10.594010506600904, 10.866807348434806, -3.7715590876711005, -9.106951260483982], time: 184.592
mmmaddpg vs mmmaddpg steps: 2324975, episodes: 93000, mean episode reward: 29.000248523647926, agent episode reward: [10.397296543831777, 10.145668721627963, 10.186417364842221, 10.453461545817877, -3.918813181753002, -8.263782470718908], time: 180.138
mmmaddpg vs mmmaddpg steps: 2349975, episodes: 94000, mean episode reward: 28.498604612613942, agent episode reward: [10.444613045057661, 10.159292865301705, 10.120376333420086, 10.43161278682291, -4.099222553669633, -8.558067864318788], time: 181.437
mmmaddpg vs mmmaddpg steps: 2374975, episodes: 95000, mean episode reward: 29.1974773310102, agent episode reward: [10.576162142105824, 10.3034489026361, 10.300553187180578, 10.553400246737741, -4.980204219457619, -7.555882928192425], time: 185.172
mmmaddpg vs mmmaddpg steps: 2399975, episodes: 96000, mean episode reward: 29.632345192404863, agent episode reward: [10.648766046399782, 10.365665800237228, 10.303310361386908, 10.597305616194935, -4.580557315022345, -7.702145316791643], time: 186.323
mmmaddpg vs mmmaddpg steps: 2424975, episodes: 97000, mean episode reward: 29.064640703344477, agent episode reward: [10.703226703534806, 10.30287279799874, 10.338688417113284, 10.586194559212343, -4.828086985990283, -8.038254788524414], time: 180.022
mmmaddpg vs mmmaddpg steps: 2449975, episodes: 98000, mean episode reward: 32.43124990005824, agent episode reward: [11.64915520067496, 11.329977388203742, 11.235979755658635, 11.591552314408966, -5.403456827668717, -7.971957931219345], time: 178.356
mmmaddpg vs mmmaddpg steps: 2474975, episodes: 99000, mean episode reward: 29.963715172332517, agent episode reward: [10.93687819154529, 10.566526372920594, 10.624921985046807, 10.908478736485081, -5.5527563998356175, -7.520333713829639], time: 179.784
mmmaddpg vs mmmaddpg steps: 2499975, episodes: 100000, mean episode reward: 32.88497034781577, agent episode reward: [11.774159036847683, 11.323601332812162, 11.367601659593554, 11.660333140346738, -5.235172602086031, -8.005552219698327], time: 180.283
...Finished total of 100001 episodes.
