0 bad agents
      adv rate for q_index :  0 [1e-05, 0.001]
      adv rate for p_index :  0 [1e-05, 0.001]
1 good agents
      adv rate for q_index :  1 [0.001, 1e-05]
      adv rate for p_index :  1 [0.001, 1e-05]
Using good policy mmmaddpg and bad policy mmmaddpg with 1 adversaries
Starting iterations...
mmmaddpg vs mmmaddpg steps: 24975, episodes: 1000, mean episode reward: -25.917317279491492, agent episode reward: [3.176164647523754, -29.09348192701525], time: 37.696
mmmaddpg vs mmmaddpg steps: 49975, episodes: 2000, mean episode reward: -18.851262116594217, agent episode reward: [-4.71963987227583, -14.131622244318386], time: 68.246
mmmaddpg vs mmmaddpg steps: 74975, episodes: 3000, mean episode reward: -11.69619048459343, agent episode reward: [-4.799578481211572, -6.896612003381856], time: 82.03
mmmaddpg vs mmmaddpg steps: 99975, episodes: 4000, mean episode reward: -9.812448686989534, agent episode reward: [-3.384837500515051, -6.4276111864744845], time: 81.485
mmmaddpg vs mmmaddpg steps: 124975, episodes: 5000, mean episode reward: -9.354535574043442, agent episode reward: [-2.928465335768476, -6.426070238274966], time: 80.616
mmmaddpg vs mmmaddpg steps: 149975, episodes: 6000, mean episode reward: -9.081236227329775, agent episode reward: [-2.480043359960339, -6.601192867369437], time: 80.196
mmmaddpg vs mmmaddpg steps: 174975, episodes: 7000, mean episode reward: -8.90236414490222, agent episode reward: [-2.334139685613295, -6.568224459288923], time: 80.721
mmmaddpg vs mmmaddpg steps: 199975, episodes: 8000, mean episode reward: -8.950889328649442, agent episode reward: [-2.132411416540718, -6.818477912108725], time: 81.529
mmmaddpg vs mmmaddpg steps: 224975, episodes: 9000, mean episode reward: -8.763547341771973, agent episode reward: [-2.14327359169409, -6.6202737500778825], time: 82.17
mmmaddpg vs mmmaddpg steps: 249975, episodes: 10000, mean episode reward: -8.910236532462726, agent episode reward: [-2.4068859471719923, -6.503350585290733], time: 81.198
mmmaddpg vs mmmaddpg steps: 274975, episodes: 11000, mean episode reward: -8.936903674563732, agent episode reward: [-2.1184331156068374, -6.818470558956893], time: 80.864
mmmaddpg vs mmmaddpg steps: 299975, episodes: 12000, mean episode reward: -9.26804208357921, agent episode reward: [-2.4008180880861993, -6.867223995493011], time: 82.241
mmmaddpg vs mmmaddpg steps: 324975, episodes: 13000, mean episode reward: -8.860962252951307, agent episode reward: [-1.9478371536592691, -6.913125099292038], time: 81.571
mmmaddpg vs mmmaddpg steps: 349975, episodes: 14000, mean episode reward: -8.794641282409039, agent episode reward: [-1.8708052253010317, -6.923836057108007], time: 79.867
mmmaddpg vs mmmaddpg steps: 374975, episodes: 15000, mean episode reward: -8.505341042913862, agent episode reward: [-2.016128492978138, -6.489212549935723], time: 80.722
mmmaddpg vs mmmaddpg steps: 399975, episodes: 16000, mean episode reward: -8.85364593751135, agent episode reward: [-1.9676925285444258, -6.885953408966923], time: 80.378
mmmaddpg vs mmmaddpg steps: 424975, episodes: 17000, mean episode reward: -8.52427128307455, agent episode reward: [-1.8774070956524544, -6.646864187422094], time: 79.944
mmmaddpg vs mmmaddpg steps: 449975, episodes: 18000, mean episode reward: -8.71197643167706, agent episode reward: [-1.96740212769641, -6.744574303980651], time: 80.162
mmmaddpg vs mmmaddpg steps: 474975, episodes: 19000, mean episode reward: -8.849141469124683, agent episode reward: [-2.2950086365105724, -6.554132832614112], time: 80.227
mmmaddpg vs mmmaddpg steps: 499975, episodes: 20000, mean episode reward: -8.795573752208444, agent episode reward: [-2.091348283744529, -6.704225468463916], time: 80.781
mmmaddpg vs mmmaddpg steps: 524975, episodes: 21000, mean episode reward: -8.708393957604676, agent episode reward: [-2.1280552965444706, -6.580338661060207], time: 80.032
mmmaddpg vs mmmaddpg steps: 549975, episodes: 22000, mean episode reward: -8.61630573885561, agent episode reward: [-1.861927855010113, -6.754377883845498], time: 80.714
mmmaddpg vs mmmaddpg steps: 574975, episodes: 23000, mean episode reward: -8.726908021331878, agent episode reward: [-1.985575749283668, -6.741332272048211], time: 82.007
mmmaddpg vs mmmaddpg steps: 599975, episodes: 24000, mean episode reward: -8.624381171690656, agent episode reward: [-1.791195257659509, -6.833185914031148], time: 82.265
mmmaddpg vs mmmaddpg steps: 624975, episodes: 25000, mean episode reward: -8.315898628391881, agent episode reward: [-1.9034061632972683, -6.412492465094612], time: 79.416
mmmaddpg vs mmmaddpg steps: 649975, episodes: 26000, mean episode reward: -8.536668896320942, agent episode reward: [-1.9608903420190076, -6.575778554301933], time: 80.038
mmmaddpg vs mmmaddpg steps: 674975, episodes: 27000, mean episode reward: -8.51331906406189, agent episode reward: [-2.0652013435052288, -6.4481177205566595], time: 80.954
mmmaddpg vs mmmaddpg steps: 699975, episodes: 28000, mean episode reward: -8.590217089461538, agent episode reward: [-1.858165738369218, -6.732051351092321], time: 80.462
mmmaddpg vs mmmaddpg steps: 724975, episodes: 29000, mean episode reward: -8.511912091846206, agent episode reward: [-1.8607383248646647, -6.651173766981542], time: 79.999
mmmaddpg vs mmmaddpg steps: 749975, episodes: 30000, mean episode reward: -8.106552329192661, agent episode reward: [-1.4985665943418984, -6.607985734850764], time: 81.098
mmmaddpg vs mmmaddpg steps: 774975, episodes: 31000, mean episode reward: -8.4056654910537, agent episode reward: [-1.507635190469355, -6.898030300584344], time: 80.215
mmmaddpg vs mmmaddpg steps: 799975, episodes: 32000, mean episode reward: -8.350332961164062, agent episode reward: [-1.5210153518539633, -6.829317609310099], time: 80.35
mmmaddpg vs mmmaddpg steps: 824975, episodes: 33000, mean episode reward: -8.630997112864572, agent episode reward: [-1.7036697916217989, -6.927327321242772], time: 80.657
mmmaddpg vs mmmaddpg steps: 849975, episodes: 34000, mean episode reward: -8.64689737655864, agent episode reward: [-1.5866008493898593, -7.060296527168781], time: 80.514
mmmaddpg vs mmmaddpg steps: 874975, episodes: 35000, mean episode reward: -8.670838101822822, agent episode reward: [-1.6443452886109942, -7.026492813211829], time: 80.839
mmmaddpg vs mmmaddpg steps: 899975, episodes: 36000, mean episode reward: -8.442015818015836, agent episode reward: [-1.5678541969548778, -6.874161621060957], time: 80.008
mmmaddpg vs mmmaddpg steps: 924975, episodes: 37000, mean episode reward: -8.798880676035633, agent episode reward: [-1.8741430887800947, -6.924737587255539], time: 80.481
mmmaddpg vs mmmaddpg steps: 949975, episodes: 38000, mean episode reward: -8.272574574722489, agent episode reward: [-1.5153147093776729, -6.757259865344815], time: 80.024
mmmaddpg vs mmmaddpg steps: 974975, episodes: 39000, mean episode reward: -8.751279238640068, agent episode reward: [-1.525995007931079, -7.225284230708991], time: 80.278
mmmaddpg vs mmmaddpg steps: 999975, episodes: 40000, mean episode reward: -8.465176195395102, agent episode reward: [-1.6186144074594044, -6.8465617879356975], time: 80.86
mmmaddpg vs mmmaddpg steps: 1024975, episodes: 41000, mean episode reward: -8.159581411879996, agent episode reward: [-1.4967256602033672, -6.662855751676629], time: 79.761
mmmaddpg vs mmmaddpg steps: 1049975, episodes: 42000, mean episode reward: -8.554440376941221, agent episode reward: [-1.8037682516845173, -6.750672125256703], time: 80.652
mmmaddpg vs mmmaddpg steps: 1074975, episodes: 43000, mean episode reward: -8.677485731722609, agent episode reward: [-1.7475266146756097, -6.929959117046999], time: 79.906
mmmaddpg vs mmmaddpg steps: 1099975, episodes: 44000, mean episode reward: -8.645201938115537, agent episode reward: [-1.7982906640725962, -6.846911274042941], time: 80.029
mmmaddpg vs mmmaddpg steps: 1124975, episodes: 45000, mean episode reward: -8.485249112340854, agent episode reward: [-1.1914378035276443, -7.29381130881321], time: 81.455
mmmaddpg vs mmmaddpg steps: 1149975, episodes: 46000, mean episode reward: -8.186044646815573, agent episode reward: [-0.9665351475059193, -7.219509499309654], time: 81.289
mmmaddpg vs mmmaddpg steps: 1174975, episodes: 47000, mean episode reward: -8.425745088445408, agent episode reward: [-0.5640323679210949, -7.861712720524314], time: 80.235
mmmaddpg vs mmmaddpg steps: 1199975, episodes: 48000, mean episode reward: -8.383261179427135, agent episode reward: [-1.0515927673659817, -7.331668412061154], time: 80.148
mmmaddpg vs mmmaddpg steps: 1224975, episodes: 49000, mean episode reward: -8.434994435905773, agent episode reward: [-1.2812823034358585, -7.153712132469914], time: 82.428
mmmaddpg vs mmmaddpg steps: 1249975, episodes: 50000, mean episode reward: -8.187253109285987, agent episode reward: [-1.0506570729784748, -7.136596036307511], time: 81.497
mmmaddpg vs mmmaddpg steps: 1274975, episodes: 51000, mean episode reward: -8.368443642214547, agent episode reward: [-1.3783194382680777, -6.990124203946468], time: 80.6
mmmaddpg vs mmmaddpg steps: 1299975, episodes: 52000, mean episode reward: -8.594711678724005, agent episode reward: [-1.7268384891224386, -6.867873189601567], time: 81.292
mmmaddpg vs mmmaddpg steps: 1324975, episodes: 53000, mean episode reward: -8.733284933130898, agent episode reward: [-1.5681099308927913, -7.165175002238107], time: 80.976
mmmaddpg vs mmmaddpg steps: 1349975, episodes: 54000, mean episode reward: -8.608478149826679, agent episode reward: [-1.1338838327651133, -7.474594317061564], time: 80.946
mmmaddpg vs mmmaddpg steps: 1374975, episodes: 55000, mean episode reward: -8.175673147414638, agent episode reward: [-0.34985708771887974, -7.825816059695759], time: 81.293
mmmaddpg vs mmmaddpg steps: 1399975, episodes: 56000, mean episode reward: -8.55847865915643, agent episode reward: [0.42152274284807917, -8.98000140200451], time: 81.309
mmmaddpg vs mmmaddpg steps: 1424975, episodes: 57000, mean episode reward: -8.33307841426359, agent episode reward: [0.20908005390636264, -8.542158468169953], time: 81.543
mmmaddpg vs mmmaddpg steps: 1449975, episodes: 58000, mean episode reward: -8.629999074346982, agent episode reward: [0.9206121901654808, -9.550611264512463], time: 80.912
mmmaddpg vs mmmaddpg steps: 1474975, episodes: 59000, mean episode reward: -8.597703967819726, agent episode reward: [0.42887639868011035, -9.026580366499834], time: 81.24
mmmaddpg vs mmmaddpg steps: 1499975, episodes: 60000, mean episode reward: -8.402240717083838, agent episode reward: [-0.2450774630723253, -8.157163254011513], time: 81.478
mmmaddpg vs mmmaddpg steps: 1524975, episodes: 61000, mean episode reward: -8.509805405985643, agent episode reward: [-0.8618070314457229, -7.647998374539922], time: 80.963
mmmaddpg vs mmmaddpg steps: 1549975, episodes: 62000, mean episode reward: -8.214654907948152, agent episode reward: [-0.8285043244463887, -7.386150583501761], time: 82.367
mmmaddpg vs mmmaddpg steps: 1574975, episodes: 63000, mean episode reward: -8.162883908715084, agent episode reward: [-0.7390851015730953, -7.423798807141989], time: 82.563
mmmaddpg vs mmmaddpg steps: 1599975, episodes: 64000, mean episode reward: -8.627057123868262, agent episode reward: [-0.8068976060954741, -7.820159517772788], time: 81.931
mmmaddpg vs mmmaddpg steps: 1624975, episodes: 65000, mean episode reward: -8.499528661546943, agent episode reward: [-0.39783033143360913, -8.101698330113335], time: 81.517
mmmaddpg vs mmmaddpg steps: 1649975, episodes: 66000, mean episode reward: -8.470519489434363, agent episode reward: [-0.014730823527446518, -8.455788665906915], time: 82.431
mmmaddpg vs mmmaddpg steps: 1674975, episodes: 67000, mean episode reward: -8.188819303492952, agent episode reward: [-0.7809632432356403, -7.407856060257312], time: 82.731
mmmaddpg vs mmmaddpg steps: 1699975, episodes: 68000, mean episode reward: -8.640937360253417, agent episode reward: [-0.9460533125828805, -7.694884047670537], time: 82.251
mmmaddpg vs mmmaddpg steps: 1724975, episodes: 69000, mean episode reward: -8.311433369076523, agent episode reward: [-0.8911475418451899, -7.420285827231334], time: 81.406
mmmaddpg vs mmmaddpg steps: 1749975, episodes: 70000, mean episode reward: -8.030965179688684, agent episode reward: [-0.8257126801669633, -7.205252499521719], time: 81.909
mmmaddpg vs mmmaddpg steps: 1774975, episodes: 71000, mean episode reward: -8.372964969308178, agent episode reward: [-0.6033602173195352, -7.769604751988643], time: 82.622
mmmaddpg vs mmmaddpg steps: 1799975, episodes: 72000, mean episode reward: -8.840763858884632, agent episode reward: [-0.41629074533871413, -8.424473113545915], time: 82.646
mmmaddpg vs mmmaddpg steps: 1824975, episodes: 73000, mean episode reward: -8.745581106142321, agent episode reward: [0.35474627920959356, -9.100327385351918], time: 81.267
mmmaddpg vs mmmaddpg steps: 1849975, episodes: 74000, mean episode reward: -8.821313402744194, agent episode reward: [-0.7222424897312146, -8.099070913012978], time: 82.707
mmmaddpg vs mmmaddpg steps: 1874975, episodes: 75000, mean episode reward: -8.808933059643094, agent episode reward: [-1.048092565261621, -7.760840494381473], time: 82.335
mmmaddpg vs mmmaddpg steps: 1899975, episodes: 76000, mean episode reward: -8.76267750188925, agent episode reward: [-1.383023033494257, -7.3796544683949925], time: 81.031
mmmaddpg vs mmmaddpg steps: 1924975, episodes: 77000, mean episode reward: -8.560230287459484, agent episode reward: [-1.3211157606660406, -7.239114526793444], time: 82.151
mmmaddpg vs mmmaddpg steps: 1949975, episodes: 78000, mean episode reward: -8.790865741725812, agent episode reward: [-1.2240494454954016, -7.566816296230409], time: 81.587
mmmaddpg vs mmmaddpg steps: 1974975, episodes: 79000, mean episode reward: -8.710450251096463, agent episode reward: [-1.5047485104757325, -7.205701740620732], time: 81.406
mmmaddpg vs mmmaddpg steps: 1999975, episodes: 80000, mean episode reward: -9.165424562985347, agent episode reward: [-1.6024218560398285, -7.563002706945519], time: 81.449
mmmaddpg vs mmmaddpg steps: 2024975, episodes: 81000, mean episode reward: -9.289567834891892, agent episode reward: [-1.7727722328817699, -7.516795602010121], time: 81.029
mmmaddpg vs mmmaddpg steps: 2049975, episodes: 82000, mean episode reward: -9.205011427265836, agent episode reward: [-2.197011804926876, -7.007999622338959], time: 81.832
mmmaddpg vs mmmaddpg steps: 2074975, episodes: 83000, mean episode reward: -9.036250085715794, agent episode reward: [-2.1090094506961248, -6.927240635019667], time: 81.14
mmmaddpg vs mmmaddpg steps: 2099975, episodes: 84000, mean episode reward: -8.961138616887286, agent episode reward: [-0.817210079884224, -8.143928537003061], time: 82.522
mmmaddpg vs mmmaddpg steps: 2124975, episodes: 85000, mean episode reward: -9.235309791470215, agent episode reward: [0.004273367927259699, -9.239583159397474], time: 81.42
mmmaddpg vs mmmaddpg steps: 2149975, episodes: 86000, mean episode reward: -8.968079749503017, agent episode reward: [0.37209506175302387, -9.340174811256041], time: 82.1
mmmaddpg vs mmmaddpg steps: 2174975, episodes: 87000, mean episode reward: -8.741145920410984, agent episode reward: [0.2778247202390428, -9.018970640650029], time: 80.901
mmmaddpg vs mmmaddpg steps: 2199975, episodes: 88000, mean episode reward: -9.031193685182053, agent episode reward: [0.029941353533705382, -9.061135038715758], time: 81.904
mmmaddpg vs mmmaddpg steps: 2224975, episodes: 89000, mean episode reward: -8.790236722452596, agent episode reward: [0.04287708461605487, -8.833113807068651], time: 81.459
mmmaddpg vs mmmaddpg steps: 2249975, episodes: 90000, mean episode reward: -8.843155484391021, agent episode reward: [-0.6531732742958064, -8.189982210095216], time: 80.864
mmmaddpg vs mmmaddpg steps: 2274975, episodes: 91000, mean episode reward: -8.848911336455359, agent episode reward: [-0.9002396806612039, -7.948671655794155], time: 81.177
mmmaddpg vs mmmaddpg steps: 2299975, episodes: 92000, mean episode reward: -8.705184816073524, agent episode reward: [-1.2864260966990178, -7.418758719374509], time: 81.621
mmmaddpg vs mmmaddpg steps: 2324975, episodes: 93000, mean episode reward: -9.008584924453482, agent episode reward: [-1.1135898699914923, -7.894995054461989], time: 82.698
mmmaddpg vs mmmaddpg steps: 2349975, episodes: 94000, mean episode reward: -8.679994905889489, agent episode reward: [-0.09699739117300527, -8.582997514716483], time: 82.117
mmmaddpg vs mmmaddpg steps: 2374975, episodes: 95000, mean episode reward: -8.979022382395863, agent episode reward: [1.5850504402779275, -10.564072822673792], time: 81.063
mmmaddpg vs mmmaddpg steps: 2399975, episodes: 96000, mean episode reward: -9.037954728965921, agent episode reward: [1.6903316396723145, -10.728286368638237], time: 82.784
mmmaddpg vs mmmaddpg steps: 2424975, episodes: 97000, mean episode reward: -8.845865768428538, agent episode reward: [1.1112336857497371, -9.957099454178277], time: 80.78
mmmaddpg vs mmmaddpg steps: 2449975, episodes: 98000, mean episode reward: -8.788589694619343, agent episode reward: [0.15631249642902037, -8.944902191048364], time: 81.678
mmmaddpg vs mmmaddpg steps: 2474975, episodes: 99000, mean episode reward: -8.904514151038839, agent episode reward: [-0.5950523158627175, -8.309461835176121], time: 82.116
mmmaddpg vs mmmaddpg steps: 2499975, episodes: 100000, mean episode reward: -8.9053707085985, agent episode reward: [-0.893899207235273, -8.011471501363228], time: 82.48
...Finished total of 100001 episodes.
