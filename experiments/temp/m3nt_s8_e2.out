0 bad agents
      adv rate for q_index :  0 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
      adv rate for p_index :  0 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
1 bad agents
      adv rate for q_index :  1 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
      adv rate for p_index :  1 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
2 bad agents
      adv rate for q_index :  2 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
      adv rate for p_index :  2 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
3 bad agents
      adv rate for q_index :  3 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
      adv rate for p_index :  3 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
4 good agents
      adv rate for q_index :  4 [0.001, 0.001, 0.001, 0.001, 1e-05, 1e-05]
      adv rate for p_index :  4 [0.001, 0.001, 0.001, 0.001, 1e-05, 1e-05]
5 good agents
      adv rate for q_index :  5 [0.001, 0.001, 0.001, 0.001, 1e-05, 1e-05]
      adv rate for p_index :  5 [0.001, 0.001, 0.001, 0.001, 1e-05, 1e-05]
Using good policy mmmaddpg and bad policy mmmaddpg with 4 adversaries
Starting iterations...
mmmaddpg vs mmmaddpg steps: 24975, episodes: 1000, mean episode reward: -28.533392470950755, agent episode reward: [0.7958275270671045, 0.7398100822549816, 0.7595447452765882, 0.7881084560417149, -17.3889165625445, -14.227766719046642], time: 154.972
mmmaddpg vs mmmaddpg steps: 49975, episodes: 2000, mean episode reward: -8.044155195088251, agent episode reward: [2.921208464247438, 2.7550252304781053, 2.6695112937422105, 2.7170169126201444, -6.646172801626552, -12.460744294549597], time: 247.735
mmmaddpg vs mmmaddpg steps: 74975, episodes: 3000, mean episode reward: 12.354291317570107, agent episode reward: [4.3635759198832975, 3.888660006934613, 3.7551466971352294, 4.2321092715799535, -1.596145554420727, -2.2890550235422595], time: 251.47
mmmaddpg vs mmmaddpg steps: 99975, episodes: 4000, mean episode reward: 18.432057466570345, agent episode reward: [5.90983999884083, 6.258351342867099, 5.520910826865027, 6.431191902213999, -2.079950106197719, -3.6082864980188916], time: 247.993
mmmaddpg vs mmmaddpg steps: 124975, episodes: 5000, mean episode reward: 23.78229477009758, agent episode reward: [8.060589953258505, 8.006150259878428, 7.309652725579748, 7.735530092530712, -3.1955393416812523, -4.134088919468566], time: 256.649
mmmaddpg vs mmmaddpg steps: 149975, episodes: 6000, mean episode reward: 32.57791439295304, agent episode reward: [10.957229409272811, 10.679686222283859, 10.62818911954483, 10.650750754678876, -4.692732344486489, -5.645208768340853], time: 253.209
mmmaddpg vs mmmaddpg steps: 174975, episodes: 7000, mean episode reward: 41.59035442312443, agent episode reward: [13.773867375726615, 13.620483545573101, 13.4385978969358, 13.710684323256869, -7.764876978360744, -5.188401740007215], time: 258.943
mmmaddpg vs mmmaddpg steps: 199975, episodes: 8000, mean episode reward: 37.364906388780746, agent episode reward: [12.402981658759801, 12.418427937634464, 12.113521769316568, 12.323669552781883, -6.770938477551605, -5.122756052160365], time: 260.225
mmmaddpg vs mmmaddpg steps: 224975, episodes: 9000, mean episode reward: 33.50968577600368, agent episode reward: [11.22434934609694, 11.175400869093869, 10.881661674372763, 10.957511258816824, -4.246997016568198, -6.482240355808518], time: 258.625
mmmaddpg vs mmmaddpg steps: 249975, episodes: 10000, mean episode reward: 34.49801370819567, agent episode reward: [11.978798682167874, 11.886226691783126, 11.670936032958906, 11.555262518158905, -6.664373228313856, -5.9288369885592855], time: 259.321
mmmaddpg vs mmmaddpg steps: 274975, episodes: 11000, mean episode reward: 31.812097981018212, agent episode reward: [11.185499106352536, 11.224213594427983, 11.162554157125909, 11.092015906246498, -7.379704688457093, -5.472480094677623], time: 260.364
mmmaddpg vs mmmaddpg steps: 299975, episodes: 12000, mean episode reward: 31.915386553371675, agent episode reward: [11.245636410022918, 11.277197709151364, 11.170171301340023, 11.208275681504361, -7.573735265735171, -5.41215928291182], time: 260.049
mmmaddpg vs mmmaddpg steps: 324975, episodes: 13000, mean episode reward: 27.889999813633047, agent episode reward: [10.02597987309201, 9.999952903970193, 10.039092502706321, 10.024871500653779, -6.8035969042740705, -5.396300062515185], time: 259.945
mmmaddpg vs mmmaddpg steps: 349975, episodes: 14000, mean episode reward: 19.711711803283798, agent episode reward: [7.9122665838770185, 7.938653842574402, 7.944426476269062, 7.859946197330195, -6.940387237107912, -5.003194059658966], time: 257.624
mmmaddpg vs mmmaddpg steps: 374975, episodes: 15000, mean episode reward: 20.723702228826, agent episode reward: [8.086008232083305, 8.049028960893791, 7.953842971569743, 7.94648438970998, -7.709230218075401, -3.602432107355422], time: 251.077
mmmaddpg vs mmmaddpg steps: 399975, episodes: 16000, mean episode reward: 20.442282647957867, agent episode reward: [7.70951738996758, 7.747775684343687, 7.729634211702693, 7.7756325064841185, -6.941669615044973, -3.578607529495236], time: 262.531
mmmaddpg vs mmmaddpg steps: 424975, episodes: 17000, mean episode reward: 20.656562231679455, agent episode reward: [7.513254124894435, 7.535127021557627, 7.579292478149819, 7.584031361666402, -7.08540045520164, -2.469742299387187], time: 262.996
mmmaddpg vs mmmaddpg steps: 449975, episodes: 18000, mean episode reward: 14.941599488297765, agent episode reward: [5.5610989993494675, 5.629439535284154, 5.651758173438691, 5.5718977614399625, -5.121571129298168, -2.351023851916342], time: 261.069
mmmaddpg vs mmmaddpg steps: 474975, episodes: 19000, mean episode reward: 18.24799685301538, agent episode reward: [6.5053193347209, 6.432910278507519, 6.36820485328385, 6.421997362037413, -5.033434499392055, -2.447000476142246], time: 261.57
mmmaddpg vs mmmaddpg steps: 499975, episodes: 20000, mean episode reward: 20.435928357441284, agent episode reward: [7.396399778053486, 7.247397826427419, 7.191083900392742, 7.253159480462313, -6.466359562083229, -2.1857530658114483], time: 264.102
mmmaddpg vs mmmaddpg steps: 524975, episodes: 21000, mean episode reward: 17.508605332314737, agent episode reward: [6.580038207565243, 6.418991243823797, 6.331011482420315, 6.483965769321593, -6.570191595102477, -1.7352097757137355], time: 258.3
mmmaddpg vs mmmaddpg steps: 549975, episodes: 22000, mean episode reward: 16.96204870081368, agent episode reward: [6.401944790510914, 6.380151186800386, 6.397130903795475, 6.422220433981655, -6.070897819561856, -2.5685007947128926], time: 267.692
mmmaddpg vs mmmaddpg steps: 574975, episodes: 23000, mean episode reward: 21.762767397193464, agent episode reward: [7.874945353130475, 7.7961911215325905, 7.79032060280706, 7.738490521612468, -7.226925469129557, -2.2102547327595725], time: 260.759
mmmaddpg vs mmmaddpg steps: 599975, episodes: 24000, mean episode reward: 19.378293174461994, agent episode reward: [7.689817544711696, 7.582560617374193, 7.469335846713333, 7.5467817487344275, -8.882157212835377, -2.028045370236275], time: 265.427
mmmaddpg vs mmmaddpg steps: 624975, episodes: 25000, mean episode reward: 25.27500097439513, agent episode reward: [9.557592896991565, 9.464675808330343, 9.377917851775612, 9.403655760644702, -9.921188908114363, -2.6076524352327275], time: 256.29
mmmaddpg vs mmmaddpg steps: 649975, episodes: 26000, mean episode reward: 26.68577349388906, agent episode reward: [9.699903987935944, 9.604055148844397, 9.394105926346844, 9.549087838044354, -9.687646619883006, -1.8737327873994747], time: 261.917
mmmaddpg vs mmmaddpg steps: 674975, episodes: 27000, mean episode reward: 22.45039910901776, agent episode reward: [8.726845986550073, 8.601293658618959, 8.445650784226292, 8.57240956942633, -9.675830684336095, -2.2199702054678], time: 264.801
mmmaddpg vs mmmaddpg steps: 699975, episodes: 28000, mean episode reward: 20.99917829794715, agent episode reward: [8.180722721632849, 8.301901678098554, 8.12135549933812, 8.11157132023148, -8.6812610274547, -3.0351118938991544], time: 266.787
mmmaddpg vs mmmaddpg steps: 724975, episodes: 29000, mean episode reward: 16.55491573779097, agent episode reward: [7.2623109599101845, 7.423069686171231, 7.036766040231985, 7.178127690829793, -8.547516647187477, -3.797841992164746], time: 269.715
mmmaddpg vs mmmaddpg steps: 749975, episodes: 30000, mean episode reward: 17.726353161773083, agent episode reward: [7.363993254934664, 7.35089790580957, 7.188111338082032, 7.190551162378046, -7.423963734702007, -3.9432367647292237], time: 268.424
mmmaddpg vs mmmaddpg steps: 774975, episodes: 31000, mean episode reward: 19.311222380672195, agent episode reward: [7.964248128640108, 8.009894576162909, 7.837573842928036, 7.668384519620314, -7.608346770805412, -4.560531915873761], time: 263.393
mmmaddpg vs mmmaddpg steps: 799975, episodes: 32000, mean episode reward: 18.86408128667716, agent episode reward: [7.416793569328178, 7.292692618238641, 7.273231966228206, 6.916763383636077, -6.611078496304825, -3.4243217544491187], time: 267.467
mmmaddpg vs mmmaddpg steps: 824975, episodes: 33000, mean episode reward: 18.531787673943292, agent episode reward: [7.292961751035097, 7.108711136954886, 7.079431806862682, 7.01335945461909, -5.935997684482184, -4.02667879104628], time: 263.163
mmmaddpg vs mmmaddpg steps: 849975, episodes: 34000, mean episode reward: 22.19872146907299, agent episode reward: [8.520878890263553, 8.354394032025864, 8.388969533209456, 8.165404046231666, -7.353728064676248, -3.877196967981308], time: 269.207
mmmaddpg vs mmmaddpg steps: 874975, episodes: 35000, mean episode reward: 21.02047869188155, agent episode reward: [8.170137717157436, 7.9287702813566465, 7.952057662040743, 7.6701669152989504, -6.912540488836118, -3.788113395136105], time: 267.282
mmmaddpg vs mmmaddpg steps: 899975, episodes: 36000, mean episode reward: 23.780711360708224, agent episode reward: [8.989079958336943, 8.728420651829278, 8.73242457151709, 8.590655049747493, -7.685024944721172, -3.574843926001407], time: 270.812
mmmaddpg vs mmmaddpg steps: 924975, episodes: 37000, mean episode reward: 27.262337480322365, agent episode reward: [10.18421475163259, 9.921607184989567, 10.03786292411908, 9.952587315766483, -9.035839018750245, -3.7980956774351067], time: 276.621
mmmaddpg vs mmmaddpg steps: 949975, episodes: 38000, mean episode reward: 27.056684690943555, agent episode reward: [10.216722754441767, 10.011656171673229, 10.128193793741183, 10.054565066383395, -9.198310168576208, -4.156142926719808], time: 264.176
mmmaddpg vs mmmaddpg steps: 974975, episodes: 39000, mean episode reward: 30.429973576225667, agent episode reward: [11.345999451436736, 11.170259276885604, 11.272213139406922, 11.17647977130789, -10.386511333727588, -4.148466729083899], time: 263.061
mmmaddpg vs mmmaddpg steps: 999975, episodes: 40000, mean episode reward: 27.190385343298228, agent episode reward: [10.378358735104992, 10.252979055950785, 10.257136129272501, 10.082491925130428, -9.015847281715512, -4.764733220444963], time: 278.426
mmmaddpg vs mmmaddpg steps: 1024975, episodes: 41000, mean episode reward: 33.790623159845296, agent episode reward: [12.376430629541963, 12.207417664481563, 12.290993958549892, 12.029427906589818, -9.847708737207405, -5.265938262110534], time: 270.242
mmmaddpg vs mmmaddpg steps: 1049975, episodes: 42000, mean episode reward: 27.666105656125424, agent episode reward: [10.451611660459276, 10.265149124846067, 10.433237483830515, 10.22731856672822, -9.269742895942512, -4.441468283796143], time: 275.857
mmmaddpg vs mmmaddpg steps: 1074975, episodes: 43000, mean episode reward: 30.323721087658598, agent episode reward: [11.321052031572334, 11.096637648671297, 11.258352104998743, 11.005427515154357, -9.447742972821754, -4.910005239916385], time: 270.582
mmmaddpg vs mmmaddpg steps: 1099975, episodes: 44000, mean episode reward: 28.742641152926314, agent episode reward: [11.028835971954864, 10.715118185119579, 10.836729211350262, 10.745502518117672, -9.922147675633813, -4.661397057982254], time: 270.726
mmmaddpg vs mmmaddpg steps: 1124975, episodes: 45000, mean episode reward: 29.2212256143662, agent episode reward: [11.167732960626491, 10.865240209051017, 10.99368238530283, 10.89889595032644, -10.133082580002966, -4.571243310937611], time: 263.974
mmmaddpg vs mmmaddpg steps: 1149975, episodes: 46000, mean episode reward: 26.661124493875832, agent episode reward: [10.333553422104607, 10.144869315579905, 10.092872527755977, 10.054236566210147, -8.747043599760731, -5.217363738014072], time: 259.841
mmmaddpg vs mmmaddpg steps: 1174975, episodes: 47000, mean episode reward: 29.309222853489526, agent episode reward: [11.0054865632493, 10.830074225010575, 10.843595113570016, 10.809658698945393, -8.471593372011386, -5.707998375274377], time: 264.705
mmmaddpg vs mmmaddpg steps: 1199975, episodes: 48000, mean episode reward: 24.671065125356808, agent episode reward: [9.303610632846219, 9.234718358498581, 9.125270150645836, 9.088346008884452, -6.981126407599276, -5.099753617919008], time: 267.104
mmmaddpg vs mmmaddpg steps: 1224975, episodes: 49000, mean episode reward: 28.061783550293942, agent episode reward: [11.121857669616412, 10.914492733030222, 10.87683383391069, 10.860330757145602, -9.993100772073127, -5.718630671335857], time: 266.68
mmmaddpg vs mmmaddpg steps: 1249975, episodes: 50000, mean episode reward: 34.02825074945687, agent episode reward: [12.714960478494136, 12.395125327274958, 12.504761050896235, 12.442467516840063, -10.721312938896286, -5.3077506851522305], time: 262.961
mmmaddpg vs mmmaddpg steps: 1274975, episodes: 51000, mean episode reward: 28.5990513086107, agent episode reward: [11.390218731516962, 10.95373783219476, 11.20757337646398, 11.088301965038411, -10.964578988924172, -5.0762016076792404], time: 262.346
mmmaddpg vs mmmaddpg steps: 1299975, episodes: 52000, mean episode reward: 29.544219133955753, agent episode reward: [11.597660086626044, 11.142080643002446, 11.366646368484844, 11.22231230969114, -11.175442994258615, -4.609037279590106], time: 277.01
mmmaddpg vs mmmaddpg steps: 1324975, episodes: 53000, mean episode reward: 32.10119546334162, agent episode reward: [12.779953851030557, 12.172013437743114, 12.568358112222496, 12.331338492491671, -12.688069548003622, -5.0623988821426], time: 267.228
mmmaddpg vs mmmaddpg steps: 1349975, episodes: 54000, mean episode reward: 30.628603641918097, agent episode reward: [11.70995203214024, 11.143458159854715, 11.582575884134041, 11.276266047013745, -10.473097468571318, -4.610551012653328], time: 266.098
mmmaddpg vs mmmaddpg steps: 1374975, episodes: 55000, mean episode reward: 29.663630855902355, agent episode reward: [11.284255133830834, 10.827315724146374, 11.100026475521641, 10.875139901936612, -9.700473315028528, -4.722633064504579], time: 267.124
mmmaddpg vs mmmaddpg steps: 1399975, episodes: 56000, mean episode reward: 30.044638346202852, agent episode reward: [11.482995420032694, 11.063893126432971, 11.328740321939346, 11.251020178898434, -10.147557979544812, -4.934452721555776], time: 267.809
mmmaddpg vs mmmaddpg steps: 1424975, episodes: 57000, mean episode reward: 31.84889408537763, agent episode reward: [12.09803570200689, 11.862265622322422, 11.962298146562947, 11.77777806101848, -10.020039064759391, -5.831444381773719], time: 272.33
mmmaddpg vs mmmaddpg steps: 1449975, episodes: 58000, mean episode reward: 27.71448376889126, agent episode reward: [10.478688415043042, 10.259294842167662, 10.36983477484442, 10.313057929327647, -8.78867278262888, -4.917719409862629], time: 274.424
mmmaddpg vs mmmaddpg steps: 1474975, episodes: 59000, mean episode reward: 28.237706323565007, agent episode reward: [10.846648191964686, 10.61447619525541, 10.740834272874729, 10.685444199144799, -9.742196073344912, -4.907500462329708], time: 266.527
mmmaddpg vs mmmaddpg steps: 1499975, episodes: 60000, mean episode reward: 34.63399500154063, agent episode reward: [12.918287644445966, 12.761240222430784, 12.814979303596903, 12.759166178507614, -11.643369317043259, -4.976309030397371], time: 265.004
mmmaddpg vs mmmaddpg steps: 1524975, episodes: 61000, mean episode reward: 32.805731231187195, agent episode reward: [12.57837148937747, 12.372881242203716, 12.458019977493212, 12.344437626702666, -11.705483996988143, -5.242495107601728], time: 265.928
mmmaddpg vs mmmaddpg steps: 1549975, episodes: 62000, mean episode reward: 30.918094935192094, agent episode reward: [12.0750489892781, 11.928894824682333, 11.943188171955661, 11.77178999874347, -10.209069268591012, -6.591757780876459], time: 273.667
mmmaddpg vs mmmaddpg steps: 1574975, episodes: 63000, mean episode reward: 31.237859926895137, agent episode reward: [11.931360593071124, 11.773814928253854, 11.83036854867066, 11.830204322880164, -10.597399864102815, -5.530488601877842], time: 265.841
mmmaddpg vs mmmaddpg steps: 1599975, episodes: 64000, mean episode reward: 30.007335420915386, agent episode reward: [11.300355752961947, 11.13775883571676, 11.219223447418077, 11.14933639625791, -9.656721567310237, -5.142617444129072], time: 269.781
mmmaddpg vs mmmaddpg steps: 1624975, episodes: 65000, mean episode reward: 23.22252420355316, agent episode reward: [9.662739100960154, 9.50538261742345, 9.562276490374542, 9.481293451843168, -9.597415783795265, -5.391751673252886], time: 278.946
mmmaddpg vs mmmaddpg steps: 1649975, episodes: 66000, mean episode reward: 22.21884839648041, agent episode reward: [9.837795142675045, 9.70422854749225, 9.719901644177709, 9.650833829060575, -11.30015996078906, -5.39375080613611], time: 280.391
mmmaddpg vs mmmaddpg steps: 1674975, episodes: 67000, mean episode reward: 27.26245597196931, agent episode reward: [10.977196683922394, 10.875622912815496, 10.865952074346664, 10.819410377812186, -10.863529638648405, -5.412196438279031], time: 267.518
mmmaddpg vs mmmaddpg steps: 1699975, episodes: 68000, mean episode reward: 28.271469579154758, agent episode reward: [11.172852830901894, 11.096314701238805, 11.054828810729258, 11.083165267006374, -10.520616440428835, -5.615075590292736], time: 268.474
mmmaddpg vs mmmaddpg steps: 1724975, episodes: 69000, mean episode reward: 25.205815871513792, agent episode reward: [10.462679380951126, 10.399062366203568, 10.36003174146813, 10.296848235953886, -9.571567037152494, -6.741238815910423], time: 278.245
mmmaddpg vs mmmaddpg steps: 1749975, episodes: 70000, mean episode reward: 23.93103222320701, agent episode reward: [10.148870120226876, 10.05605116024625, 10.042991419402338, 10.040881861753086, -10.456638251517788, -5.90112408690375], time: 271.603
mmmaddpg vs mmmaddpg steps: 1774975, episodes: 71000, mean episode reward: 23.276883225396546, agent episode reward: [10.167131529665875, 9.956744761927853, 10.012217622324425, 9.995337171671668, -10.63557220603882, -6.218975654154461], time: 272.211
mmmaddpg vs mmmaddpg steps: 1799975, episodes: 72000, mean episode reward: 25.164477048023176, agent episode reward: [10.959603462385214, 10.743424036341258, 10.8096438614535, 10.80016642930725, -11.776564852775234, -6.371795888688812], time: 269.781
mmmaddpg vs mmmaddpg steps: 1824975, episodes: 73000, mean episode reward: 29.37558059005122, agent episode reward: [11.74213727377097, 11.600745409572852, 11.579761473813894, 11.661197246813455, -10.990500638716844, -6.217760175203108], time: 265.922
mmmaddpg vs mmmaddpg steps: 1849975, episodes: 74000, mean episode reward: 27.42161446326923, agent episode reward: [11.10544496448259, 11.010763170948831, 11.043942491603335, 11.043734494300796, -10.868199152744463, -5.914071505321863], time: 261.137
mmmaddpg vs mmmaddpg steps: 1874975, episodes: 75000, mean episode reward: 25.635869663721003, agent episode reward: [10.430007228743307, 10.229549450740176, 10.272568668967196, 10.276545131695668, -10.252885468018114, -5.319915348407233], time: 266.553
mmmaddpg vs mmmaddpg steps: 1899975, episodes: 76000, mean episode reward: 28.500646055998253, agent episode reward: [11.134930997995594, 11.020480316879224, 11.037449736902843, 11.013769606785248, -9.950756676291427, -5.755227926273228], time: 270.644
mmmaddpg vs mmmaddpg steps: 1924975, episodes: 77000, mean episode reward: 30.298307566333715, agent episode reward: [11.618953113442661, 11.511622957944471, 11.54174359369736, 11.51274203859773, -9.76262924864809, -6.124124888700414], time: 268.129
mmmaddpg vs mmmaddpg steps: 1949975, episodes: 78000, mean episode reward: 27.495263118454808, agent episode reward: [10.862277562272546, 10.78572827525917, 10.735936578019283, 10.752822953215667, -10.376573064812542, -5.264929185499315], time: 268.312
mmmaddpg vs mmmaddpg steps: 1974975, episodes: 79000, mean episode reward: 31.978448639338016, agent episode reward: [12.236510971497792, 12.08527305943658, 12.093315950829467, 12.029940248604872, -10.109433260728546, -6.357158330302143], time: 270.68
mmmaddpg vs mmmaddpg steps: 1999975, episodes: 80000, mean episode reward: 30.827319993031217, agent episode reward: [11.951358407319898, 11.824266131045613, 11.862800078901508, 11.828007074229408, -10.750442769475562, -5.888668928989646], time: 269.835
mmmaddpg vs mmmaddpg steps: 2024975, episodes: 81000, mean episode reward: 29.574577165104493, agent episode reward: [11.499284697452861, 11.373934730749832, 11.402835891029845, 11.44987945174667, -10.945149374679367, -5.206208231195353], time: 267.427
mmmaddpg vs mmmaddpg steps: 2049975, episodes: 82000, mean episode reward: 29.943690473151904, agent episode reward: [11.923427420750874, 11.810226206768863, 11.723195461706393, 11.844254289534813, -10.767488729822722, -6.589924175786321], time: 269.269
mmmaddpg vs mmmaddpg steps: 2074975, episodes: 83000, mean episode reward: 31.370954736964872, agent episode reward: [12.144076687272598, 11.979641058154957, 12.04019524666811, 12.04163166812685, -10.929204242639393, -5.90538568061825], time: 264.926
mmmaddpg vs mmmaddpg steps: 2099975, episodes: 84000, mean episode reward: 31.902516884302823, agent episode reward: [12.210667530394566, 12.132419493043598, 12.12520131918728, 12.110079666040495, -11.29405529847187, -5.381795825891252], time: 267.993
mmmaddpg vs mmmaddpg steps: 2124975, episodes: 85000, mean episode reward: 32.20071056783622, agent episode reward: [12.465091658962518, 12.342076652174727, 12.37527007929971, 12.352064522499534, -11.120960669353732, -6.212831675746544], time: 269.564
mmmaddpg vs mmmaddpg steps: 2149975, episodes: 86000, mean episode reward: 31.966325263642855, agent episode reward: [12.143517122527, 12.027046568804574, 12.072003588787485, 12.0538505071848, -10.385883611208136, -5.944208912452864], time: 269.601
mmmaddpg vs mmmaddpg steps: 2174975, episodes: 87000, mean episode reward: 31.837992520082274, agent episode reward: [12.325914315341675, 12.207449858793796, 12.225431798215094, 12.192081385010486, -11.010418173852079, -6.1024666634267], time: 272.888
mmmaddpg vs mmmaddpg steps: 2199975, episodes: 88000, mean episode reward: 32.18661385403876, agent episode reward: [12.346064358118102, 12.18697786414646, 12.271609587747415, 12.2467915545711, -10.87997093152544, -5.984858579018874], time: 263.654
mmmaddpg vs mmmaddpg steps: 2224975, episodes: 89000, mean episode reward: 32.770133472703336, agent episode reward: [12.520726816971061, 12.302231447281207, 12.412226333837648, 12.387465398788025, -11.452550915754408, -5.399965608420191], time: 266.745
mmmaddpg vs mmmaddpg steps: 2249975, episodes: 90000, mean episode reward: 33.99057331740458, agent episode reward: [12.817289225685206, 12.698538917836434, 12.713060987233856, 12.683289847399516, -11.570486164118137, -5.351119496632297], time: 276.071
mmmaddpg vs mmmaddpg steps: 2274975, episodes: 91000, mean episode reward: 32.26210566099129, agent episode reward: [12.5859868854482, 12.485854558566139, 12.51626695984396, 12.515452549146564, -11.647423049005427, -6.194032243008149], time: 269.672
mmmaddpg vs mmmaddpg steps: 2299975, episodes: 92000, mean episode reward: 32.994018193631426, agent episode reward: [12.672055190087347, 12.50474349072684, 12.580830181480334, 12.582487846045092, -11.601241100850574, -5.744857413857616], time: 270.685
mmmaddpg vs mmmaddpg steps: 2324975, episodes: 93000, mean episode reward: 32.70132121733227, agent episode reward: [12.671445098106911, 12.485688174690075, 12.531003465004003, 12.578996824912723, -11.541574840775738, -6.024237504605701], time: 276.338
mmmaddpg vs mmmaddpg steps: 2349975, episodes: 94000, mean episode reward: 32.93226382837025, agent episode reward: [12.688667050996862, 12.554700475135261, 12.568282443483058, 12.686310387712972, -11.244344270193585, -6.321352258764311], time: 269.869
mmmaddpg vs mmmaddpg steps: 2374975, episodes: 95000, mean episode reward: 30.08705933454746, agent episode reward: [12.277241337561332, 12.134501315015918, 12.145678119964893, 12.149919291264233, -12.405583191334804, -6.2146975379241045], time: 270.792
mmmaddpg vs mmmaddpg steps: 2399975, episodes: 96000, mean episode reward: 30.92047328346537, agent episode reward: [12.366162781004691, 12.157495603540186, 12.208245290681845, 12.17594613686483, -11.478603784471707, -6.508772744154474], time: 271.286
mmmaddpg vs mmmaddpg steps: 2424975, episodes: 97000, mean episode reward: 32.02858427584892, agent episode reward: [12.512556695187557, 12.3087782565806, 12.39171848754917, 12.355812016115971, -11.526426569329105, -6.013854610255277], time: 267.232
mmmaddpg vs mmmaddpg steps: 2449975, episodes: 98000, mean episode reward: 29.662496078349086, agent episode reward: [11.87273196556351, 11.697790410661783, 11.765235669597466, 11.734779538565643, -11.365432648268268, -6.042608857771053], time: 270.297
mmmaddpg vs mmmaddpg steps: 2474975, episodes: 99000, mean episode reward: 31.22022640921509, agent episode reward: [12.333902074458209, 12.148975201124475, 12.178532268781405, 12.231802751803494, -11.516848686913395, -6.156137200039095], time: 265.07
mmmaddpg vs mmmaddpg steps: 2499975, episodes: 100000, mean episode reward: 35.94221313559671, agent episode reward: [13.469939254697245, 13.272795496105793, 13.325380411879083, 13.388568461572524, -11.82693563137145, -5.687534857286487], time: 267.689
...Finished total of 100001 episodes.
