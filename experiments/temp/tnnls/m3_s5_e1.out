0 bad agents
      adv rate for q_index :  0 [1e-05, 0.001, 0.001]
      adv rate for p_index :  0 [1e-05, 0.001, 0.001]
1 good agents
      adv rate for q_index :  1 [0.001, 1e-05, 1e-05]
      adv rate for p_index :  1 [0.001, 1e-05, 1e-05]
2 good agents
      adv rate for q_index :  2 [0.001, 1e-05, 1e-05]
      adv rate for p_index :  2 [0.001, 1e-05, 1e-05]
Using good policy mmmaddpg and bad policy mmmaddpg with 1 adversaries
Starting iterations...
mmmaddpg vs mmmaddpg steps: 24975, episodes: 1000, mean episode reward: -25.093467899978812, agent episode reward: [-24.19800445169701, -0.4477317241408999, -0.4477317241408999], time: 54.071
mmmaddpg vs mmmaddpg steps: 49975, episodes: 2000, mean episode reward: -18.166060834393186, agent episode reward: [-17.606240838923878, -0.2799099977346533, -0.2799099977346533], time: 71.254
mmmaddpg vs mmmaddpg steps: 74975, episodes: 3000, mean episode reward: -2.8848133295448544, agent episode reward: [-16.908559060118016, 7.011872865286581, 7.011872865286581], time: 69.568
mmmaddpg vs mmmaddpg steps: 99975, episodes: 4000, mean episode reward: 12.499364783054066, agent episode reward: [-17.339670617310198, 14.919517700182132, 14.919517700182132], time: 69.863
mmmaddpg vs mmmaddpg steps: 124975, episodes: 5000, mean episode reward: 14.030261500087835, agent episode reward: [-16.128335056615303, 15.079298278351569, 15.079298278351569], time: 69.805
mmmaddpg vs mmmaddpg steps: 149975, episodes: 6000, mean episode reward: 15.836809366532986, agent episode reward: [-17.64110061953994, 16.73895499303646, 16.73895499303646], time: 70.55
mmmaddpg vs mmmaddpg steps: 174975, episodes: 7000, mean episode reward: 16.23851377944206, agent episode reward: [-17.918770898042716, 17.07864233874239, 17.07864233874239], time: 69.723
mmmaddpg vs mmmaddpg steps: 199975, episodes: 8000, mean episode reward: 15.206036011810678, agent episode reward: [-16.7613246623901, 15.983680337100388, 15.983680337100388], time: 70.253
mmmaddpg vs mmmaddpg steps: 224975, episodes: 9000, mean episode reward: 15.881928932051457, agent episode reward: [-17.401044938598933, 16.641486935325194, 16.641486935325194], time: 70.103
mmmaddpg vs mmmaddpg steps: 249975, episodes: 10000, mean episode reward: 15.227024695806367, agent episode reward: [-16.785893645402812, 16.006459170604586, 16.006459170604586], time: 70.213
mmmaddpg vs mmmaddpg steps: 274975, episodes: 11000, mean episode reward: 15.363807007915183, agent episode reward: [-16.8321300624536, 16.097968535184393, 16.097968535184393], time: 70.69
mmmaddpg vs mmmaddpg steps: 299975, episodes: 12000, mean episode reward: 15.74684130226971, agent episode reward: [-17.30945021996319, 16.528145761116452, 16.528145761116452], time: 69.74
mmmaddpg vs mmmaddpg steps: 324975, episodes: 13000, mean episode reward: 14.854092413950964, agent episode reward: [-16.411227908783516, 15.63266016136724, 15.63266016136724], time: 69.976
mmmaddpg vs mmmaddpg steps: 349975, episodes: 14000, mean episode reward: 15.835509294447458, agent episode reward: [-17.32719831634667, 16.58135380539706, 16.58135380539706], time: 69.946
mmmaddpg vs mmmaddpg steps: 374975, episodes: 15000, mean episode reward: 15.036209159777416, agent episode reward: [-16.58205808408961, 15.809133621933514, 15.809133621933514], time: 69.652
mmmaddpg vs mmmaddpg steps: 399975, episodes: 16000, mean episode reward: 15.726674677759322, agent episode reward: [-17.20626683972089, 16.466470758740105, 16.466470758740105], time: 70.525
mmmaddpg vs mmmaddpg steps: 424975, episodes: 17000, mean episode reward: 15.11979712934715, agent episode reward: [-16.56105591086745, 15.8404265201073, 15.8404265201073], time: 70.24
mmmaddpg vs mmmaddpg steps: 449975, episodes: 18000, mean episode reward: 15.561627796204109, agent episode reward: [-17.097424493732017, 16.329526144968064, 16.329526144968064], time: 70.542
mmmaddpg vs mmmaddpg steps: 474975, episodes: 19000, mean episode reward: 15.322066916433581, agent episode reward: [-16.706443143178465, 16.014255029806023, 16.014255029806023], time: 70.944
mmmaddpg vs mmmaddpg steps: 499975, episodes: 20000, mean episode reward: 15.07830122877839, agent episode reward: [-16.497707666558686, 15.788004447668536, 15.788004447668536], time: 70.603
mmmaddpg vs mmmaddpg steps: 524975, episodes: 21000, mean episode reward: 15.2271161249329, agent episode reward: [-16.633410091907034, 15.930263108419968, 15.930263108419968], time: 70.416
mmmaddpg vs mmmaddpg steps: 549975, episodes: 22000, mean episode reward: 15.360960654678147, agent episode reward: [-16.79709349152051, 16.07902707309933, 16.07902707309933], time: 70.599
mmmaddpg vs mmmaddpg steps: 574975, episodes: 23000, mean episode reward: 15.200291669461592, agent episode reward: [-16.624128684894064, 15.91221017717783, 15.91221017717783], time: 69.908
mmmaddpg vs mmmaddpg steps: 599975, episodes: 24000, mean episode reward: 15.14786527411575, agent episode reward: [-16.610574829912277, 15.879220052014015, 15.879220052014015], time: 70.289
mmmaddpg vs mmmaddpg steps: 624975, episodes: 25000, mean episode reward: 15.311093198907214, agent episode reward: [-16.71952708816758, 16.0153101435374, 16.0153101435374], time: 69.974
mmmaddpg vs mmmaddpg steps: 649975, episodes: 26000, mean episode reward: 15.33195358442011, agent episode reward: [-16.790046353075972, 16.060999968748042, 16.060999968748042], time: 70.845
mmmaddpg vs mmmaddpg steps: 674975, episodes: 27000, mean episode reward: 15.220565193247774, agent episode reward: [-16.622276793961973, 15.921420993604876, 15.921420993604876], time: 69.035
mmmaddpg vs mmmaddpg steps: 699975, episodes: 28000, mean episode reward: 15.230212252214457, agent episode reward: [-16.675424024764173, 15.952818138489315, 15.952818138489315], time: 70.635
mmmaddpg vs mmmaddpg steps: 724975, episodes: 29000, mean episode reward: 15.39263605669557, agent episode reward: [-16.77341636885517, 16.083026212775373, 16.083026212775373], time: 69.944
mmmaddpg vs mmmaddpg steps: 749975, episodes: 30000, mean episode reward: 15.237456669150294, agent episode reward: [-16.668994894203585, 15.953225781676938, 15.953225781676938], time: 70.751
mmmaddpg vs mmmaddpg steps: 774975, episodes: 31000, mean episode reward: 15.159201130030146, agent episode reward: [-16.584708381011968, 15.87195475552106, 15.87195475552106], time: 70.424
mmmaddpg vs mmmaddpg steps: 799975, episodes: 32000, mean episode reward: 15.132605415414828, agent episode reward: [-16.591796182687183, 15.862200799051006, 15.862200799051006], time: 69.627
mmmaddpg vs mmmaddpg steps: 824975, episodes: 33000, mean episode reward: 15.207552895135802, agent episode reward: [-16.61821038709004, 15.912881641112923, 15.912881641112923], time: 70.673
mmmaddpg vs mmmaddpg steps: 849975, episodes: 34000, mean episode reward: 15.126804002284889, agent episode reward: [-16.72300575088895, 15.92490487658692, 15.92490487658692], time: 71.022
mmmaddpg vs mmmaddpg steps: 874975, episodes: 35000, mean episode reward: 15.159458485995238, agent episode reward: [-16.606533247702597, 15.882995866848916, 15.882995866848916], time: 70.614
mmmaddpg vs mmmaddpg steps: 899975, episodes: 36000, mean episode reward: 15.266439108204601, agent episode reward: [-16.67532196268444, 15.970880535444522, 15.970880535444522], time: 63.984
mmmaddpg vs mmmaddpg steps: 924975, episodes: 37000, mean episode reward: 15.148267830985153, agent episode reward: [-16.511832276201922, 15.830050053593535, 15.830050053593535], time: 57.051
mmmaddpg vs mmmaddpg steps: 949975, episodes: 38000, mean episode reward: 15.204709105938889, agent episode reward: [-16.707636756245517, 15.956172931092201, 15.956172931092201], time: 55.396
mmmaddpg vs mmmaddpg steps: 974975, episodes: 39000, mean episode reward: 15.34344840064292, agent episode reward: [-16.747526291567905, 16.04548734610541, 16.04548734610541], time: 57.31
mmmaddpg vs mmmaddpg steps: 999975, episodes: 40000, mean episode reward: 15.25480183276101, agent episode reward: [-16.65708276953794, 15.955942301149477, 15.955942301149477], time: 56.967
mmmaddpg vs mmmaddpg steps: 1024975, episodes: 41000, mean episode reward: 15.36306065929233, agent episode reward: [-16.81067013814641, 16.086865398719368, 16.086865398719368], time: 57.908
mmmaddpg vs mmmaddpg steps: 1049975, episodes: 42000, mean episode reward: 15.350911113252259, agent episode reward: [-16.81286744238009, 16.08188927781617, 16.08188927781617], time: 58.94
mmmaddpg vs mmmaddpg steps: 1074975, episodes: 43000, mean episode reward: 15.310788100713511, agent episode reward: [-16.766862781161922, 16.038825440937718, 16.038825440937718], time: 56.864
mmmaddpg vs mmmaddpg steps: 1099975, episodes: 44000, mean episode reward: 15.375677796199703, agent episode reward: [-16.834515563249976, 16.10509667972484, 16.10509667972484], time: 58.684
mmmaddpg vs mmmaddpg steps: 1124975, episodes: 45000, mean episode reward: 14.723492242821496, agent episode reward: [-16.469398724635997, 15.596445483728749, 15.596445483728749], time: 56.787
mmmaddpg vs mmmaddpg steps: 1149975, episodes: 46000, mean episode reward: 15.612171545594087, agent episode reward: [-17.39427415966588, 16.503222852629985, 16.503222852629985], time: 59.404
mmmaddpg vs mmmaddpg steps: 1174975, episodes: 47000, mean episode reward: 11.86932155312473, agent episode reward: [-14.5336267140132, 13.201474133568965, 13.201474133568965], time: 58.172
mmmaddpg vs mmmaddpg steps: 1199975, episodes: 48000, mean episode reward: 15.443362504194523, agent episode reward: [-16.84556545425276, 16.14446397922364, 16.14446397922364], time: 57.442
mmmaddpg vs mmmaddpg steps: 1224975, episodes: 49000, mean episode reward: 15.748396749849384, agent episode reward: [-17.284007472443285, 16.51620211114633, 16.51620211114633], time: 57.811
mmmaddpg vs mmmaddpg steps: 1249975, episodes: 50000, mean episode reward: 15.188375536931161, agent episode reward: [-16.72907946955893, 15.958727503245045, 15.958727503245045], time: 56.593
mmmaddpg vs mmmaddpg steps: 1274975, episodes: 51000, mean episode reward: 15.315602903842555, agent episode reward: [-16.933152254726465, 16.12437757928451, 16.12437757928451], time: 58.187
mmmaddpg vs mmmaddpg steps: 1299975, episodes: 52000, mean episode reward: 15.45877337277755, agent episode reward: [-16.996841403763465, 16.227807388270506, 16.227807388270506], time: 58.136
mmmaddpg vs mmmaddpg steps: 1324975, episodes: 53000, mean episode reward: 15.026044453820093, agent episode reward: [-16.56971866740896, 15.797881560614526, 15.797881560614526], time: 58.73
mmmaddpg vs mmmaddpg steps: 1349975, episodes: 54000, mean episode reward: 15.057427371062492, agent episode reward: [-16.533770401251793, 15.79559888615714, 15.79559888615714], time: 56.524
mmmaddpg vs mmmaddpg steps: 1374975, episodes: 55000, mean episode reward: 15.195150737401882, agent episode reward: [-16.662957578594696, 15.929054157998289, 15.929054157998289], time: 56.382
mmmaddpg vs mmmaddpg steps: 1399975, episodes: 56000, mean episode reward: 14.894854591229196, agent episode reward: [-16.49208055060877, 15.693467570918981, 15.693467570918981], time: 56.888
mmmaddpg vs mmmaddpg steps: 1424975, episodes: 57000, mean episode reward: 15.118338673234478, agent episode reward: [-16.69759032873384, 15.907964500984157, 15.907964500984157], time: 56.99
mmmaddpg vs mmmaddpg steps: 1449975, episodes: 58000, mean episode reward: 15.226302254226294, agent episode reward: [-16.732916983515146, 15.979609618870718, 15.979609618870718], time: 57.865
mmmaddpg vs mmmaddpg steps: 1474975, episodes: 59000, mean episode reward: 15.199374775631492, agent episode reward: [-16.719899801716252, 15.959637288673871, 15.959637288673871], time: 56.887
mmmaddpg vs mmmaddpg steps: 1499975, episodes: 60000, mean episode reward: 16.00672424945299, agent episode reward: [-17.63573818252011, 16.821231215986547, 16.821231215986547], time: 58.868
mmmaddpg vs mmmaddpg steps: 1524975, episodes: 61000, mean episode reward: 11.60735160568853, agent episode reward: [-18.270714501976894, 14.939033053832713, 14.939033053832713], time: 58.075
mmmaddpg vs mmmaddpg steps: 1549975, episodes: 62000, mean episode reward: 14.581479466689549, agent episode reward: [-16.20956185918742, 15.395520662938484, 15.395520662938484], time: 58.211
mmmaddpg vs mmmaddpg steps: 1574975, episodes: 63000, mean episode reward: 11.390061343216605, agent episode reward: [-18.550263254109165, 14.970162298662887, 14.970162298662887], time: 58.85
mmmaddpg vs mmmaddpg steps: 1599975, episodes: 64000, mean episode reward: 14.063088605858805, agent episode reward: [-19.08721678981877, 16.575152697838785, 16.575152697838785], time: 58.811
mmmaddpg vs mmmaddpg steps: 1624975, episodes: 65000, mean episode reward: 12.665318304701843, agent episode reward: [-16.568916654984083, 14.61711747984296, 14.61711747984296], time: 57.914
mmmaddpg vs mmmaddpg steps: 1649975, episodes: 66000, mean episode reward: 16.287808923479204, agent episode reward: [-17.870506390366945, 17.079157656923076, 17.079157656923076], time: 56.627
mmmaddpg vs mmmaddpg steps: 1674975, episodes: 67000, mean episode reward: 13.814609176153331, agent episode reward: [-15.490890280019864, 14.652749728086597, 14.652749728086597], time: 56.633
mmmaddpg vs mmmaddpg steps: 1699975, episodes: 68000, mean episode reward: 16.199209371227674, agent episode reward: [-17.682189161012765, 16.940699266120216, 16.940699266120216], time: 58.189
mmmaddpg vs mmmaddpg steps: 1724975, episodes: 69000, mean episode reward: 18.434352051045543, agent episode reward: [-20.793261580848224, 19.613806815946884, 19.613806815946884], time: 57.059
mmmaddpg vs mmmaddpg steps: 1749975, episodes: 70000, mean episode reward: 14.767172809880103, agent episode reward: [-17.205859015246627, 15.986515912563366, 15.986515912563366], time: 57.658
mmmaddpg vs mmmaddpg steps: 1774975, episodes: 71000, mean episode reward: 15.41207780285474, agent episode reward: [-17.19437979358071, 16.303228798217724, 16.303228798217724], time: 57.576
mmmaddpg vs mmmaddpg steps: 1799975, episodes: 72000, mean episode reward: 14.96667327746028, agent episode reward: [-16.69793252137943, 15.832302899419856, 15.832302899419856], time: 56.595
mmmaddpg vs mmmaddpg steps: 1824975, episodes: 73000, mean episode reward: 14.509455443768825, agent episode reward: [-16.05987680666413, 15.284666125216477, 15.284666125216477], time: 56.539
mmmaddpg vs mmmaddpg steps: 1849975, episodes: 74000, mean episode reward: 16.28620287900819, agent episode reward: [-17.816377119991543, 17.051289999499865, 17.051289999499865], time: 56.958
mmmaddpg vs mmmaddpg steps: 1874975, episodes: 75000, mean episode reward: 16.07103175141766, agent episode reward: [-17.692236215081643, 16.881633983249653, 16.881633983249653], time: 55.694
mmmaddpg vs mmmaddpg steps: 1899975, episodes: 76000, mean episode reward: 16.807176013107416, agent episode reward: [-18.443369621101535, 17.625272817104474, 17.625272817104474], time: 58.094
mmmaddpg vs mmmaddpg steps: 1924975, episodes: 77000, mean episode reward: 15.170543937009912, agent episode reward: [-16.922673994650598, 16.046608965830252, 16.046608965830252], time: 57.469
mmmaddpg vs mmmaddpg steps: 1949975, episodes: 78000, mean episode reward: 14.788820931849205, agent episode reward: [-16.370645451770812, 15.579733191810007, 15.579733191810007], time: 55.604
mmmaddpg vs mmmaddpg steps: 1974975, episodes: 79000, mean episode reward: 14.936519617942274, agent episode reward: [-16.418037287875674, 15.677278452908975, 15.677278452908975], time: 57.711
mmmaddpg vs mmmaddpg steps: 1999975, episodes: 80000, mean episode reward: 15.76453083694382, agent episode reward: [-17.640198217589575, 16.7023645272667, 16.7023645272667], time: 57.153
mmmaddpg vs mmmaddpg steps: 2024975, episodes: 81000, mean episode reward: 14.976205196174625, agent episode reward: [-16.96152198068233, 15.96886358842848, 15.96886358842848], time: 58.733
mmmaddpg vs mmmaddpg steps: 2049975, episodes: 82000, mean episode reward: 15.20077326036171, agent episode reward: [-16.839792706584475, 16.02028298347309, 16.02028298347309], time: 59.295
mmmaddpg vs mmmaddpg steps: 2074975, episodes: 83000, mean episode reward: 15.51976602794827, agent episode reward: [-17.19929822107759, 16.35953212451293, 16.35953212451293], time: 56.762
mmmaddpg vs mmmaddpg steps: 2099975, episodes: 84000, mean episode reward: 15.014479550350893, agent episode reward: [-16.636810167404523, 15.825644858877705, 15.825644858877705], time: 56.057
mmmaddpg vs mmmaddpg steps: 2124975, episodes: 85000, mean episode reward: 15.165333200179054, agent episode reward: [-16.626491172469933, 15.895912186324495, 15.895912186324495], time: 58.205
mmmaddpg vs mmmaddpg steps: 2149975, episodes: 86000, mean episode reward: 15.30641693400081, agent episode reward: [-16.830148722619015, 16.068282828309915, 16.068282828309915], time: 56.869
mmmaddpg vs mmmaddpg steps: 2174975, episodes: 87000, mean episode reward: 15.436912890996604, agent episode reward: [-16.87011846109542, 16.153515676046013, 16.153515676046013], time: 57.201
mmmaddpg vs mmmaddpg steps: 2199975, episodes: 88000, mean episode reward: 15.269969870011215, agent episode reward: [-16.79060310725673, 16.03028648863397, 16.03028648863397], time: 57.773
mmmaddpg vs mmmaddpg steps: 2224975, episodes: 89000, mean episode reward: 15.28745575674679, agent episode reward: [-16.8641941136569, 16.075824935201847, 16.075824935201847], time: 58.486
mmmaddpg vs mmmaddpg steps: 2249975, episodes: 90000, mean episode reward: 15.188275173059228, agent episode reward: [-16.76836908139386, 15.978322127226543, 15.978322127226543], time: 57.456
mmmaddpg vs mmmaddpg steps: 2274975, episodes: 91000, mean episode reward: 15.247781018411363, agent episode reward: [-16.7706781854048, 16.009229601908086, 16.009229601908086], time: 56.848
mmmaddpg vs mmmaddpg steps: 2299975, episodes: 92000, mean episode reward: 15.46497949854143, agent episode reward: [-17.026525117587422, 16.245752308064425, 16.245752308064425], time: 57.4
mmmaddpg vs mmmaddpg steps: 2324975, episodes: 93000, mean episode reward: 15.212099016728052, agent episode reward: [-16.950649866882568, 16.081374441805306, 16.081374441805306], time: 57.301
mmmaddpg vs mmmaddpg steps: 2349975, episodes: 94000, mean episode reward: 14.681925009655536, agent episode reward: [-16.41841253157292, 15.550168770614226, 15.550168770614226], time: 57.479
mmmaddpg vs mmmaddpg steps: 2374975, episodes: 95000, mean episode reward: 15.025555431767524, agent episode reward: [-16.537881013459184, 15.781718222613353, 15.781718222613353], time: 58.644
mmmaddpg vs mmmaddpg steps: 2399975, episodes: 96000, mean episode reward: 14.758429107490278, agent episode reward: [-16.285802373244596, 15.522115740367436, 15.522115740367436], time: 55.776
mmmaddpg vs mmmaddpg steps: 2424975, episodes: 97000, mean episode reward: 15.367472785436362, agent episode reward: [-16.867417707324815, 16.117445246380587, 16.117445246380587], time: 58.264
mmmaddpg vs mmmaddpg steps: 2449975, episodes: 98000, mean episode reward: 15.468368014203396, agent episode reward: [-17.009925795496663, 16.239146904850028, 16.239146904850028], time: 57.919
mmmaddpg vs mmmaddpg steps: 2474975, episodes: 99000, mean episode reward: 15.380979858032394, agent episode reward: [-16.89818515405369, 16.13958250604304, 16.13958250604304], time: 55.133
mmmaddpg vs mmmaddpg steps: 2499975, episodes: 100000, mean episode reward: 14.859342000190825, agent episode reward: [-16.587536915813892, 15.72343945800236, 15.72343945800236], time: 55.234
...Finished total of 100001 episodes.
5], time: 57.679
...Finished total of 100001 episodes.
