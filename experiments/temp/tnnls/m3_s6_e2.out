0 bad agents
      adv rate for q_index :  0 [1e-05, 0.001]
      adv rate for p_index :  0 [1e-05, 0.001]
1 good agents
      adv rate for q_index :  1 [0.001, 1e-05]
      adv rate for p_index :  1 [0.001, 1e-05]
Using good policy mmmaddpg and bad policy mmmaddpg with 1 adversaries
Starting iterations...
mmmaddpg vs mmmaddpg steps: 24975, episodes: 1000, mean episode reward: -27.952088911232924, agent episode reward: [-0.9672103920717113, -26.984878519161214], time: 34.306
mmmaddpg vs mmmaddpg steps: 49975, episodes: 2000, mean episode reward: -18.834762528160265, agent episode reward: [-3.410834327363676, -15.423928200796588], time: 47.189
mmmaddpg vs mmmaddpg steps: 74975, episodes: 3000, mean episode reward: -10.815131264566546, agent episode reward: [-4.12366408669652, -6.691467177870025], time: 46.183
mmmaddpg vs mmmaddpg steps: 99975, episodes: 4000, mean episode reward: -9.44891626174876, agent episode reward: [-2.6595067160381904, -6.78940954571057], time: 46.145
mmmaddpg vs mmmaddpg steps: 124975, episodes: 5000, mean episode reward: -8.890926815777293, agent episode reward: [-2.2911479971558846, -6.5997788186214095], time: 46.68
mmmaddpg vs mmmaddpg steps: 149975, episodes: 6000, mean episode reward: -9.079385355292217, agent episode reward: [-2.3691693700361487, -6.710215985256068], time: 46.999
mmmaddpg vs mmmaddpg steps: 174975, episodes: 7000, mean episode reward: -8.85575041795861, agent episode reward: [-2.2002623914638306, -6.6554880264947816], time: 47.267
mmmaddpg vs mmmaddpg steps: 199975, episodes: 8000, mean episode reward: -8.785141361781797, agent episode reward: [-1.9537684834130342, -6.831372878368762], time: 47.54
mmmaddpg vs mmmaddpg steps: 224975, episodes: 9000, mean episode reward: -9.004882353479385, agent episode reward: [-2.095433575302955, -6.909448778176429], time: 47.231
mmmaddpg vs mmmaddpg steps: 249975, episodes: 10000, mean episode reward: -8.7793825451335, agent episode reward: [-2.058182900743055, -6.721199644390444], time: 46.932
mmmaddpg vs mmmaddpg steps: 274975, episodes: 11000, mean episode reward: -8.90840089115738, agent episode reward: [-2.1730641519136586, -6.735336739243722], time: 47.065
mmmaddpg vs mmmaddpg steps: 299975, episodes: 12000, mean episode reward: -8.671052972925198, agent episode reward: [-1.9540981585278394, -6.716954814397357], time: 46.917
mmmaddpg vs mmmaddpg steps: 324975, episodes: 13000, mean episode reward: -8.945564171073991, agent episode reward: [-2.325128086810572, -6.620436084263419], time: 46.91
mmmaddpg vs mmmaddpg steps: 349975, episodes: 14000, mean episode reward: -8.706244760580855, agent episode reward: [-2.2740321416598577, -6.432212618920997], time: 46.462
mmmaddpg vs mmmaddpg steps: 374975, episodes: 15000, mean episode reward: -8.718222597323201, agent episode reward: [-1.993268940845714, -6.724953656477486], time: 47.309
mmmaddpg vs mmmaddpg steps: 399975, episodes: 16000, mean episode reward: -8.709138604285647, agent episode reward: [-1.930896572793724, -6.7782420314919225], time: 47.198
mmmaddpg vs mmmaddpg steps: 424975, episodes: 17000, mean episode reward: -8.54706639940021, agent episode reward: [-1.8563306880695158, -6.690735711330693], time: 47.18
mmmaddpg vs mmmaddpg steps: 449975, episodes: 18000, mean episode reward: -8.44462778733416, agent episode reward: [-1.7724922017032982, -6.67213558563086], time: 46.05
mmmaddpg vs mmmaddpg steps: 474975, episodes: 19000, mean episode reward: -8.557136521712911, agent episode reward: [-2.004114738896588, -6.553021782816322], time: 46.946
mmmaddpg vs mmmaddpg steps: 499975, episodes: 20000, mean episode reward: -8.762426204627625, agent episode reward: [-2.1633702261642074, -6.599055978463417], time: 46.94
mmmaddpg vs mmmaddpg steps: 524975, episodes: 21000, mean episode reward: -8.664751882798644, agent episode reward: [-2.106473401184463, -6.558278481614181], time: 46.801
mmmaddpg vs mmmaddpg steps: 549975, episodes: 22000, mean episode reward: -8.680111201986003, agent episode reward: [-1.925881363820391, -6.754229838165611], time: 46.431
mmmaddpg vs mmmaddpg steps: 574975, episodes: 23000, mean episode reward: -8.591450315092693, agent episode reward: [-1.9278849454953975, -6.663565369597296], time: 46.867
mmmaddpg vs mmmaddpg steps: 599975, episodes: 24000, mean episode reward: -8.716252656602515, agent episode reward: [-1.6347227276271792, -7.0815299289753355], time: 47.558
mmmaddpg vs mmmaddpg steps: 624975, episodes: 25000, mean episode reward: -8.897957314787725, agent episode reward: [-1.9721752441874214, -6.925782070600304], time: 45.874
mmmaddpg vs mmmaddpg steps: 649975, episodes: 26000, mean episode reward: -8.79428560502262, agent episode reward: [-1.6046037991760664, -7.189681805846554], time: 46.807
mmmaddpg vs mmmaddpg steps: 674975, episodes: 27000, mean episode reward: -8.736844034624177, agent episode reward: [-1.0361228313404063, -7.700721203283771], time: 46.964
mmmaddpg vs mmmaddpg steps: 699975, episodes: 28000, mean episode reward: -8.864429138448232, agent episode reward: [-1.2134808826971588, -7.6509482557510715], time: 46.998
mmmaddpg vs mmmaddpg steps: 724975, episodes: 29000, mean episode reward: -8.756411688225239, agent episode reward: [-1.8669656301533817, -6.889446058071857], time: 46.743
mmmaddpg vs mmmaddpg steps: 749975, episodes: 30000, mean episode reward: -8.489871995406432, agent episode reward: [-1.6627559492207336, -6.827116046185698], time: 46.84
mmmaddpg vs mmmaddpg steps: 774975, episodes: 31000, mean episode reward: -8.571220105761762, agent episode reward: [-1.3368961044667353, -7.234324001295026], time: 45.918
mmmaddpg vs mmmaddpg steps: 799975, episodes: 32000, mean episode reward: -8.776695395554372, agent episode reward: [-1.4371068048714286, -7.339588590682944], time: 46.323
mmmaddpg vs mmmaddpg steps: 824975, episodes: 33000, mean episode reward: -8.493611069500947, agent episode reward: [-1.216678701835256, -7.276932367665691], time: 46.604
mmmaddpg vs mmmaddpg steps: 849975, episodes: 34000, mean episode reward: -8.633327981354828, agent episode reward: [-1.0067554412388058, -7.626572540116023], time: 46.315
mmmaddpg vs mmmaddpg steps: 874975, episodes: 35000, mean episode reward: -8.362261036336083, agent episode reward: [-0.4813643753247784, -7.880896661011305], time: 46.606
mmmaddpg vs mmmaddpg steps: 899975, episodes: 36000, mean episode reward: -8.892620243906949, agent episode reward: [-1.4547754588018929, -7.437844785105055], time: 46.939
mmmaddpg vs mmmaddpg steps: 924975, episodes: 37000, mean episode reward: -8.680200442112943, agent episode reward: [-1.1622974435077444, -7.517902998605197], time: 47.447
mmmaddpg vs mmmaddpg steps: 949975, episodes: 38000, mean episode reward: -8.451459155146138, agent episode reward: [-0.9962956132405612, -7.455163541905578], time: 46.995
mmmaddpg vs mmmaddpg steps: 974975, episodes: 39000, mean episode reward: -8.38228418196298, agent episode reward: [-0.7362328946920416, -7.6460512872709385], time: 46.586
mmmaddpg vs mmmaddpg steps: 999975, episodes: 40000, mean episode reward: -8.394063189333757, agent episode reward: [-0.9056386435629765, -7.488424545770778], time: 45.94
mmmaddpg vs mmmaddpg steps: 1024975, episodes: 41000, mean episode reward: -8.537502380605522, agent episode reward: [-0.6725897263632705, -7.86491265424225], time: 47.327
mmmaddpg vs mmmaddpg steps: 1049975, episodes: 42000, mean episode reward: -8.823952543933864, agent episode reward: [-1.203903625750329, -7.6200489181835325], time: 46.422
mmmaddpg vs mmmaddpg steps: 1074975, episodes: 43000, mean episode reward: -8.918524885788255, agent episode reward: [-1.306266929269958, -7.612257956518296], time: 46.441
mmmaddpg vs mmmaddpg steps: 1099975, episodes: 44000, mean episode reward: -8.944284573569218, agent episode reward: [-1.3646869878431824, -7.579597585726036], time: 45.417
mmmaddpg vs mmmaddpg steps: 1124975, episodes: 45000, mean episode reward: -8.876120211992973, agent episode reward: [-1.6231065841927463, -7.253013627800226], time: 46.203
mmmaddpg vs mmmaddpg steps: 1149975, episodes: 46000, mean episode reward: -8.682743457152004, agent episode reward: [-1.2710531170203558, -7.411690340131649], time: 45.756
mmmaddpg vs mmmaddpg steps: 1174975, episodes: 47000, mean episode reward: -9.12405047562882, agent episode reward: [-0.962757059470518, -8.161293416158303], time: 45.759
mmmaddpg vs mmmaddpg steps: 1199975, episodes: 48000, mean episode reward: -9.035831607348698, agent episode reward: [-1.0062074875684202, -8.029624119780276], time: 46.116
mmmaddpg vs mmmaddpg steps: 1224975, episodes: 49000, mean episode reward: -8.846140070100297, agent episode reward: [-1.5470938358919801, -7.2990462342083156], time: 46.237
mmmaddpg vs mmmaddpg steps: 1249975, episodes: 50000, mean episode reward: -8.760863538524886, agent episode reward: [-1.3810970289388798, -7.3797665095860046], time: 45.599
mmmaddpg vs mmmaddpg steps: 1274975, episodes: 51000, mean episode reward: -9.414654429219688, agent episode reward: [-2.0190934639736784, -7.395560965246011], time: 45.177
mmmaddpg vs mmmaddpg steps: 1299975, episodes: 52000, mean episode reward: -8.77971793967947, agent episode reward: [-1.5575836931946578, -7.222134246484813], time: 45.247
mmmaddpg vs mmmaddpg steps: 1324975, episodes: 53000, mean episode reward: -8.751994197489001, agent episode reward: [-1.077299636812281, -7.674694560676721], time: 45.388
mmmaddpg vs mmmaddpg steps: 1349975, episodes: 54000, mean episode reward: -8.815144734662704, agent episode reward: [-0.8308581524541145, -7.984286582208591], time: 45.996
mmmaddpg vs mmmaddpg steps: 1374975, episodes: 55000, mean episode reward: -8.60901998403311, agent episode reward: [-1.1241431718707424, -7.484876812162367], time: 46.39
mmmaddpg vs mmmaddpg steps: 1399975, episodes: 56000, mean episode reward: -8.819635058101918, agent episode reward: [-1.1733197430573497, -7.6463153150445695], time: 46.143
mmmaddpg vs mmmaddpg steps: 1424975, episodes: 57000, mean episode reward: -8.776878796455305, agent episode reward: [-1.1269263694411793, -7.649952427014125], time: 45.861
mmmaddpg vs mmmaddpg steps: 1449975, episodes: 58000, mean episode reward: -8.748860592345086, agent episode reward: [-1.9827903683875283, -6.7660702239575565], time: 46.091
mmmaddpg vs mmmaddpg steps: 1474975, episodes: 59000, mean episode reward: -9.015787210746263, agent episode reward: [-2.3299695840206005, -6.685817626725663], time: 46.148
mmmaddpg vs mmmaddpg steps: 1499975, episodes: 60000, mean episode reward: -8.80297166446931, agent episode reward: [-2.338578014712642, -6.4643936497566665], time: 45.858
mmmaddpg vs mmmaddpg steps: 1524975, episodes: 61000, mean episode reward: -8.930711838326554, agent episode reward: [-2.001813695085623, -6.9288981432409305], time: 45.029
mmmaddpg vs mmmaddpg steps: 1549975, episodes: 62000, mean episode reward: -8.643120333684546, agent episode reward: [-1.8766292996124787, -6.766491034072067], time: 45.922
mmmaddpg vs mmmaddpg steps: 1574975, episodes: 63000, mean episode reward: -8.841761036019046, agent episode reward: [-1.9616728125410368, -6.8800882234780065], time: 46.536
mmmaddpg vs mmmaddpg steps: 1599975, episodes: 64000, mean episode reward: -8.633871991227702, agent episode reward: [-1.9554437490792766, -6.678428242148424], time: 46.394
mmmaddpg vs mmmaddpg steps: 1624975, episodes: 65000, mean episode reward: -8.808858771396704, agent episode reward: [-2.0637426522105002, -6.7451161191862035], time: 46.311
mmmaddpg vs mmmaddpg steps: 1649975, episodes: 66000, mean episode reward: -8.74261971719713, agent episode reward: [-2.1314591931942433, -6.6111605240028855], time: 46.497
mmmaddpg vs mmmaddpg steps: 1674975, episodes: 67000, mean episode reward: -8.816738420306967, agent episode reward: [-1.9630597557009617, -6.853678664606006], time: 46.269
mmmaddpg vs mmmaddpg steps: 1699975, episodes: 68000, mean episode reward: -8.69128037395461, agent episode reward: [-1.879533328590414, -6.811747045364198], time: 46.553
mmmaddpg vs mmmaddpg steps: 1724975, episodes: 69000, mean episode reward: -8.37471331271806, agent episode reward: [-1.6599375132549845, -6.714775799463074], time: 45.883
mmmaddpg vs mmmaddpg steps: 1749975, episodes: 70000, mean episode reward: -8.717459393282905, agent episode reward: [-1.7169665248167902, -7.000492868466114], time: 45.728
mmmaddpg vs mmmaddpg steps: 1774975, episodes: 71000, mean episode reward: -8.305179420533484, agent episode reward: [-1.4592577936374576, -6.845921626896027], time: 45.226
mmmaddpg vs mmmaddpg steps: 1799975, episodes: 72000, mean episode reward: -8.726280700213055, agent episode reward: [-1.541465710525221, -7.1848149896878315], time: 45.288
mmmaddpg vs mmmaddpg steps: 1824975, episodes: 73000, mean episode reward: -8.590881905558144, agent episode reward: [-1.4175425508380535, -7.173339354720091], time: 44.916
mmmaddpg vs mmmaddpg steps: 1849975, episodes: 74000, mean episode reward: -8.496436938423646, agent episode reward: [-1.569432138388001, -6.927004800035643], time: 44.987
mmmaddpg vs mmmaddpg steps: 1874975, episodes: 75000, mean episode reward: -8.611974493844906, agent episode reward: [-1.7421512132561143, -6.869823280588791], time: 45.124
mmmaddpg vs mmmaddpg steps: 1899975, episodes: 76000, mean episode reward: -8.645055577520132, agent episode reward: [-1.9868293707707738, -6.658226206749359], time: 45.401
mmmaddpg vs mmmaddpg steps: 1924975, episodes: 77000, mean episode reward: -8.794068207371055, agent episode reward: [-2.137676014744237, -6.656392192626818], time: 46.249
mmmaddpg vs mmmaddpg steps: 1949975, episodes: 78000, mean episode reward: -8.502652718052117, agent episode reward: [-2.150063295548458, -6.352589422503659], time: 46.056
mmmaddpg vs mmmaddpg steps: 1974975, episodes: 79000, mean episode reward: -8.55685020388933, agent episode reward: [-1.877638400235664, -6.679211803653667], time: 45.952
mmmaddpg vs mmmaddpg steps: 1999975, episodes: 80000, mean episode reward: -9.09710709165364, agent episode reward: [-2.6893237068875906, -6.407783384766051], time: 46.066
mmmaddpg vs mmmaddpg steps: 2024975, episodes: 81000, mean episode reward: -8.672264908790456, agent episode reward: [-2.068892320160732, -6.603372588629723], time: 46.027
mmmaddpg vs mmmaddpg steps: 2049975, episodes: 82000, mean episode reward: -8.700490107985749, agent episode reward: [-2.223473871626425, -6.477016236359325], time: 46.748
mmmaddpg vs mmmaddpg steps: 2074975, episodes: 83000, mean episode reward: -8.647303202431976, agent episode reward: [-1.9393776337216944, -6.70792556871028], time: 46.36
mmmaddpg vs mmmaddpg steps: 2099975, episodes: 84000, mean episode reward: -8.641276723655832, agent episode reward: [-2.190455352392541, -6.450821371263292], time: 45.322
mmmaddpg vs mmmaddpg steps: 2124975, episodes: 85000, mean episode reward: -8.73318008540024, agent episode reward: [-2.1299752753987433, -6.603204810001497], time: 45.008
mmmaddpg vs mmmaddpg steps: 2149975, episodes: 86000, mean episode reward: -8.754734382605445, agent episode reward: [-2.4372284966139888, -6.317505885991458], time: 45.717
mmmaddpg vs mmmaddpg steps: 2174975, episodes: 87000, mean episode reward: -8.94950444803868, agent episode reward: [-2.4140914428787754, -6.535413005159904], time: 46.566
mmmaddpg vs mmmaddpg steps: 2199975, episodes: 88000, mean episode reward: -8.829099179623624, agent episode reward: [-2.4896499767230535, -6.33944920290057], time: 45.405
mmmaddpg vs mmmaddpg steps: 2224975, episodes: 89000, mean episode reward: -8.542002064393994, agent episode reward: [-1.9484999235128795, -6.593502140881114], time: 45.954
mmmaddpg vs mmmaddpg steps: 2249975, episodes: 90000, mean episode reward: -8.806280496578514, agent episode reward: [-2.3586297916692835, -6.447650704909233], time: 45.882
mmmaddpg vs mmmaddpg steps: 2274975, episodes: 91000, mean episode reward: -8.745803371244373, agent episode reward: [-2.2369826263952883, -6.508820744849083], time: 45.873
mmmaddpg vs mmmaddpg steps: 2299975, episodes: 92000, mean episode reward: -8.580806252139398, agent episode reward: [-2.141128899865514, -6.439677352273885], time: 45.957
mmmaddpg vs mmmaddpg steps: 2324975, episodes: 93000, mean episode reward: -8.873904068974682, agent episode reward: [-2.1773813457784574, -6.696522723196224], time: 46.441
mmmaddpg vs mmmaddpg steps: 2349975, episodes: 94000, mean episode reward: -8.780121306344517, agent episode reward: [-2.4593778799452317, -6.320743426399286], time: 46.204
mmmaddpg vs mmmaddpg steps: 2374975, episodes: 95000, mean episode reward: -9.073901344471265, agent episode reward: [-2.235707654322123, -6.838193690149141], time: 45.651
mmmaddpg vs mmmaddpg steps: 2399975, episodes: 96000, mean episode reward: -8.617212978019055, agent episode reward: [-1.8846013087211495, -6.732611669297906], time: 45.968
mmmaddpg vs mmmaddpg steps: 2424975, episodes: 97000, mean episode reward: -8.679111302165463, agent episode reward: [-2.1509270419640254, -6.528184260201438], time: 46.485
mmmaddpg vs mmmaddpg steps: 2449975, episodes: 98000, mean episode reward: -8.861622844625694, agent episode reward: [-2.3981729258919167, -6.463449918733779], time: 46.434
mmmaddpg vs mmmaddpg steps: 2474975, episodes: 99000, mean episode reward: -8.693680866383621, agent episode reward: [-2.0318810083035266, -6.661799858080094], time: 46.241
mmmaddpg vs mmmaddpg steps: 2499975, episodes: 100000, mean episode reward: -8.687925498478162, agent episode reward: [-2.2233394005049507, -6.464586097973211], time: 45.683
...Finished total of 100001 episodes.
