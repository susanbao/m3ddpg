0 bad agents
      adv rate for q_index :  0 [1e-05, 0.001, 0.001]
      adv rate for p_index :  0 [1e-05, 0.001, 0.001]
1 good agents
      adv rate for q_index :  1 [0.001, 1e-05, 1e-05]
      adv rate for p_index :  1 [0.001, 1e-05, 1e-05]
2 good agents
      adv rate for q_index :  2 [0.001, 1e-05, 1e-05]
      adv rate for p_index :  2 [0.001, 1e-05, 1e-05]
Using good policy mmmaddpg and bad policy mmmaddpg with 1 adversaries
Starting iterations...
mmmaddpg vs mmmaddpg steps: 24975, episodes: 1000, mean episode reward: -22.795676480994334, agent episode reward: [-39.43498003007188, 8.319651774538771, 8.319651774538771], time: 53.947
mmmaddpg vs mmmaddpg steps: 49975, episodes: 2000, mean episode reward: -24.6691592556678, agent episode reward: [-29.54255607629962, 2.4366984103159104, 2.4366984103159104], time: 73.065
mmmaddpg vs mmmaddpg steps: 74975, episodes: 3000, mean episode reward: 4.083719237093642, agent episode reward: [-9.345993555841353, 6.714856396467498, 6.714856396467498], time: 71.173
mmmaddpg vs mmmaddpg steps: 99975, episodes: 4000, mean episode reward: 2.6820221097644055, agent episode reward: [-8.057279125518322, 5.369650617641364, 5.369650617641364], time: 71.119
mmmaddpg vs mmmaddpg steps: 124975, episodes: 5000, mean episode reward: 2.6585538669473228, agent episode reward: [-9.245280305502199, 5.9519170862247615, 5.9519170862247615], time: 70.155
mmmaddpg vs mmmaddpg steps: 149975, episodes: 6000, mean episode reward: 2.539441397359471, agent episode reward: [-9.553210345433666, 6.046325871396568, 6.046325871396568], time: 72.489
mmmaddpg vs mmmaddpg steps: 174975, episodes: 7000, mean episode reward: 2.382208012266423, agent episode reward: [-10.341553220284055, 6.36188061627524, 6.36188061627524], time: 71.959
mmmaddpg vs mmmaddpg steps: 199975, episodes: 8000, mean episode reward: 1.385054256174818, agent episode reward: [-10.383314313622018, 5.884184284898416, 5.884184284898416], time: 70.388
mmmaddpg vs mmmaddpg steps: 224975, episodes: 9000, mean episode reward: 2.050558358479983, agent episode reward: [-10.19310680538714, 6.121832581933562, 6.121832581933562], time: 72.002
mmmaddpg vs mmmaddpg steps: 249975, episodes: 10000, mean episode reward: 1.6783676427820373, agent episode reward: [-10.791475201467403, 6.23492142212472, 6.23492142212472], time: 71.585
mmmaddpg vs mmmaddpg steps: 274975, episodes: 11000, mean episode reward: 1.1435620272235623, agent episode reward: [-10.553139754374161, 5.848350890798861, 5.848350890798861], time: 72.491
mmmaddpg vs mmmaddpg steps: 299975, episodes: 12000, mean episode reward: 0.830308124338255, agent episode reward: [-10.670971269339454, 5.750639696838855, 5.750639696838855], time: 72.653
mmmaddpg vs mmmaddpg steps: 324975, episodes: 13000, mean episode reward: 1.2570918865425655, agent episode reward: [-10.851672172784562, 6.0543820296635635, 6.0543820296635635], time: 72.164
mmmaddpg vs mmmaddpg steps: 349975, episodes: 14000, mean episode reward: 0.8908171969760205, agent episode reward: [-11.167803811961798, 6.029310504468909, 6.029310504468909], time: 73.447
mmmaddpg vs mmmaddpg steps: 374975, episodes: 15000, mean episode reward: 1.595010049685041, agent episode reward: [-10.598021210847314, 6.096515630266176, 6.096515630266176], time: 72.258
mmmaddpg vs mmmaddpg steps: 399975, episodes: 16000, mean episode reward: 0.5430187849571804, agent episode reward: [-10.65332327658543, 5.598171030771305, 5.598171030771305], time: 72.418
mmmaddpg vs mmmaddpg steps: 424975, episodes: 17000, mean episode reward: 0.8635117382749659, agent episode reward: [-11.01029139858752, 5.936901568431243, 5.936901568431243], time: 72.547
mmmaddpg vs mmmaddpg steps: 449975, episodes: 18000, mean episode reward: 1.439017146693648, agent episode reward: [-11.724338354761468, 6.581677750727558, 6.581677750727558], time: 72.672
mmmaddpg vs mmmaddpg steps: 474975, episodes: 19000, mean episode reward: 1.5838765239924115, agent episode reward: [-11.814565605513868, 6.699221064753139, 6.699221064753139], time: 72.397
mmmaddpg vs mmmaddpg steps: 499975, episodes: 20000, mean episode reward: 2.0150585096529707, agent episode reward: [-11.808199975795588, 6.9116292427242785, 6.9116292427242785], time: 72.396
mmmaddpg vs mmmaddpg steps: 524975, episodes: 21000, mean episode reward: 1.7529832150938647, agent episode reward: [-11.486604625070282, 6.619793920082074, 6.619793920082074], time: 71.376
mmmaddpg vs mmmaddpg steps: 549975, episodes: 22000, mean episode reward: 1.9610794951071548, agent episode reward: [-11.938246433309622, 6.949662964208389, 6.949662964208389], time: 72.418
mmmaddpg vs mmmaddpg steps: 574975, episodes: 23000, mean episode reward: 2.2336905310196906, agent episode reward: [-11.426711243160614, 6.830200887090153, 6.830200887090153], time: 72.007
mmmaddpg vs mmmaddpg steps: 599975, episodes: 24000, mean episode reward: 2.0393720916270053, agent episode reward: [-11.618550380188925, 6.828961235907966, 6.828961235907966], time: 72.125
mmmaddpg vs mmmaddpg steps: 624975, episodes: 25000, mean episode reward: 1.9702727973289202, agent episode reward: [-12.269145883661103, 7.119709340495012, 7.119709340495012], time: 71.452
mmmaddpg vs mmmaddpg steps: 649975, episodes: 26000, mean episode reward: 2.4493225280047373, agent episode reward: [-12.374427482355172, 7.4118750051799545, 7.4118750051799545], time: 70.563
mmmaddpg vs mmmaddpg steps: 674975, episodes: 27000, mean episode reward: 1.878720273698509, agent episode reward: [-12.671866400563017, 7.275293337130762, 7.275293337130762], time: 72.0
mmmaddpg vs mmmaddpg steps: 699975, episodes: 28000, mean episode reward: 1.724778041268866, agent episode reward: [-11.938988247126812, 6.831883144197838, 6.831883144197838], time: 72.269
mmmaddpg vs mmmaddpg steps: 724975, episodes: 29000, mean episode reward: 2.114917531006361, agent episode reward: [-12.209287322437893, 7.162102426722127, 7.162102426722127], time: 72.136
mmmaddpg vs mmmaddpg steps: 749975, episodes: 30000, mean episode reward: 1.6096151817347482, agent episode reward: [-11.642935733944157, 6.626275457839452, 6.626275457839452], time: 72.264
mmmaddpg vs mmmaddpg steps: 774975, episodes: 31000, mean episode reward: 2.0292168043286694, agent episode reward: [-11.990383336300885, 7.009800070314778, 7.009800070314778], time: 72.487
mmmaddpg vs mmmaddpg steps: 799975, episodes: 32000, mean episode reward: 1.847307165231358, agent episode reward: [-12.414370910914153, 7.130839038072756, 7.130839038072756], time: 70.916
mmmaddpg vs mmmaddpg steps: 824975, episodes: 33000, mean episode reward: 2.039417845929104, agent episode reward: [-12.390143669963502, 7.214780757946302, 7.214780757946302], time: 72.714
mmmaddpg vs mmmaddpg steps: 849975, episodes: 34000, mean episode reward: 1.9618818896401795, agent episode reward: [-12.378299977843525, 7.170090933741853, 7.170090933741853], time: 72.974
mmmaddpg vs mmmaddpg steps: 874975, episodes: 35000, mean episode reward: 1.7593640319960653, agent episode reward: [-13.214400521939016, 7.486882276967541, 7.486882276967541], time: 72.671
mmmaddpg vs mmmaddpg steps: 899975, episodes: 36000, mean episode reward: 1.4782435473333595, agent episode reward: [-12.62668828430165, 7.052465915817503, 7.052465915817503], time: 71.745
mmmaddpg vs mmmaddpg steps: 924975, episodes: 37000, mean episode reward: 1.7656785136925834, agent episode reward: [-12.615627687431187, 7.190653100561885, 7.190653100561885], time: 70.941
mmmaddpg vs mmmaddpg steps: 949975, episodes: 38000, mean episode reward: 2.265493851764045, agent episode reward: [-12.650393840182186, 7.457943845973115, 7.457943845973115], time: 70.655
mmmaddpg vs mmmaddpg steps: 974975, episodes: 39000, mean episode reward: 2.5270390152517184, agent episode reward: [-13.084213396353233, 7.805626205802476, 7.805626205802476], time: 71.29
mmmaddpg vs mmmaddpg steps: 999975, episodes: 40000, mean episode reward: 2.445850019825791, agent episode reward: [-13.725458380169789, 8.085654199997789, 8.085654199997789], time: 70.833
mmmaddpg vs mmmaddpg steps: 1024975, episodes: 41000, mean episode reward: 2.1997130682659947, agent episode reward: [-12.61036085518687, 7.4050369617264336, 7.4050369617264336], time: 71.286
mmmaddpg vs mmmaddpg steps: 1049975, episodes: 42000, mean episode reward: 2.598342678063882, agent episode reward: [-12.545254757569634, 7.571798717816758, 7.571798717816758], time: 71.433
mmmaddpg vs mmmaddpg steps: 1074975, episodes: 43000, mean episode reward: 2.7332196117440337, agent episode reward: [-12.444777995856752, 7.588998803800391, 7.588998803800391], time: 71.976
mmmaddpg vs mmmaddpg steps: 1099975, episodes: 44000, mean episode reward: 3.000729983457558, agent episode reward: [-13.269866617033742, 8.135298300245651, 8.135298300245651], time: 71.08
mmmaddpg vs mmmaddpg steps: 1124975, episodes: 45000, mean episode reward: 3.1440616447304905, agent episode reward: [-12.944228183746075, 8.044144914238283, 8.044144914238283], time: 70.964
mmmaddpg vs mmmaddpg steps: 1149975, episodes: 46000, mean episode reward: 2.928804121076145, agent episode reward: [-13.107974883087136, 8.018389502081641, 8.018389502081641], time: 71.633
mmmaddpg vs mmmaddpg steps: 1174975, episodes: 47000, mean episode reward: 3.0233484835065316, agent episode reward: [-12.882196532625219, 7.952772508065877, 7.952772508065877], time: 72.289
mmmaddpg vs mmmaddpg steps: 1199975, episodes: 48000, mean episode reward: 2.7947536783492497, agent episode reward: [-13.37753453727368, 8.086144107811466, 8.086144107811466], time: 71.725
mmmaddpg vs mmmaddpg steps: 1224975, episodes: 49000, mean episode reward: 3.183677798315109, agent episode reward: [-13.174550664836083, 8.179114231575596, 8.179114231575596], time: 72.059
mmmaddpg vs mmmaddpg steps: 1249975, episodes: 50000, mean episode reward: 2.78321661196226, agent episode reward: [-13.365315157667714, 8.074265884814988, 8.074265884814988], time: 70.444
mmmaddpg vs mmmaddpg steps: 1274975, episodes: 51000, mean episode reward: 2.603390057538592, agent episode reward: [-12.883164238895224, 7.743277148216908, 7.743277148216908], time: 71.508
mmmaddpg vs mmmaddpg steps: 1299975, episodes: 52000, mean episode reward: 2.629598124470569, agent episode reward: [-12.516830683385088, 7.573214403927828, 7.573214403927828], time: 70.624
mmmaddpg vs mmmaddpg steps: 1324975, episodes: 53000, mean episode reward: 2.8246120083315844, agent episode reward: [-13.200184112189454, 8.01239806026052, 8.01239806026052], time: 72.412
mmmaddpg vs mmmaddpg steps: 1349975, episodes: 54000, mean episode reward: 2.851437954276502, agent episode reward: [-13.20733058814985, 8.029384271213175, 8.029384271213175], time: 69.666
mmmaddpg vs mmmaddpg steps: 1374975, episodes: 55000, mean episode reward: 3.3180817967869207, agent episode reward: [-13.179073955262224, 8.248577876024573, 8.248577876024573], time: 72.134
mmmaddpg vs mmmaddpg steps: 1399975, episodes: 56000, mean episode reward: 3.7626213748949513, agent episode reward: [-13.114940476813171, 8.438780925854061, 8.438780925854061], time: 71.769
mmmaddpg vs mmmaddpg steps: 1424975, episodes: 57000, mean episode reward: 3.6809950343023754, agent episode reward: [-13.832894149387544, 8.75694459184496, 8.75694459184496], time: 71.244
mmmaddpg vs mmmaddpg steps: 1449975, episodes: 58000, mean episode reward: 3.967089547412616, agent episode reward: [-13.087801636806892, 8.527445592109753, 8.527445592109753], time: 72.594
mmmaddpg vs mmmaddpg steps: 1474975, episodes: 59000, mean episode reward: 4.3095185676693815, agent episode reward: [-13.536265435437993, 8.922892001553688, 8.922892001553688], time: 70.405
mmmaddpg vs mmmaddpg steps: 1499975, episodes: 60000, mean episode reward: 4.7996471984464675, agent episode reward: [-13.134020427568354, 8.96683381300741, 8.96683381300741], time: 71.296
mmmaddpg vs mmmaddpg steps: 1524975, episodes: 61000, mean episode reward: 4.752202706303593, agent episode reward: [-13.390360550302985, 9.071281628303288, 9.071281628303288], time: 71.458
mmmaddpg vs mmmaddpg steps: 1549975, episodes: 62000, mean episode reward: 4.740235424274634, agent episode reward: [-13.602438083413883, 9.171336753844258, 9.171336753844258], time: 70.797
mmmaddpg vs mmmaddpg steps: 1574975, episodes: 63000, mean episode reward: 4.525800821548037, agent episode reward: [-13.487232406711453, 9.006516614129746, 9.006516614129746], time: 72.558
mmmaddpg vs mmmaddpg steps: 1599975, episodes: 64000, mean episode reward: 4.757310170671877, agent episode reward: [-13.47257278981927, 9.114941480245577, 9.114941480245577], time: 72.233
mmmaddpg vs mmmaddpg steps: 1624975, episodes: 65000, mean episode reward: 4.765297284704808, agent episode reward: [-13.040815987787704, 8.903056636246255, 8.903056636246255], time: 71.544
mmmaddpg vs mmmaddpg steps: 1649975, episodes: 66000, mean episode reward: 4.861620481494262, agent episode reward: [-12.695829690645713, 8.778725086069986, 8.778725086069986], time: 72.081
mmmaddpg vs mmmaddpg steps: 1674975, episodes: 67000, mean episode reward: 4.782626346157962, agent episode reward: [-13.702360739211134, 9.242493542684548, 9.242493542684548], time: 72.902
mmmaddpg vs mmmaddpg steps: 1699975, episodes: 68000, mean episode reward: 5.0264893125382715, agent episode reward: [-13.708118409383655, 9.367303860960961, 9.367303860960961], time: 71.061
mmmaddpg vs mmmaddpg steps: 1724975, episodes: 69000, mean episode reward: 5.197178949449318, agent episode reward: [-13.270267497876826, 9.233723223663073, 9.233723223663073], time: 72.084
mmmaddpg vs mmmaddpg steps: 1749975, episodes: 70000, mean episode reward: 5.342946740660315, agent episode reward: [-12.772597416307754, 9.057772078484033, 9.057772078484033], time: 71.584
mmmaddpg vs mmmaddpg steps: 1774975, episodes: 71000, mean episode reward: 4.945534424596462, agent episode reward: [-13.469345359301776, 9.20743989194912, 9.20743989194912], time: 71.254
mmmaddpg vs mmmaddpg steps: 1799975, episodes: 72000, mean episode reward: 4.9877157595348605, agent episode reward: [-13.299959307113436, 9.143837533324149, 9.143837533324149], time: 70.806
mmmaddpg vs mmmaddpg steps: 1824975, episodes: 73000, mean episode reward: 4.884427290627754, agent episode reward: [-12.78252854789906, 8.833477919263407, 8.833477919263407], time: 71.401
mmmaddpg vs mmmaddpg steps: 1849975, episodes: 74000, mean episode reward: 4.645050871629881, agent episode reward: [-13.179946247551587, 8.912498559590734, 8.912498559590734], time: 70.404
mmmaddpg vs mmmaddpg steps: 1874975, episodes: 75000, mean episode reward: 4.384697128107421, agent episode reward: [-13.344270194777483, 8.864483661442451, 8.864483661442451], time: 71.287
mmmaddpg vs mmmaddpg steps: 1899975, episodes: 76000, mean episode reward: 4.6543859698111625, agent episode reward: [-12.92942847339644, 8.7919072216038, 8.7919072216038], time: 71.864
mmmaddpg vs mmmaddpg steps: 1924975, episodes: 77000, mean episode reward: 4.801401394292261, agent episode reward: [-13.447096450472326, 9.124248922382295, 9.124248922382295], time: 70.687
mmmaddpg vs mmmaddpg steps: 1949975, episodes: 78000, mean episode reward: 4.285472395091345, agent episode reward: [-13.197034703841917, 8.74125354946663, 8.74125354946663], time: 71.584
mmmaddpg vs mmmaddpg steps: 1974975, episodes: 79000, mean episode reward: 3.9995626828012463, agent episode reward: [-13.619428766395602, 8.809495724598422, 8.809495724598422], time: 72.142
mmmaddpg vs mmmaddpg steps: 1999975, episodes: 80000, mean episode reward: 3.6814201350189886, agent episode reward: [-13.660325540262654, 8.670872837640822, 8.670872837640822], time: 71.147
mmmaddpg vs mmmaddpg steps: 2024975, episodes: 81000, mean episode reward: 3.825141278501278, agent episode reward: [-13.454966025154937, 8.640053651828108, 8.640053651828108], time: 71.594
mmmaddpg vs mmmaddpg steps: 2049975, episodes: 82000, mean episode reward: 4.28451016955927, agent episode reward: [-13.76517399233819, 9.02484208094873, 9.02484208094873], time: 72.803
mmmaddpg vs mmmaddpg steps: 2074975, episodes: 83000, mean episode reward: 4.394826907052871, agent episode reward: [-13.381168008703197, 8.887997457878035, 8.887997457878035], time: 71.715
mmmaddpg vs mmmaddpg steps: 2099975, episodes: 84000, mean episode reward: 4.533593314804756, agent episode reward: [-13.500176262820915, 9.016884788812835, 9.016884788812835], time: 70.974
mmmaddpg vs mmmaddpg steps: 2124975, episodes: 85000, mean episode reward: 4.323758363196148, agent episode reward: [-14.112702805240408, 9.218230584218277, 9.218230584218277], time: 71.333
mmmaddpg vs mmmaddpg steps: 2149975, episodes: 86000, mean episode reward: 4.230107036128567, agent episode reward: [-13.546559428360705, 8.888333232244637, 8.888333232244637], time: 72.142
mmmaddpg vs mmmaddpg steps: 2174975, episodes: 87000, mean episode reward: 4.604068845988191, agent episode reward: [-13.528765766527224, 9.066417306257707, 9.066417306257707], time: 70.521
mmmaddpg vs mmmaddpg steps: 2199975, episodes: 88000, mean episode reward: 4.336040289226821, agent episode reward: [-13.57380272501295, 8.954921507119884, 8.954921507119884], time: 68.957
mmmaddpg vs mmmaddpg steps: 2224975, episodes: 89000, mean episode reward: 3.9183264536981697, agent episode reward: [-12.96378990094732, 8.441058177322747, 8.441058177322747], time: 69.398
mmmaddpg vs mmmaddpg steps: 2249975, episodes: 90000, mean episode reward: 4.0224329995774495, agent episode reward: [-13.705860564788194, 8.864146782182823, 8.864146782182823], time: 70.345
mmmaddpg vs mmmaddpg steps: 2274975, episodes: 91000, mean episode reward: 4.120920385866081, agent episode reward: [-13.399709425715562, 8.760314905790821, 8.760314905790821], time: 69.656
mmmaddpg vs mmmaddpg steps: 2299975, episodes: 92000, mean episode reward: 3.8812443022745797, agent episode reward: [-13.44926352883195, 8.665253915553265, 8.665253915553265], time: 69.899
mmmaddpg vs mmmaddpg steps: 2324975, episodes: 93000, mean episode reward: 3.902172949314709, agent episode reward: [-13.500982871317563, 8.701577910316137, 8.701577910316137], time: 69.684
mmmaddpg vs mmmaddpg steps: 2349975, episodes: 94000, mean episode reward: 3.419428777020468, agent episode reward: [-13.853043926649546, 8.636236351835006, 8.636236351835006], time: 69.182
mmmaddpg vs mmmaddpg steps: 2374975, episodes: 95000, mean episode reward: 3.573259985799015, agent episode reward: [-14.176713695555666, 8.874986840677343, 8.874986840677343], time: 69.37
mmmaddpg vs mmmaddpg steps: 2399975, episodes: 96000, mean episode reward: 3.64269231887837, agent episode reward: [-14.31584745303225, 8.979269885955311, 8.979269885955311], time: 69.666
mmmaddpg vs mmmaddpg steps: 2424975, episodes: 97000, mean episode reward: 3.1750339468316287, agent episode reward: [-14.344792153257524, 8.759913050044576, 8.759913050044576], time: 69.241
mmmaddpg vs mmmaddpg steps: 2449975, episodes: 98000, mean episode reward: 2.9505652872673354, agent episode reward: [-14.086318078601625, 8.51844168293448, 8.51844168293448], time: 70.098
mmmaddpg vs mmmaddpg steps: 2474975, episodes: 99000, mean episode reward: 2.647735772587797, agent episode reward: [-14.483957609163376, 8.565846690875587, 8.565846690875587], time: 69.875
mmmaddpg vs mmmaddpg steps: 2499975, episodes: 100000, mean episode reward: 2.412754731598862, agent episode reward: [-13.40104959866371, 7.906902165131285, 7.906902165131285], time: 69.87
...Finished total of 100001 episodes.
