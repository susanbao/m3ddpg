0 bad agents
      adv rate for q_index :  0 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
      adv rate for p_index :  0 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
1 bad agents
      adv rate for q_index :  1 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
      adv rate for p_index :  1 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
2 bad agents
      adv rate for q_index :  2 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
      adv rate for p_index :  2 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
3 bad agents
      adv rate for q_index :  3 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
      adv rate for p_index :  3 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
4 good agents
      adv rate for q_index :  4 [0.001, 0.001, 0.001, 0.001, 1e-05, 1e-05]
      adv rate for p_index :  4 [0.001, 0.001, 0.001, 0.001, 1e-05, 1e-05]
5 good agents
      adv rate for q_index :  5 [0.001, 0.001, 0.001, 0.001, 1e-05, 1e-05]
      adv rate for p_index :  5 [0.001, 0.001, 0.001, 0.001, 1e-05, 1e-05]
Using good policy mmmaddpg and bad policy mmmaddpg with 4 adversaries
Starting iterations...
mmmaddpg vs mmmaddpg steps: 24975, episodes: 1000, mean episode reward: -44.97202194130357, agent episode reward: [0.6027434168916751, 0.5681306581630936, 0.6306201096417746, 0.65113156673704, -27.100133502260345, -20.3245141904768], time: 152.977
mmmaddpg vs mmmaddpg steps: 49975, episodes: 2000, mean episode reward: -10.309953991300961, agent episode reward: [2.799083849459175, 3.2240922704087325, 3.185378326847117, 3.431768412787412, -14.934341460423253, -8.015935390380145], time: 203.064
mmmaddpg vs mmmaddpg steps: 74975, episodes: 3000, mean episode reward: 11.584279023796112, agent episode reward: [3.611272791022234, 3.8894406803666093, 4.0710904971356525, 4.385509307844136, -1.8397265250278694, -2.5333077275446474], time: 200.453
mmmaddpg vs mmmaddpg steps: 99975, episodes: 4000, mean episode reward: 15.989980390456697, agent episode reward: [5.13772807439102, 5.506166360896798, 5.35552741787015, 5.497433867735356, -2.6333956986860847, -2.8734796317505396], time: 202.881
mmmaddpg vs mmmaddpg steps: 124975, episodes: 5000, mean episode reward: 21.12646792439987, agent episode reward: [7.358134399182769, 7.009772796101699, 6.84291273339018, 7.03529050424483, -3.327408218092373, -3.7922342904272366], time: 200.281
mmmaddpg vs mmmaddpg steps: 149975, episodes: 6000, mean episode reward: 24.98786103263028, agent episode reward: [8.40749234182022, 8.009190288869625, 7.993536883422373, 8.175860849793516, -3.2796400055672534, -4.318579325708204], time: 201.903
mmmaddpg vs mmmaddpg steps: 174975, episodes: 7000, mean episode reward: 32.01216378384648, agent episode reward: [10.658196329364172, 10.272552310407319, 10.56868069747675, 10.593686859405523, -4.374474675422758, -5.706477737384526], time: 200.761
mmmaddpg vs mmmaddpg steps: 199975, episodes: 8000, mean episode reward: 34.158878070333316, agent episode reward: [11.292414032629091, 10.91513326493345, 11.143511960521884, 11.195275827962469, -4.693439878902921, -5.694017136810659], time: 197.615
mmmaddpg vs mmmaddpg steps: 224975, episodes: 9000, mean episode reward: 37.25408523160576, agent episode reward: [12.443335599822552, 12.224479271741103, 12.379627409108936, 12.383293983759547, -5.970554221885317, -6.206096810941062], time: 198.59
mmmaddpg vs mmmaddpg steps: 249975, episodes: 10000, mean episode reward: 34.263065138606876, agent episode reward: [11.38585717466897, 11.146206724258246, 11.404330302708669, 11.313820445550173, -4.46495900669931, -6.522190501879876], time: 201.35
mmmaddpg vs mmmaddpg steps: 274975, episodes: 11000, mean episode reward: 35.7163889925028, agent episode reward: [12.004723696719164, 11.948169406228699, 12.068141450089861, 11.930160410998122, -4.926463967389059, -7.308342004143988], time: 200.768
mmmaddpg vs mmmaddpg steps: 299975, episodes: 12000, mean episode reward: 34.39413456494435, agent episode reward: [11.823516234568185, 11.862243552291554, 11.89516909122359, 11.76724493985956, -4.910084874270878, -8.043954378727657], time: 202.002
mmmaddpg vs mmmaddpg steps: 324975, episodes: 13000, mean episode reward: 26.931980973494834, agent episode reward: [9.283712459873467, 9.340340580765755, 9.362102569479418, 9.19895561782071, -3.1855457449974898, -7.067584509447024], time: 202.968
mmmaddpg vs mmmaddpg steps: 349975, episodes: 14000, mean episode reward: 27.985217643340963, agent episode reward: [9.449091652337076, 9.473161990224046, 9.455610345763043, 9.351572494455926, -2.873418072332756, -6.870800767106368], time: 201.421
mmmaddpg vs mmmaddpg steps: 374975, episodes: 15000, mean episode reward: 23.854071421083088, agent episode reward: [8.033579620414187, 8.022829966588082, 8.038988846815174, 7.926631336753581, -2.5148468534030246, -5.653111496084912], time: 201.093
mmmaddpg vs mmmaddpg steps: 399975, episodes: 16000, mean episode reward: 23.138431825572866, agent episode reward: [8.012459069232975, 8.075376734178104, 8.05135581481728, 7.936146627371912, -2.5599078167303477, -6.376998603297057], time: 200.451
mmmaddpg vs mmmaddpg steps: 424975, episodes: 17000, mean episode reward: 18.390346184942537, agent episode reward: [6.692870553841027, 6.745612851499812, 6.784782734544369, 6.676058273073606, -2.238594111617095, -6.270384116399185], time: 201.869
mmmaddpg vs mmmaddpg steps: 449975, episodes: 18000, mean episode reward: 17.91404606605129, agent episode reward: [6.4799707511006694, 6.584991556677737, 6.63578747014995, 6.494605195774072, -2.449874288667299, -5.831434618983843], time: 201.869
mmmaddpg vs mmmaddpg steps: 474975, episodes: 19000, mean episode reward: 15.989425894511147, agent episode reward: [5.644133843160494, 5.739294980148736, 5.858120558535212, 5.689447498013887, -2.003765387819015, -4.937805597528171], time: 202.167
mmmaddpg vs mmmaddpg steps: 499975, episodes: 20000, mean episode reward: 16.737214854746, agent episode reward: [6.110540535965549, 6.285553755624538, 6.262278338663991, 6.122391272090761, -2.7972478370387632, -5.246301210560079], time: 203.741
mmmaddpg vs mmmaddpg steps: 524975, episodes: 21000, mean episode reward: 20.56786679148337, agent episode reward: [7.130593832215485, 7.184317982773316, 7.1610072088076, 7.0312374909455215, -2.62931594391336, -5.309973779345189], time: 198.964
mmmaddpg vs mmmaddpg steps: 549975, episodes: 22000, mean episode reward: 17.785524982229763, agent episode reward: [6.471302677184056, 6.492450701066405, 6.420846267883944, 6.245421077302197, -2.7944334930625043, -5.050062248144333], time: 207.331
mmmaddpg vs mmmaddpg steps: 574975, episodes: 23000, mean episode reward: 15.793814292050893, agent episode reward: [6.094438114353101, 6.082207843698205, 5.935786465372349, 5.89327185979334, -3.0561220618261404, -5.1557679293399605], time: 198.485
mmmaddpg vs mmmaddpg steps: 599975, episodes: 24000, mean episode reward: 18.222135370042853, agent episode reward: [6.810498164091125, 6.797970337110832, 6.688292955786757, 6.6472253981650775, -3.123679669761907, -5.59817181534903], time: 205.069
mmmaddpg vs mmmaddpg steps: 624975, episodes: 25000, mean episode reward: 15.212790684921863, agent episode reward: [6.107369055115987, 6.03949903575785, 5.882434076021051, 5.977559696721262, -3.7682021233352394, -5.025869055359049], time: 200.883
mmmaddpg vs mmmaddpg steps: 649975, episodes: 26000, mean episode reward: 19.761428261216462, agent episode reward: [7.067726411107292, 7.082189830243172, 6.779665776680986, 7.002443930384341, -2.713546060425167, -5.457051626774166], time: 195.982
mmmaddpg vs mmmaddpg steps: 674975, episodes: 27000, mean episode reward: 19.503934884695962, agent episode reward: [6.7816246352661596, 6.707535462149064, 6.4702764126229715, 6.588184735470055, -2.652502001740389, -4.3911843590719], time: 203.543
mmmaddpg vs mmmaddpg steps: 699975, episodes: 28000, mean episode reward: 18.47586516671276, agent episode reward: [6.57069204462725, 6.475367693691495, 6.305016557231441, 6.4492263619719905, -2.1791711106294342, -5.145266380179978], time: 203.279
mmmaddpg vs mmmaddpg steps: 724975, episodes: 29000, mean episode reward: 19.23287517772259, agent episode reward: [6.739286679552179, 6.744996300681207, 6.632518841561315, 6.749912667678787, -2.7268395005761885, -4.906999811174704], time: 199.178
mmmaddpg vs mmmaddpg steps: 749975, episodes: 30000, mean episode reward: 20.63658202154747, agent episode reward: [7.124316689501596, 7.104337076217661, 6.956275341914827, 7.013250010814569, -2.489655243602103, -5.07194185329908], time: 203.606
mmmaddpg vs mmmaddpg steps: 774975, episodes: 31000, mean episode reward: 20.93161771663361, agent episode reward: [7.312859865626519, 7.255858087903394, 7.293274370369167, 7.305134283087989, -3.027397354797684, -5.208111535555772], time: 198.247
mmmaddpg vs mmmaddpg steps: 799975, episodes: 32000, mean episode reward: 25.39714109181198, agent episode reward: [8.49821959332573, 8.572540719190382, 8.613904178196837, 8.657090940741979, -2.899965092495574, -6.044649247147374], time: 202.29
mmmaddpg vs mmmaddpg steps: 824975, episodes: 33000, mean episode reward: 23.696147525199052, agent episode reward: [7.984512398473418, 8.043705284554346, 8.089159798102337, 8.072887777632252, -3.0633839547475556, -5.430733778815743], time: 203.279
mmmaddpg vs mmmaddpg steps: 849975, episodes: 34000, mean episode reward: 25.550858503959965, agent episode reward: [8.727247354924051, 8.72167897873227, 8.747520759639826, 8.784173756920428, -3.2281701562042544, -6.201592190052358], time: 203.865
mmmaddpg vs mmmaddpg steps: 874975, episodes: 35000, mean episode reward: 26.37197779959828, agent episode reward: [9.020609573431493, 8.960876830574298, 8.971232434757681, 8.965061425727795, -2.772656006763506, -6.773146458129482], time: 203.913
mmmaddpg vs mmmaddpg steps: 899975, episodes: 36000, mean episode reward: 25.224851749129012, agent episode reward: [8.622198978790726, 8.592085475183877, 8.604189039195994, 8.482980167336615, -3.1896767516682814, -5.886925159709924], time: 203.755
mmmaddpg vs mmmaddpg steps: 924975, episodes: 37000, mean episode reward: 28.20402506553974, agent episode reward: [9.891651557869048, 9.821195339985438, 9.827411697166598, 9.702642910991122, -3.519166471825033, -7.519709968647437], time: 202.709
mmmaddpg vs mmmaddpg steps: 949975, episodes: 38000, mean episode reward: 29.17395332883177, agent episode reward: [10.048290038725666, 10.005935181122604, 9.980908564963784, 9.828500064571934, -3.787205969855413, -6.902474550696801], time: 200.608
mmmaddpg vs mmmaddpg steps: 974975, episodes: 39000, mean episode reward: 31.759594989176346, agent episode reward: [11.026358753209351, 10.95296814435365, 10.966528919453499, 10.701610999071713, -3.861180980133711, -8.026690846778159], time: 198.112
mmmaddpg vs mmmaddpg steps: 999975, episodes: 40000, mean episode reward: 32.987876232007636, agent episode reward: [11.379955496128558, 11.409199389419573, 11.281432654919248, 11.114727577683762, -3.4337066919686876, -8.76373219417482], time: 201.531
mmmaddpg vs mmmaddpg steps: 1024975, episodes: 41000, mean episode reward: 33.81497899832921, agent episode reward: [11.81881758982791, 11.886667032272614, 11.77819862537345, 11.65591972475145, -4.872523510889599, -8.45210046300662], time: 198.581
mmmaddpg vs mmmaddpg steps: 1049975, episodes: 42000, mean episode reward: 31.63903847107169, agent episode reward: [11.060726635689996, 11.184679222832584, 11.05365986420893, 10.902931263353853, -3.309026185130745, -9.253932329882936], time: 202.428
mmmaddpg vs mmmaddpg steps: 1074975, episodes: 43000, mean episode reward: 31.269752832176586, agent episode reward: [10.963517193258314, 11.137543391037635, 10.995508545549677, 10.808642229591966, -3.6485952689740033, -8.986863258287004], time: 200.815
mmmaddpg vs mmmaddpg steps: 1099975, episodes: 44000, mean episode reward: 28.655902294646555, agent episode reward: [10.018244426421232, 10.1689932450122, 10.126682780469695, 9.846223892376551, -3.050651991437114, -8.453590058196006], time: 201.404
mmmaddpg vs mmmaddpg steps: 1124975, episodes: 45000, mean episode reward: 28.93444162959105, agent episode reward: [9.806358747451178, 9.973749273604863, 9.87182444736872, 9.765540555882891, -2.5166551046907433, -7.966376290025861], time: 207.573
mmmaddpg vs mmmaddpg steps: 1149975, episodes: 46000, mean episode reward: 29.294274015047694, agent episode reward: [10.008837434736895, 10.239318298942989, 10.158703732939493, 9.900153255253825, -2.7515155844373913, -8.261223122388119], time: 206.76
mmmaddpg vs mmmaddpg steps: 1174975, episodes: 47000, mean episode reward: 34.18524402061362, agent episode reward: [11.585814329151617, 11.833758789121676, 11.722568789412195, 11.418910765932909, -2.7331760670365197, -9.642632585968261], time: 205.502
mmmaddpg vs mmmaddpg steps: 1199975, episodes: 48000, mean episode reward: 33.25361186529616, agent episode reward: [11.319928176480811, 11.555018946089818, 11.417176228201548, 11.224079782167761, -2.5033111969784803, -9.759280070665293], time: 205.691
mmmaddpg vs mmmaddpg steps: 1224975, episodes: 49000, mean episode reward: 36.12176622154888, agent episode reward: [12.282962325742709, 12.468420658883588, 12.33869539211329, 12.074819062779882, -3.039402903430313, -10.003728314540275], time: 203.434
mmmaddpg vs mmmaddpg steps: 1249975, episodes: 50000, mean episode reward: 34.044647379704585, agent episode reward: [11.389578734607214, 11.589483878853535, 11.459641760958293, 11.201284366081751, -2.3997773818115826, -9.195563978984625], time: 188.218
mmmaddpg vs mmmaddpg steps: 1274975, episodes: 51000, mean episode reward: 34.46269952027291, agent episode reward: [11.88976161605083, 12.074102988966528, 12.014520289315612, 11.68990447333831, -3.365126602361821, -9.840463245036542], time: 184.163
mmmaddpg vs mmmaddpg steps: 1299975, episodes: 52000, mean episode reward: 32.34777786582813, agent episode reward: [11.312173045649361, 11.377423328081933, 11.349128415946709, 11.10386756496995, -2.9555974468987607, -9.83921704192106], time: 181.53
mmmaddpg vs mmmaddpg steps: 1324975, episodes: 53000, mean episode reward: 33.4459715207713, agent episode reward: [11.508326606927204, 11.598820299209702, 11.492122550514205, 11.337442350152232, -2.437563825085184, -10.053176460946858], time: 181.01
mmmaddpg vs mmmaddpg steps: 1349975, episodes: 54000, mean episode reward: 30.818040856432788, agent episode reward: [10.850058340699409, 10.978892722109025, 10.887916318513279, 10.697535361674047, -3.142258046569985, -9.454103839992989], time: 187.909
mmmaddpg vs mmmaddpg steps: 1374975, episodes: 55000, mean episode reward: 29.162122914032466, agent episode reward: [10.400389670242424, 10.501818402735589, 10.519978753171008, 10.299589518000898, -3.4246214613789157, -9.13503196873854], time: 186.385
mmmaddpg vs mmmaddpg steps: 1399975, episodes: 56000, mean episode reward: 31.022266486108627, agent episode reward: [10.798519295745608, 10.838757609036987, 10.862917711399387, 10.666908936390158, -2.973340573308596, -9.171496493154915], time: 188.64
mmmaddpg vs mmmaddpg steps: 1424975, episodes: 57000, mean episode reward: 31.05964913175134, agent episode reward: [10.809860965841082, 10.845248975858091, 10.815784438307473, 10.707520746420887, -3.2342143577462656, -8.884551636929931], time: 183.765
mmmaddpg vs mmmaddpg steps: 1449975, episodes: 58000, mean episode reward: 28.52576348439589, agent episode reward: [9.900461144452517, 9.969013723744272, 9.885883105347713, 9.797115254332212, -2.828223648294098, -8.198486095186727], time: 185.406
mmmaddpg vs mmmaddpg steps: 1474975, episodes: 59000, mean episode reward: 25.492021858251046, agent episode reward: [8.875691072292174, 8.899520191443294, 8.90537510619328, 8.673793475494222, -2.0379300795966615, -7.824427907575264], time: 187.781
mmmaddpg vs mmmaddpg steps: 1499975, episodes: 60000, mean episode reward: 27.913458789339078, agent episode reward: [9.857973420622862, 9.771278900609323, 9.819537827513052, 9.73818392421569, -3.030758906972039, -8.242756376649806], time: 187.453
mmmaddpg vs mmmaddpg steps: 1524975, episodes: 61000, mean episode reward: 26.765721022407618, agent episode reward: [9.43378251790843, 9.436006355013816, 9.40803594137331, 9.331783468546066, -2.320164833426269, -8.523722427007733], time: 182.655
mmmaddpg vs mmmaddpg steps: 1549975, episodes: 62000, mean episode reward: 23.942788617252003, agent episode reward: [8.743999566778518, 8.72694851245935, 8.665273988271219, 8.68641699084301, -3.4779658230406505, -7.401884618059449], time: 185.041
mmmaddpg vs mmmaddpg steps: 1574975, episodes: 63000, mean episode reward: 24.58585863059398, agent episode reward: [8.851480384639551, 8.82371920588321, 8.770570570606912, 8.738141414481394, -3.0441519313924625, -7.553901013624626], time: 186.41
mmmaddpg vs mmmaddpg steps: 1599975, episodes: 64000, mean episode reward: 23.07657577098716, agent episode reward: [8.301706652894584, 8.245133286101527, 8.277157854584864, 8.191243046774755, -3.526534940110713, -6.412130129257861], time: 178.92
mmmaddpg vs mmmaddpg steps: 1624975, episodes: 65000, mean episode reward: 25.98976153818891, agent episode reward: [9.29267750263467, 9.3118779216356, 9.310050387177965, 9.186413710421025, -3.7991620916365245, -7.31209589204383], time: 180.614
mmmaddpg vs mmmaddpg steps: 1649975, episodes: 66000, mean episode reward: 28.353078484808925, agent episode reward: [10.094196408728811, 10.068363647964084, 10.068902646372106, 10.015344510166816, -3.973505062551053, -7.920223665871841], time: 182.415
mmmaddpg vs mmmaddpg steps: 1674975, episodes: 67000, mean episode reward: 27.69998170390243, agent episode reward: [10.004048392295635, 9.998208035693173, 9.96392534552467, 9.892125909853693, -4.318405285176963, -7.839920694287778], time: 186.811
mmmaddpg vs mmmaddpg steps: 1699975, episodes: 68000, mean episode reward: 25.479881352547654, agent episode reward: [9.312162032155305, 9.33800569529874, 9.281319022061908, 9.285458692201402, -4.0724468308562, -7.664617258313499], time: 187.209
mmmaddpg vs mmmaddpg steps: 1724975, episodes: 69000, mean episode reward: 28.371682884082766, agent episode reward: [10.056338479798157, 10.071373518168395, 9.982354556886191, 9.967864825853288, -3.830416651707109, -7.875831844916163], time: 184.307
mmmaddpg vs mmmaddpg steps: 1749975, episodes: 70000, mean episode reward: 27.978090179831643, agent episode reward: [9.895851459349972, 9.888028904611387, 9.86962549633418, 9.890999091362353, -3.9540724063763677, -7.612342365449882], time: 182.971
mmmaddpg vs mmmaddpg steps: 1774975, episodes: 71000, mean episode reward: 30.261721244744606, agent episode reward: [10.721455904112238, 10.718444066470482, 10.686681670982754, 10.648283679380663, -3.7107411470905025, -8.802402929111027], time: 187.726
mmmaddpg vs mmmaddpg steps: 1799975, episodes: 72000, mean episode reward: 30.598604925260965, agent episode reward: [10.75436980265304, 10.773553533447066, 10.657260752704307, 10.640898399060234, -3.623106872261133, -8.604370690342549], time: 187.414
mmmaddpg vs mmmaddpg steps: 1824975, episodes: 73000, mean episode reward: 25.663186680825383, agent episode reward: [9.557444008465273, 9.561715161293291, 9.521388540886266, 9.479736109531752, -3.789357515764368, -8.667739623586828], time: 185.725
mmmaddpg vs mmmaddpg steps: 1849975, episodes: 74000, mean episode reward: 28.75997715920303, agent episode reward: [10.608075064325142, 10.586648690388921, 10.549056312622485, 10.502258172567258, -4.105064739221202, -9.380996341479571], time: 182.676
mmmaddpg vs mmmaddpg steps: 1874975, episodes: 75000, mean episode reward: 29.999142531172836, agent episode reward: [10.812386261135496, 10.76332340075426, 10.727395639926725, 10.649639819046657, -3.5465890283722237, -9.407013561318076], time: 179.182
mmmaddpg vs mmmaddpg steps: 1899975, episodes: 76000, mean episode reward: 32.10010082338388, agent episode reward: [11.429387075932068, 11.300759606141728, 11.21217636678553, 11.179532438643335, -3.385470875117899, -9.63628378900088], time: 180.034
mmmaddpg vs mmmaddpg steps: 1924975, episodes: 77000, mean episode reward: 35.24846852778407, agent episode reward: [12.603748843678645, 12.480926526331302, 12.377351534994657, 12.29166278160243, -3.538885791828969, -10.966335366994], time: 185.69
mmmaddpg vs mmmaddpg steps: 1949975, episodes: 78000, mean episode reward: 33.51016327857293, agent episode reward: [12.198297625340555, 12.052690220690925, 12.001018570774217, 11.952863501462202, -3.4973670751819417, -11.19733956451303], time: 183.218
mmmaddpg vs mmmaddpg steps: 1974975, episodes: 79000, mean episode reward: 34.15894028715516, agent episode reward: [12.16596551112473, 11.97650738404533, 11.939283115320112, 11.884564336666019, -2.8256024608207504, -10.981777599180274], time: 179.331
mmmaddpg vs mmmaddpg steps: 1999975, episodes: 80000, mean episode reward: 36.02524338924226, agent episode reward: [12.792812252802243, 12.64348047475379, 12.537675010548202, 12.492263526903477, -3.1391134810498356, -11.301874394715615], time: 181.859
mmmaddpg vs mmmaddpg steps: 2024975, episodes: 81000, mean episode reward: 38.856245589628685, agent episode reward: [13.725652379738497, 13.520610571366928, 13.412344528890602, 13.387534763600703, -2.9848320685652636, -12.20506458540278], time: 190.838
mmmaddpg vs mmmaddpg steps: 2049975, episodes: 82000, mean episode reward: 35.10884360861973, agent episode reward: [12.519852946816194, 12.292580407186717, 12.245963701225813, 12.180414032262723, -2.394796670618563, -11.735170808253152], time: 182.059
mmmaddpg vs mmmaddpg steps: 2074975, episodes: 83000, mean episode reward: 36.511269750746585, agent episode reward: [13.054210532955864, 12.891135186866224, 12.746974969481926, 12.719677313667649, -1.9565427314212207, -12.944185520803854], time: 189.988
mmmaddpg vs mmmaddpg steps: 2099975, episodes: 84000, mean episode reward: 38.39287469019148, agent episode reward: [13.424609340613333, 13.204320044322102, 13.063429462997599, 13.063962606494133, -1.9496022508104593, -12.413844513425222], time: 191.091
mmmaddpg vs mmmaddpg steps: 2124975, episodes: 85000, mean episode reward: 39.1526252554726, agent episode reward: [13.73337400070239, 13.509046427434637, 13.443861101196992, 13.376167759998319, -1.846071480725968, -13.06375255313377], time: 185.211
mmmaddpg vs mmmaddpg steps: 2149975, episodes: 86000, mean episode reward: 38.259235165215884, agent episode reward: [13.63059754922182, 13.37883750904528, 13.253289343537633, 13.23429354974932, -1.7221424111585284, -13.51564037517964], time: 184.141
mmmaddpg vs mmmaddpg steps: 2174975, episodes: 87000, mean episode reward: 34.12550278404703, agent episode reward: [12.207745099351463, 11.973299243738431, 11.813992033794824, 11.821584848708731, -1.293300410912002, -12.397818030634422], time: 188.014
mmmaddpg vs mmmaddpg steps: 2199975, episodes: 88000, mean episode reward: 38.70102114580657, agent episode reward: [13.85336979742981, 13.571770464550445, 13.553549129081047, 13.415529631887727, -1.7069314153034378, -13.98626646183902], time: 184.236
mmmaddpg vs mmmaddpg steps: 2224975, episodes: 89000, mean episode reward: 37.638151794174895, agent episode reward: [13.615703757610317, 13.347502410261015, 13.311000545726811, 13.22002938749316, -2.0199525353552974, -13.836131771561108], time: 186.607
mmmaddpg vs mmmaddpg steps: 2249975, episodes: 90000, mean episode reward: 33.292195515311775, agent episode reward: [12.21812959451585, 11.971122939916716, 11.969879190764491, 11.844060307070656, -1.8925363475883898, -12.818460169367544], time: 188.875
mmmaddpg vs mmmaddpg steps: 2274975, episodes: 91000, mean episode reward: 35.34212201319222, agent episode reward: [12.88240006691207, 12.68265346241398, 12.609452947485547, 12.555054237834716, -2.0362229082742265, -13.351215793179865], time: 181.514
mmmaddpg vs mmmaddpg steps: 2299975, episodes: 92000, mean episode reward: 35.51543533452507, agent episode reward: [12.713169208460032, 12.524280818075626, 12.421474050762532, 12.460790134025324, -2.1663050079073396, -12.437973868891103], time: 180.574
mmmaddpg vs mmmaddpg steps: 2324975, episodes: 93000, mean episode reward: 32.434450391924734, agent episode reward: [11.777188060492286, 11.670235637527705, 11.586843404546276, 11.552899892483664, -2.1522464175627456, -12.000470185562452], time: 185.844
mmmaddpg vs mmmaddpg steps: 2349975, episodes: 94000, mean episode reward: 30.065379999467513, agent episode reward: [10.960558179883014, 10.824307182741624, 10.793869852240318, 10.729007324617596, -2.438832666164175, -10.803529873850865], time: 187.124
mmmaddpg vs mmmaddpg steps: 2374975, episodes: 95000, mean episode reward: 30.827874390610884, agent episode reward: [11.339154514416611, 11.175296797366432, 11.163706707406316, 11.113610571293746, -2.989948690988621, -10.973945508883604], time: 183.755
mmmaddpg vs mmmaddpg steps: 2399975, episodes: 96000, mean episode reward: 32.34599272536437, agent episode reward: [11.836644216797334, 11.710582504743144, 11.600414151057926, 11.607793813732092, -2.6697263483364173, -11.739715612629709], time: 184.84
mmmaddpg vs mmmaddpg steps: 2424975, episodes: 97000, mean episode reward: 32.8811859811123, agent episode reward: [11.840505939920584, 11.6995650112439, 11.43526712635914, 11.619738925857975, -2.7212273639683464, -10.992663658300955], time: 190.426
mmmaddpg vs mmmaddpg steps: 2449975, episodes: 98000, mean episode reward: 34.23644332366726, agent episode reward: [12.322994110577488, 12.226569941156114, 11.987875093511084, 12.168955224828347, -3.270087843808311, -11.199863202597463], time: 187.02
mmmaddpg vs mmmaddpg steps: 2474975, episodes: 99000, mean episode reward: 30.481058538664005, agent episode reward: [11.131089115596515, 10.983494031034507, 10.803136283321686, 10.947768591633208, -2.2021035031052403, -11.18232597981667], time: 183.499
mmmaddpg vs mmmaddpg steps: 2499975, episodes: 100000, mean episode reward: 31.59117068103699, agent episode reward: [11.573335274625029, 11.452276400639628, 11.275875636472438, 11.415798729675473, -2.9070974136819117, -11.219017946693672], time: 177.306
...Finished total of 100001 episodes.
