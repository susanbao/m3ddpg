0 bad agents
      adv rate for q_index :  0 [1e-05, 1e-05, 1e-05, 0.001]
      adv rate for p_index :  0 [1e-05, 1e-05, 1e-05, 0.001]
1 bad agents
      adv rate for q_index :  1 [1e-05, 1e-05, 1e-05, 0.001]
      adv rate for p_index :  1 [1e-05, 1e-05, 1e-05, 0.001]
2 bad agents
      adv rate for q_index :  2 [1e-05, 1e-05, 1e-05, 0.001]
      adv rate for p_index :  2 [1e-05, 1e-05, 1e-05, 0.001]
3 good agents
      adv rate for q_index :  3 [0.001, 0.001, 0.001, 1e-05]
      adv rate for p_index :  3 [0.001, 0.001, 0.001, 1e-05]
Using good policy mmmaddpg and bad policy mmmaddpg with 3 adversaries
Starting iterations...
mmmaddpg vs mmmaddpg steps: 24975, episodes: 1000, mean episode reward: -6.451280497053287, agent episode reward: [2.34, 2.34, 2.34, -13.471280497053286], time: 68.944
mmmaddpg vs mmmaddpg steps: 49975, episodes: 2000, mean episode reward: -0.8712869531084725, agent episode reward: [4.14, 4.14, 4.14, -13.291286953108475], time: 104.934
mmmaddpg vs mmmaddpg steps: 74975, episodes: 3000, mean episode reward: 8.535014081792447, agent episode reward: [4.55, 4.55, 4.55, -5.114985918207551], time: 96.374
mmmaddpg vs mmmaddpg steps: 99975, episodes: 4000, mean episode reward: 18.17999338019444, agent episode reward: [9.5, 9.5, 9.5, -10.32000661980556], time: 98.116
mmmaddpg vs mmmaddpg steps: 124975, episodes: 5000, mean episode reward: 38.057689646106724, agent episode reward: [20.34, 20.34, 20.34, -22.962310353893276], time: 97.206
mmmaddpg vs mmmaddpg steps: 149975, episodes: 6000, mean episode reward: 21.21525974271184, agent episode reward: [13.8, 13.8, 13.8, -20.18474025728816], time: 98.35
mmmaddpg vs mmmaddpg steps: 174975, episodes: 7000, mean episode reward: 15.033808062930413, agent episode reward: [9.98, 9.98, 9.98, -14.906191937069586], time: 95.514
mmmaddpg vs mmmaddpg steps: 199975, episodes: 8000, mean episode reward: 20.610740176332936, agent episode reward: [11.52, 11.52, 11.52, -13.949259823667063], time: 95.78
mmmaddpg vs mmmaddpg steps: 224975, episodes: 9000, mean episode reward: 38.60893332826445, agent episode reward: [20.8, 20.8, 20.8, -23.791066671735553], time: 97.169
mmmaddpg vs mmmaddpg steps: 249975, episodes: 10000, mean episode reward: 49.90448495291507, agent episode reward: [26.19, 26.19, 26.19, -28.66551504708493], time: 101.838
mmmaddpg vs mmmaddpg steps: 274975, episodes: 11000, mean episode reward: 35.65859504193214, agent episode reward: [20.07, 20.07, 20.07, -24.551404958067863], time: 101.122
mmmaddpg vs mmmaddpg steps: 299975, episodes: 12000, mean episode reward: 17.95215254161976, agent episode reward: [11.47, 11.47, 11.47, -16.45784745838024], time: 99.724
mmmaddpg vs mmmaddpg steps: 324975, episodes: 13000, mean episode reward: 13.919495335841251, agent episode reward: [9.61, 9.61, 9.61, -14.910504664158749], time: 97.45
mmmaddpg vs mmmaddpg steps: 349975, episodes: 14000, mean episode reward: 11.17781840860187, agent episode reward: [8.92, 8.92, 8.92, -15.582181591398133], time: 100.206
mmmaddpg vs mmmaddpg steps: 374975, episodes: 15000, mean episode reward: 12.798245641142916, agent episode reward: [8.86, 8.86, 8.86, -13.781754358857084], time: 99.936
mmmaddpg vs mmmaddpg steps: 399975, episodes: 16000, mean episode reward: 11.508352601367994, agent episode reward: [7.94, 7.94, 7.94, -12.311647398632005], time: 98.832
mmmaddpg vs mmmaddpg steps: 424975, episodes: 17000, mean episode reward: 11.661779781757748, agent episode reward: [7.52, 7.52, 7.52, -10.898220218242251], time: 100.415
mmmaddpg vs mmmaddpg steps: 449975, episodes: 18000, mean episode reward: 12.724176829313638, agent episode reward: [7.75, 7.75, 7.75, -10.525823170686362], time: 99.628
mmmaddpg vs mmmaddpg steps: 474975, episodes: 19000, mean episode reward: 11.052015472066635, agent episode reward: [6.89, 6.89, 6.89, -9.617984527933363], time: 95.677
mmmaddpg vs mmmaddpg steps: 499975, episodes: 20000, mean episode reward: 10.332186811875072, agent episode reward: [6.17, 6.17, 6.17, -8.177813188124928], time: 98.226
mmmaddpg vs mmmaddpg steps: 524975, episodes: 21000, mean episode reward: 12.197567322818344, agent episode reward: [7.06, 7.06, 7.06, -8.982432677181656], time: 100.664
mmmaddpg vs mmmaddpg steps: 549975, episodes: 22000, mean episode reward: 9.689320945641319, agent episode reward: [5.9, 5.9, 5.9, -8.01067905435868], time: 98.629
mmmaddpg vs mmmaddpg steps: 574975, episodes: 23000, mean episode reward: 8.815757151479746, agent episode reward: [5.49, 5.49, 5.49, -7.654242848520254], time: 98.06
mmmaddpg vs mmmaddpg steps: 599975, episodes: 24000, mean episode reward: 11.44553655853104, agent episode reward: [6.6, 6.6, 6.6, -8.354463441468958], time: 98.967
mmmaddpg vs mmmaddpg steps: 624975, episodes: 25000, mean episode reward: 11.268288400822334, agent episode reward: [6.51, 6.51, 6.51, -8.261711599177666], time: 99.79
mmmaddpg vs mmmaddpg steps: 649975, episodes: 26000, mean episode reward: 12.906673551690009, agent episode reward: [7.59, 7.59, 7.59, -9.863326448309993], time: 95.88
mmmaddpg vs mmmaddpg steps: 674975, episodes: 27000, mean episode reward: 15.782016810191918, agent episode reward: [8.91, 8.91, 8.91, -10.947983189808081], time: 96.444
mmmaddpg vs mmmaddpg steps: 699975, episodes: 28000, mean episode reward: 20.66639890502501, agent episode reward: [11.31, 11.31, 11.31, -13.263601094974991], time: 97.065
mmmaddpg vs mmmaddpg steps: 724975, episodes: 29000, mean episode reward: 27.883237069121176, agent episode reward: [14.53, 14.53, 14.53, -15.706762930878828], time: 98.678
mmmaddpg vs mmmaddpg steps: 749975, episodes: 30000, mean episode reward: 41.724907585642605, agent episode reward: [21.62, 21.62, 21.62, -23.135092414357395], time: 100.021
mmmaddpg vs mmmaddpg steps: 774975, episodes: 31000, mean episode reward: 54.31451377847947, agent episode reward: [27.96, 27.96, 27.96, -29.56548622152053], time: 96.992
mmmaddpg vs mmmaddpg steps: 799975, episodes: 32000, mean episode reward: 53.404504920480015, agent episode reward: [27.51, 27.51, 27.51, -29.125495079519983], time: 97.95
mmmaddpg vs mmmaddpg steps: 824975, episodes: 33000, mean episode reward: 54.04841327489073, agent episode reward: [27.9, 27.9, 27.9, -29.65158672510927], time: 97.076
mmmaddpg vs mmmaddpg steps: 849975, episodes: 34000, mean episode reward: 47.17688093356567, agent episode reward: [24.68, 24.68, 24.68, -26.863119066434333], time: 97.696
mmmaddpg vs mmmaddpg steps: 874975, episodes: 35000, mean episode reward: 37.47603188555499, agent episode reward: [20.12, 20.12, 20.12, -22.883968114445018], time: 98.702
mmmaddpg vs mmmaddpg steps: 899975, episodes: 36000, mean episode reward: 33.34259203572436, agent episode reward: [18.34, 18.34, 18.34, -21.67740796427564], time: 99.71
mmmaddpg vs mmmaddpg steps: 924975, episodes: 37000, mean episode reward: 31.039116048009184, agent episode reward: [17.13, 17.13, 17.13, -20.350883951990816], time: 96.888
mmmaddpg vs mmmaddpg steps: 949975, episodes: 38000, mean episode reward: 22.199787343969152, agent episode reward: [13.15, 13.15, 13.15, -17.250212656030847], time: 98.381
mmmaddpg vs mmmaddpg steps: 974975, episodes: 39000, mean episode reward: 19.245625387010197, agent episode reward: [12.12, 12.12, 12.12, -17.114374612989803], time: 99.64
mmmaddpg vs mmmaddpg steps: 999975, episodes: 40000, mean episode reward: 15.755112004116864, agent episode reward: [11.06, 11.06, 11.06, -17.42488799588314], time: 99.113
mmmaddpg vs mmmaddpg steps: 1024975, episodes: 41000, mean episode reward: 12.639505948714817, agent episode reward: [9.47, 9.47, 9.47, -15.770494051285183], time: 99.925
mmmaddpg vs mmmaddpg steps: 1049975, episodes: 42000, mean episode reward: 15.81267709055598, agent episode reward: [11.03, 11.03, 11.03, -17.277322909444017], time: 98.575
mmmaddpg vs mmmaddpg steps: 1074975, episodes: 43000, mean episode reward: 14.442010124552537, agent episode reward: [10.18, 10.18, 10.18, -16.097989875447468], time: 100.377
mmmaddpg vs mmmaddpg steps: 1099975, episodes: 44000, mean episode reward: 14.328992828541443, agent episode reward: [9.93, 9.93, 9.93, -15.461007171458562], time: 99.425
mmmaddpg vs mmmaddpg steps: 1124975, episodes: 45000, mean episode reward: 12.163820714328462, agent episode reward: [9.23, 9.23, 9.23, -15.52617928567154], time: 99.029
mmmaddpg vs mmmaddpg steps: 1149975, episodes: 46000, mean episode reward: 14.238024217663105, agent episode reward: [9.75, 9.75, 9.75, -15.011975782336895], time: 100.001
mmmaddpg vs mmmaddpg steps: 1174975, episodes: 47000, mean episode reward: 12.332318829225118, agent episode reward: [8.71, 8.71, 8.71, -13.797681170774881], time: 98.607
mmmaddpg vs mmmaddpg steps: 1199975, episodes: 48000, mean episode reward: 13.89372226745958, agent episode reward: [9.66, 9.66, 9.66, -15.086277732540418], time: 98.117
mmmaddpg vs mmmaddpg steps: 1224975, episodes: 49000, mean episode reward: 13.730533845553698, agent episode reward: [9.76, 9.76, 9.76, -15.549466154446302], time: 96.814
mmmaddpg vs mmmaddpg steps: 1249975, episodes: 50000, mean episode reward: 14.784373511260712, agent episode reward: [9.87, 9.87, 9.87, -14.825626488739287], time: 98.969
mmmaddpg vs mmmaddpg steps: 1274975, episodes: 51000, mean episode reward: 14.79996493681585, agent episode reward: [10.07, 10.07, 10.07, -15.410035063184148], time: 99.551
mmmaddpg vs mmmaddpg steps: 1299975, episodes: 52000, mean episode reward: 16.388896302823568, agent episode reward: [10.6, 10.6, 10.6, -15.411103697176433], time: 100.324
mmmaddpg vs mmmaddpg steps: 1324975, episodes: 53000, mean episode reward: 15.920895437874925, agent episode reward: [10.29, 10.29, 10.29, -14.949104562125077], time: 97.943
mmmaddpg vs mmmaddpg steps: 1349975, episodes: 54000, mean episode reward: 20.90038634479109, agent episode reward: [12.93, 12.93, 12.93, -17.88961365520891], time: 101.155
mmmaddpg vs mmmaddpg steps: 1374975, episodes: 55000, mean episode reward: 16.681275343878198, agent episode reward: [10.81, 10.81, 10.81, -15.748724656121802], time: 97.717
mmmaddpg vs mmmaddpg steps: 1399975, episodes: 56000, mean episode reward: 16.72590852136067, agent episode reward: [10.98, 10.98, 10.98, -16.21409147863933], time: 99.806
mmmaddpg vs mmmaddpg steps: 1424975, episodes: 57000, mean episode reward: 15.71164739039117, agent episode reward: [10.15, 10.15, 10.15, -14.73835260960883], time: 101.228
mmmaddpg vs mmmaddpg steps: 1449975, episodes: 58000, mean episode reward: 17.373067628251246, agent episode reward: [10.61, 10.61, 10.61, -14.456932371748751], time: 98.043
mmmaddpg vs mmmaddpg steps: 1474975, episodes: 59000, mean episode reward: 17.91293542620603, agent episode reward: [10.98, 10.98, 10.98, -15.027064573793972], time: 98.68
mmmaddpg vs mmmaddpg steps: 1499975, episodes: 60000, mean episode reward: 19.119350737951212, agent episode reward: [11.52, 11.52, 11.52, -15.440649262048789], time: 100.373
mmmaddpg vs mmmaddpg steps: 1524975, episodes: 61000, mean episode reward: 16.50640605830412, agent episode reward: [10.39, 10.39, 10.39, -14.663593941695883], time: 99.761
mmmaddpg vs mmmaddpg steps: 1549975, episodes: 62000, mean episode reward: 16.405176948238484, agent episode reward: [10.33, 10.33, 10.33, -14.584823051761516], time: 99.659
mmmaddpg vs mmmaddpg steps: 1574975, episodes: 63000, mean episode reward: 15.728291115143865, agent episode reward: [10.21, 10.21, 10.21, -14.901708884856136], time: 101.165
mmmaddpg vs mmmaddpg steps: 1599975, episodes: 64000, mean episode reward: 17.359836796311345, agent episode reward: [10.86, 10.86, 10.86, -15.220163203688655], time: 99.021
mmmaddpg vs mmmaddpg steps: 1624975, episodes: 65000, mean episode reward: 14.432790106304957, agent episode reward: [9.65, 9.65, 9.65, -14.517209893695043], time: 96.801
mmmaddpg vs mmmaddpg steps: 1649975, episodes: 66000, mean episode reward: 16.102114229400406, agent episode reward: [10.1, 10.1, 10.1, -14.19788577059959], time: 98.613
mmmaddpg vs mmmaddpg steps: 1674975, episodes: 67000, mean episode reward: 14.404445102390225, agent episode reward: [9.44, 9.44, 9.44, -13.915554897609775], time: 100.009
mmmaddpg vs mmmaddpg steps: 1699975, episodes: 68000, mean episode reward: 13.010282228383074, agent episode reward: [8.97, 8.97, 8.97, -13.899717771616926], time: 100.754
mmmaddpg vs mmmaddpg steps: 1724975, episodes: 69000, mean episode reward: 12.652018084871562, agent episode reward: [9.19, 9.19, 9.19, -14.917981915128436], time: 97.758
mmmaddpg vs mmmaddpg steps: 1749975, episodes: 70000, mean episode reward: 13.444521444460312, agent episode reward: [9.29, 9.29, 9.29, -14.42547855553969], time: 99.263
mmmaddpg vs mmmaddpg steps: 1774975, episodes: 71000, mean episode reward: 14.486868693606734, agent episode reward: [9.6, 9.6, 9.6, -14.313131306393267], time: 98.83
mmmaddpg vs mmmaddpg steps: 1799975, episodes: 72000, mean episode reward: 9.949955813833125, agent episode reward: [7.69, 7.69, 7.69, -13.120044186166876], time: 99.088
mmmaddpg vs mmmaddpg steps: 1824975, episodes: 73000, mean episode reward: 15.245412237303961, agent episode reward: [10.51, 10.51, 10.51, -16.284587762696038], time: 97.745
mmmaddpg vs mmmaddpg steps: 1849975, episodes: 74000, mean episode reward: 9.390652504050456, agent episode reward: [8.02, 8.02, 8.02, -14.669347495949543], time: 98.572
mmmaddpg vs mmmaddpg steps: 1874975, episodes: 75000, mean episode reward: 14.045895472700005, agent episode reward: [9.69, 9.69, 9.69, -15.024104527299995], time: 101.61
mmmaddpg vs mmmaddpg steps: 1899975, episodes: 76000, mean episode reward: 14.835420629988532, agent episode reward: [10.11, 10.11, 10.11, -15.494579370011468], time: 101.867
mmmaddpg vs mmmaddpg steps: 1924975, episodes: 77000, mean episode reward: 14.779026251144384, agent episode reward: [9.9, 9.9, 9.9, -14.920973748855616], time: 100.803
mmmaddpg vs mmmaddpg steps: 1949975, episodes: 78000, mean episode reward: 15.264871762804177, agent episode reward: [9.71, 9.71, 9.71, -13.865128237195824], time: 98.392
mmmaddpg vs mmmaddpg steps: 1974975, episodes: 79000, mean episode reward: 14.943673696424131, agent episode reward: [10.13, 10.13, 10.13, -15.446326303575868], time: 96.993
mmmaddpg vs mmmaddpg steps: 1999975, episodes: 80000, mean episode reward: 16.657873548783044, agent episode reward: [11.13, 11.13, 11.13, -16.73212645121696], time: 100.109
mmmaddpg vs mmmaddpg steps: 2024975, episodes: 81000, mean episode reward: 19.79384701529806, agent episode reward: [12.39, 12.39, 12.39, -17.376152984701942], time: 101.231
mmmaddpg vs mmmaddpg steps: 2049975, episodes: 82000, mean episode reward: 16.19687238272218, agent episode reward: [11.23, 11.23, 11.23, -17.493127617277818], time: 100.854
mmmaddpg vs mmmaddpg steps: 2074975, episodes: 83000, mean episode reward: 17.603571622065463, agent episode reward: [11.5, 11.5, 11.5, -16.89642837793454], time: 100.565
mmmaddpg vs mmmaddpg steps: 2099975, episodes: 84000, mean episode reward: 20.387210797270303, agent episode reward: [12.78, 12.78, 12.78, -17.952789202729697], time: 101.348
mmmaddpg vs mmmaddpg steps: 2124975, episodes: 85000, mean episode reward: 17.74740143952987, agent episode reward: [11.59, 11.59, 11.59, -17.02259856047013], time: 99.667
mmmaddpg vs mmmaddpg steps: 2149975, episodes: 86000, mean episode reward: 16.79222506490853, agent episode reward: [11.19, 11.19, 11.19, -16.77777493509147], time: 97.377
mmmaddpg vs mmmaddpg steps: 2174975, episodes: 87000, mean episode reward: 21.09421769142655, agent episode reward: [13.16, 13.16, 13.16, -18.38578230857345], time: 99.1
mmmaddpg vs mmmaddpg steps: 2199975, episodes: 88000, mean episode reward: 20.11397049417311, agent episode reward: [12.86, 12.86, 12.86, -18.46602950582689], time: 96.894
mmmaddpg vs mmmaddpg steps: 2224975, episodes: 89000, mean episode reward: 19.176737362457818, agent episode reward: [12.2, 12.2, 12.2, -17.423262637542187], time: 97.661
mmmaddpg vs mmmaddpg steps: 2249975, episodes: 90000, mean episode reward: 19.9008832018993, agent episode reward: [12.7, 12.7, 12.7, -18.1991167981007], time: 97.991
mmmaddpg vs mmmaddpg steps: 2274975, episodes: 91000, mean episode reward: 17.588096470076234, agent episode reward: [11.64, 11.64, 11.64, -17.331903529923764], time: 99.014
mmmaddpg vs mmmaddpg steps: 2299975, episodes: 92000, mean episode reward: 18.602731588041696, agent episode reward: [12.02, 12.02, 12.02, -17.4572684119583], time: 96.473
mmmaddpg vs mmmaddpg steps: 2324975, episodes: 93000, mean episode reward: 18.730802868512487, agent episode reward: [12.21, 12.21, 12.21, -17.89919713148751], time: 98.139
mmmaddpg vs mmmaddpg steps: 2349975, episodes: 94000, mean episode reward: 18.22274855275326, agent episode reward: [11.93, 11.93, 11.93, -17.56725144724674], time: 97.065
mmmaddpg vs mmmaddpg steps: 2374975, episodes: 95000, mean episode reward: 14.4241046264542, agent episode reward: [10.41, 10.41, 10.41, -16.8058953735458], time: 98.596
mmmaddpg vs mmmaddpg steps: 2399975, episodes: 96000, mean episode reward: 12.323621884986748, agent episode reward: [9.39, 9.39, 9.39, -15.846378115013252], time: 96.816
mmmaddpg vs mmmaddpg steps: 2424975, episodes: 97000, mean episode reward: 15.86875549734405, agent episode reward: [11.24, 11.24, 11.24, -17.851244502655952], time: 103.236
mmmaddpg vs mmmaddpg steps: 2449975, episodes: 98000, mean episode reward: 16.860334954384832, agent episode reward: [11.3, 11.3, 11.3, -17.03966504561517], time: 99.355
mmmaddpg vs mmmaddpg steps: 2474975, episodes: 99000, mean episode reward: 16.69242408913166, agent episode reward: [11.25, 11.25, 11.25, -17.05757591086834], time: 101.272
mmmaddpg vs mmmaddpg steps: 2499975, episodes: 100000, mean episode reward: 18.62389169435137, agent episode reward: [12.14, 12.14, 12.14, -17.796108305648627], time: 98.685
...Finished total of 100001 episodes.
