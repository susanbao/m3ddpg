0 bad agents
      adv rate for q_index :  0 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
      adv rate for p_index :  0 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
1 bad agents
      adv rate for q_index :  1 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
      adv rate for p_index :  1 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
2 bad agents
      adv rate for q_index :  2 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
      adv rate for p_index :  2 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
3 bad agents
      adv rate for q_index :  3 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
      adv rate for p_index :  3 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
4 good agents
      adv rate for q_index :  4 [0.001, 0.001, 0.001, 0.001, 1e-05, 1e-05]
      adv rate for p_index :  4 [0.001, 0.001, 0.001, 0.001, 1e-05, 1e-05]
5 good agents
      adv rate for q_index :  5 [0.001, 0.001, 0.001, 0.001, 1e-05, 1e-05]
      adv rate for p_index :  5 [0.001, 0.001, 0.001, 0.001, 1e-05, 1e-05]
Using good policy mmmaddpg and bad policy mmmaddpg with 4 adversaries
Starting iterations...
mmmaddpg vs mmmaddpg steps: 24975, episodes: 1000, mean episode reward: -17.97658214741286, agent episode reward: [1.1660872740574226, 1.1020517634980391, 1.109091432480558, 1.0750489401162457, -10.061297053886214, -12.367564503678912], time: 151.2
mmmaddpg vs mmmaddpg steps: 49975, episodes: 2000, mean episode reward: -19.286015909423448, agent episode reward: [2.63287496808162, 2.6108285274799896, 2.7424982811076153, 3.122580997226834, -10.673774561696948, -19.721024121622555], time: 207.331
mmmaddpg vs mmmaddpg steps: 74975, episodes: 3000, mean episode reward: 13.876074013552364, agent episode reward: [4.923572845709644, 4.602954899134513, 4.65748182103946, 5.067043587532658, -2.9117768790187024, -2.4632022608452107], time: 199.491
mmmaddpg vs mmmaddpg steps: 99975, episodes: 4000, mean episode reward: 15.634200186289693, agent episode reward: [5.050532729933464, 5.441783155674167, 5.214810023219987, 5.526575642837775, -2.8688779427040227, -2.730623422671678], time: 197.572
mmmaddpg vs mmmaddpg steps: 124975, episodes: 5000, mean episode reward: 23.685205490893996, agent episode reward: [8.02725172971693, 8.009690602006994, 7.853277783150142, 8.04534653456574, -3.9971602592017277, -4.25320089934408], time: 199.115
mmmaddpg vs mmmaddpg steps: 149975, episodes: 6000, mean episode reward: 30.069458516551514, agent episode reward: [9.99587784891651, 10.063443233128286, 10.060595547344281, 10.075876506260755, -5.261893750661206, -4.864440868437115], time: 197.519
mmmaddpg vs mmmaddpg steps: 174975, episodes: 7000, mean episode reward: 32.661174885691715, agent episode reward: [10.81582180305506, 10.821457980931235, 10.929559650637414, 10.936250523348692, -4.649337436040612, -6.1925776362400775], time: 201.747
mmmaddpg vs mmmaddpg steps: 199975, episodes: 8000, mean episode reward: 28.643971365029756, agent episode reward: [9.647405067044408, 9.290078879670713, 9.796925372075435, 9.747633105739485, -3.8423334646331706, -5.995737594867116], time: 198.765
mmmaddpg vs mmmaddpg steps: 224975, episodes: 9000, mean episode reward: 24.54795833527743, agent episode reward: [8.568277546510497, 8.24680560378752, 8.586323890727092, 8.528396757307034, -4.230107039907109, -5.151738423147605], time: 203.372
mmmaddpg vs mmmaddpg steps: 249975, episodes: 10000, mean episode reward: 25.5409360332658, agent episode reward: [8.550412669094035, 8.376322980240358, 8.489779742319035, 8.531199845500472, -3.7034883908452803, -4.703290813042821], time: 200.706
mmmaddpg vs mmmaddpg steps: 274975, episodes: 11000, mean episode reward: 24.428231887717267, agent episode reward: [8.407434405750095, 8.370743125457262, 8.322554853023503, 8.325063007927525, -4.689197986246923, -4.308365518194195], time: 201.362
mmmaddpg vs mmmaddpg steps: 299975, episodes: 12000, mean episode reward: 24.285807353581557, agent episode reward: [8.227173946769812, 8.171473636135124, 8.186826478100395, 8.172061285468612, -4.119062477302713, -4.3526655155896705], time: 198.551
mmmaddpg vs mmmaddpg steps: 324975, episodes: 13000, mean episode reward: 21.476778182629683, agent episode reward: [7.583535383135782, 7.448362493640998, 7.463609281972234, 7.478545461550106, -3.8441424575542706, -4.653131980115164], time: 199.706
mmmaddpg vs mmmaddpg steps: 349975, episodes: 14000, mean episode reward: 17.80922843545603, agent episode reward: [6.342504348144978, 6.191232021322916, 6.251896950685557, 6.325379913088884, -3.478373294741875, -3.823411503044429], time: 200.978
mmmaddpg vs mmmaddpg steps: 374975, episodes: 15000, mean episode reward: 18.721455924263406, agent episode reward: [6.89302718585711, 6.811484709844209, 6.794022058794557, 6.9429390121367325, -3.847399536637686, -4.872617505731519], time: 201.944
mmmaddpg vs mmmaddpg steps: 399975, episodes: 16000, mean episode reward: 17.36115532117218, agent episode reward: [6.279976671832397, 6.232746226597819, 6.278204278053431, 6.333537860145432, -4.834362644978781, -2.9289470704781206], time: 198.647
mmmaddpg vs mmmaddpg steps: 424975, episodes: 17000, mean episode reward: 21.672948023890772, agent episode reward: [7.28231915477549, 7.291495618486327, 7.398515192513783, 7.460436182552291, -4.92020277083259, -2.8396153536045285], time: 196.921
mmmaddpg vs mmmaddpg steps: 449975, episodes: 18000, mean episode reward: 21.843050652149692, agent episode reward: [7.282744441568943, 7.003957072143259, 7.3041221718404366, 7.368582200821491, -4.633596219175733, -2.4827590150486993], time: 202.333
mmmaddpg vs mmmaddpg steps: 474975, episodes: 19000, mean episode reward: 22.824009925959725, agent episode reward: [7.8002545625480195, 7.466136401885204, 7.855564467492578, 7.697363097068099, -5.4524320397239965, -2.5428765633101746], time: 203.823
mmmaddpg vs mmmaddpg steps: 499975, episodes: 20000, mean episode reward: 22.45044842690609, agent episode reward: [7.798879631876949, 7.302469766662593, 7.8529640556937625, 7.602114113482048, -5.265788514699921, -2.840190626109346], time: 200.311
mmmaddpg vs mmmaddpg steps: 524975, episodes: 21000, mean episode reward: 24.428814399584407, agent episode reward: [8.352398604106993, 7.962610962630026, 8.412316900285044, 8.100411613831525, -5.719805912915294, -2.679117768353884], time: 202.812
mmmaddpg vs mmmaddpg steps: 549975, episodes: 22000, mean episode reward: 25.51534686574978, agent episode reward: [8.832833815311322, 8.420441287327463, 8.851737177027148, 8.545635344756441, -5.982373668208231, -3.1529270904643645], time: 197.792
mmmaddpg vs mmmaddpg steps: 574975, episodes: 23000, mean episode reward: 24.404696558005956, agent episode reward: [8.407063879535475, 8.00110612540773, 8.444171556963072, 8.108057161946908, -5.37085009566001, -3.184852070187224], time: 201.927
mmmaddpg vs mmmaddpg steps: 599975, episodes: 24000, mean episode reward: 23.813121126603995, agent episode reward: [8.422216368289966, 7.941674133162506, 8.505708863540416, 8.137914195464543, -5.4594902773109055, -3.7349021565425318], time: 204.621
mmmaddpg vs mmmaddpg steps: 624975, episodes: 25000, mean episode reward: 26.34579617837398, agent episode reward: [9.023332319064192, 8.596755304258691, 9.11530845971962, 8.748500529463412, -6.3254529050825745, -2.8126475290493573], time: 203.138
mmmaddpg vs mmmaddpg steps: 649975, episodes: 26000, mean episode reward: 29.317005979314665, agent episode reward: [10.029126388587743, 9.662672425067894, 10.172219123871658, 9.838607571537372, -7.238372393614196, -3.1472471361358068], time: 196.371
mmmaddpg vs mmmaddpg steps: 674975, episodes: 27000, mean episode reward: 30.669118008743673, agent episode reward: [10.598659188151592, 10.297158719977633, 10.720998726188723, 10.4225850342027, -7.051330532223678, -4.318953127553298], time: 200.284
mmmaddpg vs mmmaddpg steps: 699975, episodes: 28000, mean episode reward: 32.1420510530023, agent episode reward: [10.812524713921333, 10.523420850133123, 10.877510876355936, 10.685058031522338, -6.5409099220541975, -4.215553496876233], time: 197.143
mmmaddpg vs mmmaddpg steps: 724975, episodes: 29000, mean episode reward: 37.50160864920209, agent episode reward: [12.509625906305146, 12.204176383576948, 12.585857789029305, 12.299010472682387, -7.748366510541304, -4.348695391850396], time: 195.798
mmmaddpg vs mmmaddpg steps: 749975, episodes: 30000, mean episode reward: 38.332985688382365, agent episode reward: [12.898870347179553, 12.58201701074138, 12.88769128550492, 12.57171773502682, -8.45452809355646, -4.152782596513844], time: 201.33
mmmaddpg vs mmmaddpg steps: 774975, episodes: 31000, mean episode reward: 35.96753268450046, agent episode reward: [12.086037536889423, 11.79847204861591, 12.066595963630958, 11.728349414470761, -7.826376120475712, -3.885546158630873], time: 198.568
mmmaddpg vs mmmaddpg steps: 799975, episodes: 32000, mean episode reward: 33.917168228028245, agent episode reward: [11.287888773538837, 11.11079985910985, 11.207353914707939, 10.91890390933923, -6.7896447173017, -3.8181335113659056], time: 202.187
mmmaddpg vs mmmaddpg steps: 824975, episodes: 33000, mean episode reward: 37.715007916710945, agent episode reward: [12.678301721677027, 12.436995319198854, 12.707762835863814, 12.376794372287593, -8.872546839031001, -3.6122994932853447], time: 201.745
mmmaddpg vs mmmaddpg steps: 849975, episodes: 34000, mean episode reward: 36.806841193528484, agent episode reward: [12.4232056386658, 12.21995350640724, 12.350786897218514, 12.132687164117428, -8.042215052285245, -4.277576960595263], time: 200.975
mmmaddpg vs mmmaddpg steps: 874975, episodes: 35000, mean episode reward: 37.33738420708051, agent episode reward: [12.716167332571436, 12.462733203685366, 12.60631248830329, 12.37620466562395, -8.182558126273772, -4.641475356829768], time: 203.761
mmmaddpg vs mmmaddpg steps: 899975, episodes: 36000, mean episode reward: 40.76402234529557, agent episode reward: [13.70462231551252, 13.501735689519938, 13.573307083237166, 13.334852831394924, -8.222546809157299, -5.127948765211681], time: 203.018
mmmaddpg vs mmmaddpg steps: 924975, episodes: 37000, mean episode reward: 35.25780713129017, agent episode reward: [11.947782648174348, 11.814418642292553, 11.905738149918946, 11.747316050852703, -6.9811469226907015, -5.176301437257682], time: 202.378
mmmaddpg vs mmmaddpg steps: 949975, episodes: 38000, mean episode reward: 32.274511399870526, agent episode reward: [11.177363281083757, 11.056017008722339, 11.066542137700509, 11.032487316254171, -6.206055958813831, -5.851842385076419], time: 202.09
mmmaddpg vs mmmaddpg steps: 974975, episodes: 39000, mean episode reward: 27.638595738313896, agent episode reward: [10.848300055595493, 10.757697136255432, 10.696763308481913, 10.640292698782451, -8.197137623200554, -7.107319837600836], time: 197.563
mmmaddpg vs mmmaddpg steps: 999975, episodes: 40000, mean episode reward: 33.7588265897121, agent episode reward: [12.343920600432048, 12.326978595324475, 12.345977084409045, 12.224247688407475, -7.585690419195904, -7.896606959665041], time: 197.597
mmmaddpg vs mmmaddpg steps: 1024975, episodes: 41000, mean episode reward: 39.99344763289955, agent episode reward: [13.821646901719385, 13.678570517731181, 13.76282192359135, 13.662571219244095, -8.017806191116009, -6.914356738270455], time: 200.612
mmmaddpg vs mmmaddpg steps: 1049975, episodes: 42000, mean episode reward: 34.65857597722619, agent episode reward: [12.162156251654539, 12.090450219812165, 12.117574187773858, 12.023151083887056, -6.627528812674444, -7.107226953226973], time: 200.792
mmmaddpg vs mmmaddpg steps: 1074975, episodes: 43000, mean episode reward: 30.806466750931673, agent episode reward: [10.561775012738678, 10.576617090754684, 10.469922133702891, 10.362001636963946, -5.6774803251997445, -5.4863687980287805], time: 205.471
mmmaddpg vs mmmaddpg steps: 1099975, episodes: 44000, mean episode reward: 32.80561804591387, agent episode reward: [11.194598791297253, 11.291528706075601, 11.161614519718071, 10.939195510006344, -6.162431823477429, -5.618887657705971], time: 199.336
mmmaddpg vs mmmaddpg steps: 1124975, episodes: 45000, mean episode reward: 36.443346953939674, agent episode reward: [12.350688885364027, 12.452928042442927, 12.292249623925246, 12.127385823612393, -6.69843014474572, -6.081475276659195], time: 205.446
mmmaddpg vs mmmaddpg steps: 1149975, episodes: 46000, mean episode reward: 40.685529217556436, agent episode reward: [13.90180293087509, 13.918813233400774, 13.844171200693822, 13.637503519850739, -7.852717748973714, -6.764043918290274], time: 205.402
mmmaddpg vs mmmaddpg steps: 1174975, episodes: 47000, mean episode reward: 44.891624926646294, agent episode reward: [15.449757735492913, 15.272758347089187, 15.279976659027328, 14.984201182772166, -9.786840249267563, -6.308228748467742], time: 203.009
mmmaddpg vs mmmaddpg steps: 1199975, episodes: 48000, mean episode reward: 50.025301268115506, agent episode reward: [17.229287591878645, 17.032246131238107, 17.046652707693653, 16.863181705394208, -11.400307508511515, -6.745759359577587], time: 204.276
mmmaddpg vs mmmaddpg steps: 1224975, episodes: 49000, mean episode reward: 43.83921929685934, agent episode reward: [15.467702392196465, 15.087167240834873, 15.226548837387044, 15.065209083005069, -11.252084493283322, -5.755323763280793], time: 204.35
mmmaddpg vs mmmaddpg steps: 1249975, episodes: 50000, mean episode reward: 45.02594015005043, agent episode reward: [15.594960445017383, 15.284033550225391, 15.337639272104433, 15.291066186653048, -11.112121199034767, -5.369638104915057], time: 191.055
mmmaddpg vs mmmaddpg steps: 1274975, episodes: 51000, mean episode reward: 40.242450459609564, agent episode reward: [14.027467931123434, 13.906567409518606, 13.806084576550733, 13.900636591705181, -9.474297051831272, -5.924008997457124], time: 186.99
mmmaddpg vs mmmaddpg steps: 1299975, episodes: 52000, mean episode reward: 34.56487764622728, agent episode reward: [12.469551329981734, 12.326081231119131, 12.153511488374173, 12.24629585260546, -8.445549744168298, -6.185012511684917], time: 187.601
mmmaddpg vs mmmaddpg steps: 1324975, episodes: 53000, mean episode reward: 39.48209351487072, agent episode reward: [14.087122374291768, 13.943489584744142, 13.766147180319832, 13.832122052298754, -10.01443042100866, -6.132357255775122], time: 187.499
mmmaddpg vs mmmaddpg steps: 1349975, episodes: 54000, mean episode reward: 38.6974642125829, agent episode reward: [13.56667473807974, 13.431793690890753, 13.355092442847559, 13.326653977020097, -9.412597827123003, -5.5701528091322485], time: 187.247
mmmaddpg vs mmmaddpg steps: 1374975, episodes: 55000, mean episode reward: 35.836443812461845, agent episode reward: [12.712169737814822, 12.597175389547939, 12.55174497427923, 12.491376129719782, -8.628620695370028, -5.887401723529903], time: 180.232
mmmaddpg vs mmmaddpg steps: 1399975, episodes: 56000, mean episode reward: 35.08791817986981, agent episode reward: [12.36564034240702, 12.344888454907704, 12.235969785106105, 12.219288013937625, -8.698915425620758, -5.378952990867881], time: 182.182
mmmaddpg vs mmmaddpg steps: 1424975, episodes: 57000, mean episode reward: 34.326748998545646, agent episode reward: [12.35424982676725, 12.337644204644217, 12.304817093995783, 12.191257356684178, -9.49788408770561, -5.363335395840165], time: 188.054
mmmaddpg vs mmmaddpg steps: 1449975, episodes: 58000, mean episode reward: 34.67470769851758, agent episode reward: [12.394441164306924, 12.464061454697934, 12.343816948780344, 12.341808503934706, -9.378419271988873, -5.491001101213451], time: 180.814
mmmaddpg vs mmmaddpg steps: 1474975, episodes: 59000, mean episode reward: 35.66317495571051, agent episode reward: [12.689040958552356, 12.732746221152857, 12.627310901647512, 12.50138708348635, -9.107895964513359, -5.779414244615216], time: 180.733
mmmaddpg vs mmmaddpg steps: 1499975, episodes: 60000, mean episode reward: 35.80824645425394, agent episode reward: [12.621226253899739, 12.627893283301535, 12.541231632614439, 12.458362904107664, -8.609783512063947, -5.830684107605492], time: 179.224
mmmaddpg vs mmmaddpg steps: 1524975, episodes: 61000, mean episode reward: 34.97393026261126, agent episode reward: [12.344367881489468, 12.380117537106527, 12.29357454704474, 12.233320687948726, -8.761084560390776, -5.516365830587425], time: 180.406
mmmaddpg vs mmmaddpg steps: 1549975, episodes: 62000, mean episode reward: 34.282042304575505, agent episode reward: [12.176007842404506, 12.21993240085919, 12.109563903049825, 11.990675713645116, -8.437710452825865, -5.776427102557265], time: 188.353
mmmaddpg vs mmmaddpg steps: 1574975, episodes: 63000, mean episode reward: 31.66868899344433, agent episode reward: [11.141319855689424, 11.19102865724771, 11.08749106145763, 10.965346970144871, -8.137634131102683, -4.5788634199926195], time: 183.256
mmmaddpg vs mmmaddpg steps: 1599975, episodes: 64000, mean episode reward: 32.14110322184953, agent episode reward: [11.291218482846347, 11.354138828004302, 11.300955706264233, 11.179879417896732, -8.269096843420149, -4.715992369741946], time: 181.979
mmmaddpg vs mmmaddpg steps: 1624975, episodes: 65000, mean episode reward: 30.884479597835266, agent episode reward: [10.98113746626478, 11.042032517804062, 11.006048096815425, 10.86671837573282, -8.474895331229131, -4.5365615275526885], time: 182.585
mmmaddpg vs mmmaddpg steps: 1649975, episodes: 66000, mean episode reward: 32.83056512994642, agent episode reward: [11.42471227719274, 11.545871779886696, 11.489668579108908, 11.330224056855421, -8.510740117558134, -4.449171445539211], time: 182.32
mmmaddpg vs mmmaddpg steps: 1674975, episodes: 67000, mean episode reward: 29.983837430663588, agent episode reward: [10.57078352983488, 10.576480253087906, 10.606105010065038, 10.412444233541832, -8.121340142088155, -4.060635453777918], time: 189.943
mmmaddpg vs mmmaddpg steps: 1699975, episodes: 68000, mean episode reward: 30.604764890266438, agent episode reward: [10.807756302521891, 10.882027004913226, 10.843162537267677, 10.674823681515365, -8.286283639344923, -4.3167209966068025], time: 181.366
mmmaddpg vs mmmaddpg steps: 1724975, episodes: 69000, mean episode reward: 31.165536670783982, agent episode reward: [10.83997138122113, 10.91041036504744, 10.886143766740654, 10.65547586936387, -8.056014250023292, -4.070450461565823], time: 183.126
mmmaddpg vs mmmaddpg steps: 1749975, episodes: 70000, mean episode reward: 29.35079111159774, agent episode reward: [10.315038143368255, 10.35806918533898, 10.316936612348435, 10.128197159851236, -8.178270383626886, -3.5891796056822804], time: 179.39
mmmaddpg vs mmmaddpg steps: 1774975, episodes: 71000, mean episode reward: 30.40825050713816, agent episode reward: [10.718154869188922, 10.762558210643219, 10.728555422614114, 10.499851078853784, -8.238614349434934, -4.062254724726948], time: 184.465
mmmaddpg vs mmmaddpg steps: 1799975, episodes: 72000, mean episode reward: 32.134168992834155, agent episode reward: [11.179688593990377, 11.21509510816761, 11.179389488646637, 10.983079684031292, -7.954668728303549, -4.4684151536982135], time: 179.788
mmmaddpg vs mmmaddpg steps: 1824975, episodes: 73000, mean episode reward: 29.70275712562149, agent episode reward: [10.559143873683388, 10.555874798513317, 10.505469823624193, 10.286243364810419, -7.777360092800551, -4.426614642209279], time: 187.218
mmmaddpg vs mmmaddpg steps: 1849975, episodes: 74000, mean episode reward: 30.56881800249235, agent episode reward: [10.751094695341587, 10.76808920171795, 10.689026359192031, 10.502516786466066, -7.760734179391769, -4.381174860833513], time: 181.601
mmmaddpg vs mmmaddpg steps: 1874975, episodes: 75000, mean episode reward: 31.407380724608817, agent episode reward: [10.982556896086141, 10.969936702118977, 10.91777525667646, 10.700937612883537, -7.988674324460206, -4.175151418696094], time: 188.706
mmmaddpg vs mmmaddpg steps: 1899975, episodes: 76000, mean episode reward: 30.063116562559824, agent episode reward: [10.568526699783403, 10.549239027412902, 10.494568984246845, 10.29318244575016, -7.570789802656177, -4.2716107919773165], time: 186.818
mmmaddpg vs mmmaddpg steps: 1924975, episodes: 77000, mean episode reward: 31.00238997184182, agent episode reward: [10.826974314539822, 10.847122998640241, 10.77701561500169, 10.521307587263232, -7.955660406435522, -4.0143701371676475], time: 186.272
mmmaddpg vs mmmaddpg steps: 1949975, episodes: 78000, mean episode reward: 31.43952874563792, agent episode reward: [10.945665053526358, 10.840137906054784, 10.811533409188646, 10.6558163201668, -8.170503409974852, -3.6431205333238186], time: 186.877
mmmaddpg vs mmmaddpg steps: 1974975, episodes: 79000, mean episode reward: 29.342941098247653, agent episode reward: [10.317123163055086, 10.241038801343333, 10.256599362188345, 10.102237356750349, -8.03066375884168, -3.5433938262477764], time: 190.838
mmmaddpg vs mmmaddpg steps: 1999975, episodes: 80000, mean episode reward: 29.58066482742203, agent episode reward: [10.31222082995607, 10.279168018203928, 10.234530318579957, 10.096815542891404, -7.943688035543998, -3.3983818466653286], time: 182.17
mmmaddpg vs mmmaddpg steps: 2024975, episodes: 81000, mean episode reward: 30.24710758309208, agent episode reward: [10.708996330129402, 10.617651931060749, 10.585118478196419, 10.484588534395384, -8.092315129157079, -4.056932561532792], time: 190.187
mmmaddpg vs mmmaddpg steps: 2049975, episodes: 82000, mean episode reward: 30.25413073533558, agent episode reward: [10.761989373771426, 10.630622728210314, 10.68079783269484, 10.40880951340596, -8.007979638991715, -4.220109073755246], time: 188.732
mmmaddpg vs mmmaddpg steps: 2074975, episodes: 83000, mean episode reward: 28.794634538327994, agent episode reward: [10.094769560539607, 9.94305156880138, 9.996393635495147, 9.800664877807819, -7.700997635543375, -3.3392474687725886], time: 184.408
mmmaddpg vs mmmaddpg steps: 2099975, episodes: 84000, mean episode reward: 29.84243339554677, agent episode reward: [10.802395687112012, 10.623675185112374, 10.693123314102992, 10.550281545326339, -8.292225926900615, -4.534816409206334], time: 180.406
mmmaddpg vs mmmaddpg steps: 2124975, episodes: 85000, mean episode reward: 28.039885021145345, agent episode reward: [10.069508709124856, 9.896110078955644, 9.972254666293306, 9.743960458262604, -8.32322033306623, -3.318728558424834], time: 189.678
mmmaddpg vs mmmaddpg steps: 2149975, episodes: 86000, mean episode reward: 26.74326955394187, agent episode reward: [9.672710656019085, 9.546823810256887, 9.617376563619143, 9.361238326847428, -7.916830535629206, -3.538049267171461], time: 188.055
mmmaddpg vs mmmaddpg steps: 2174975, episodes: 87000, mean episode reward: 25.663595088096066, agent episode reward: [9.203168826494569, 9.101563004816443, 9.11510562145432, 8.93236323828025, -7.359531099720995, -3.329074503228519], time: 183.886
mmmaddpg vs mmmaddpg steps: 2199975, episodes: 88000, mean episode reward: 28.32479451841023, agent episode reward: [10.154515651579219, 10.02967642200062, 10.10266186277819, 9.841457778885125, -8.36868513054523, -3.4348320662876977], time: 190.066
mmmaddpg vs mmmaddpg steps: 2224975, episodes: 89000, mean episode reward: 25.766968234495764, agent episode reward: [9.251070930365252, 9.077638474031566, 9.222828245817409, 8.955226546396585, -7.363471554929485, -3.3763244071855647], time: 182.062
mmmaddpg vs mmmaddpg steps: 2249975, episodes: 90000, mean episode reward: 27.748843373041236, agent episode reward: [9.910923222921804, 9.778435675785195, 9.821589433199577, 9.656429493759157, -7.373874355824313, -4.044660096800183], time: 180.372
mmmaddpg vs mmmaddpg steps: 2274975, episodes: 91000, mean episode reward: 28.8371019827538, agent episode reward: [10.356131092994769, 10.188914720727464, 10.261608540827446, 10.070887441971463, -7.883530159290109, -4.156909654477235], time: 185.469
mmmaddpg vs mmmaddpg steps: 2299975, episodes: 92000, mean episode reward: 25.893393270671957, agent episode reward: [9.494528812357967, 9.328840659863546, 9.386530167958325, 9.22051027412306, -7.912094951239158, -3.624921692391778], time: 184.942
mmmaddpg vs mmmaddpg steps: 2324975, episodes: 93000, mean episode reward: 28.987086671858325, agent episode reward: [10.316164478800312, 10.12831061959505, 10.15686932879743, 10.055749327803309, -7.97234486735887, -3.697662215778907], time: 185.069
mmmaddpg vs mmmaddpg steps: 2349975, episodes: 94000, mean episode reward: 27.953568637098943, agent episode reward: [10.046078090470234, 9.909688472269899, 9.945596710684338, 9.79870699675368, -8.22460027013424, -3.5219013629449663], time: 183.398
mmmaddpg vs mmmaddpg steps: 2374975, episodes: 95000, mean episode reward: 26.814975464298957, agent episode reward: [9.697346951216932, 9.588393535521933, 9.608876354773418, 9.473904020812023, -7.809044093244922, -3.744501304780426], time: 188.582
mmmaddpg vs mmmaddpg steps: 2399975, episodes: 96000, mean episode reward: 26.00776540241502, agent episode reward: [9.357404275790136, 9.195987934644332, 9.156141559236275, 9.095486660856263, -7.338958165961824, -3.4582968621501595], time: 186.959
mmmaddpg vs mmmaddpg steps: 2424975, episodes: 97000, mean episode reward: 27.3739966803347, agent episode reward: [9.855135271605873, 9.678825846066488, 9.664662779120409, 9.654734431476486, -8.047545484496675, -3.431816163437879], time: 188.204
mmmaddpg vs mmmaddpg steps: 2449975, episodes: 98000, mean episode reward: 24.408835109510058, agent episode reward: [8.885582206588065, 8.650271638971706, 8.614352741675757, 8.597735906813814, -7.247288540787169, -3.091818843752113], time: 192.089
mmmaddpg vs mmmaddpg steps: 2474975, episodes: 99000, mean episode reward: 24.56561484256881, agent episode reward: [9.088668228999506, 8.87778564360054, 8.837581382061082, 8.84146088641677, -7.853577573547015, -3.226303724962073], time: 190.21
mmmaddpg vs mmmaddpg steps: 2499975, episodes: 100000, mean episode reward: 27.33888268604825, agent episode reward: [9.906182422951074, 9.676846338693831, 9.575250840576595, 9.712053711457632, -7.717089506688939, -3.8143611209419452], time: 190.783
...Finished total of 100001 episodes.
