0 bad agents
      adv rate for q_index :  0 [1e-05, 0.001, 0.001]
      adv rate for p_index :  0 [1e-05, 0.001, 0.001]
1 good agents
      adv rate for q_index :  1 [0.001, 1e-05, 1e-05]
      adv rate for p_index :  1 [0.001, 1e-05, 1e-05]
2 good agents
      adv rate for q_index :  2 [0.001, 1e-05, 1e-05]
      adv rate for p_index :  2 [0.001, 1e-05, 1e-05]
Using good policy mmmaddpg and bad policy mmmaddpg with 1 adversaries
Starting iterations...
mmmaddpg vs mmmaddpg steps: 24975, episodes: 1000, mean episode reward: -23.35917436411591, agent episode reward: [-24.432255518692845, 0.5365405772884663, 0.5365405772884663], time: 44.09
mmmaddpg vs mmmaddpg steps: 49975, episodes: 2000, mean episode reward: -12.839466786268808, agent episode reward: [-16.5550080719067, 1.857770642818944, 1.857770642818944], time: 68.307
mmmaddpg vs mmmaddpg steps: 74975, episodes: 3000, mean episode reward: 9.8482090204078, agent episode reward: [-17.62002847310103, 13.734118746754415, 13.734118746754415], time: 70.353
mmmaddpg vs mmmaddpg steps: 99975, episodes: 4000, mean episode reward: 14.949219204277364, agent episode reward: [-16.814578250085038, 15.8818987271812, 15.8818987271812], time: 70.147
mmmaddpg vs mmmaddpg steps: 124975, episodes: 5000, mean episode reward: 14.996540315610003, agent episode reward: [-16.587283713928137, 15.79191201476907, 15.79191201476907], time: 69.113
mmmaddpg vs mmmaddpg steps: 149975, episodes: 6000, mean episode reward: 15.33907262229301, agent episode reward: [-16.82671013522197, 16.082891378757488, 16.082891378757488], time: 70.458
mmmaddpg vs mmmaddpg steps: 174975, episodes: 7000, mean episode reward: 15.259652559834475, agent episode reward: [-16.748277380614425, 16.003964970224448, 16.003964970224448], time: 70.283
mmmaddpg vs mmmaddpg steps: 199975, episodes: 8000, mean episode reward: 15.438393712242195, agent episode reward: [-16.86896761868859, 16.15368066546539, 16.15368066546539], time: 69.72
mmmaddpg vs mmmaddpg steps: 224975, episodes: 9000, mean episode reward: 15.360221749790238, agent episode reward: [-16.83189200843432, 16.09605687911228, 16.09605687911228], time: 70.45
mmmaddpg vs mmmaddpg steps: 249975, episodes: 10000, mean episode reward: 15.173560858942635, agent episode reward: [-16.62766204513194, 15.90061145203729, 15.90061145203729], time: 70.3
mmmaddpg vs mmmaddpg steps: 274975, episodes: 11000, mean episode reward: 15.12388328673919, agent episode reward: [-16.642081231351813, 15.882982259045502, 15.882982259045502], time: 69.656
mmmaddpg vs mmmaddpg steps: 299975, episodes: 12000, mean episode reward: 15.486021097883254, agent episode reward: [-16.938845830469305, 16.21243346417628, 16.21243346417628], time: 70.246
mmmaddpg vs mmmaddpg steps: 324975, episodes: 13000, mean episode reward: 15.176585280876905, agent episode reward: [-16.685029957438804, 15.930807619157855, 15.930807619157855], time: 70.856
mmmaddpg vs mmmaddpg steps: 349975, episodes: 14000, mean episode reward: 15.178229581540963, agent episode reward: [-16.701578825127218, 15.939904203334088, 15.939904203334088], time: 70.248
mmmaddpg vs mmmaddpg steps: 374975, episodes: 15000, mean episode reward: 15.450643787046356, agent episode reward: [-16.85470158541263, 16.152672686229494, 16.152672686229494], time: 69.057
mmmaddpg vs mmmaddpg steps: 399975, episodes: 16000, mean episode reward: 15.23628763146859, agent episode reward: [-16.76921535709626, 16.002751494282425, 16.002751494282425], time: 69.515
mmmaddpg vs mmmaddpg steps: 424975, episodes: 17000, mean episode reward: 15.203669223822418, agent episode reward: [-16.676542360442728, 15.940105792132574, 15.940105792132574], time: 71.164
mmmaddpg vs mmmaddpg steps: 449975, episodes: 18000, mean episode reward: 15.319972004625194, agent episode reward: [-16.79000477973237, 16.054988392178785, 16.054988392178785], time: 70.374
mmmaddpg vs mmmaddpg steps: 474975, episodes: 19000, mean episode reward: 15.200660255972098, agent episode reward: [-16.633056573265996, 15.916858414619048, 15.916858414619048], time: 70.504
mmmaddpg vs mmmaddpg steps: 499975, episodes: 20000, mean episode reward: 15.313750310046746, agent episode reward: [-16.80022645193812, 16.056988380992433, 16.056988380992433], time: 69.978
mmmaddpg vs mmmaddpg steps: 524975, episodes: 21000, mean episode reward: 15.232940300318436, agent episode reward: [-16.639169880804182, 15.93605509056131, 15.93605509056131], time: 69.563
mmmaddpg vs mmmaddpg steps: 549975, episodes: 22000, mean episode reward: 15.042876599189116, agent episode reward: [-16.512766462426885, 15.777821530808, 15.777821530808], time: 70.968
mmmaddpg vs mmmaddpg steps: 574975, episodes: 23000, mean episode reward: 15.319282371663, agent episode reward: [-16.731934493982816, 16.025608432822906, 16.025608432822906], time: 68.736
mmmaddpg vs mmmaddpg steps: 599975, episodes: 24000, mean episode reward: 15.351054796721142, agent episode reward: [-16.776741439981468, 16.063898118351304, 16.063898118351304], time: 69.96
mmmaddpg vs mmmaddpg steps: 624975, episodes: 25000, mean episode reward: 15.226625994768598, agent episode reward: [-16.662811002691882, 15.94471849873024, 15.94471849873024], time: 70.843
mmmaddpg vs mmmaddpg steps: 649975, episodes: 26000, mean episode reward: 15.326734930713599, agent episode reward: [-16.86370212668546, 16.09521852869953, 16.09521852869953], time: 69.676
mmmaddpg vs mmmaddpg steps: 674975, episodes: 27000, mean episode reward: 15.34366416236472, agent episode reward: [-16.759031076742286, 16.051347619553503, 16.051347619553503], time: 70.238
mmmaddpg vs mmmaddpg steps: 699975, episodes: 28000, mean episode reward: 15.49637514333291, agent episode reward: [-16.912457247708957, 16.204416195520935, 16.204416195520935], time: 69.292
mmmaddpg vs mmmaddpg steps: 724975, episodes: 29000, mean episode reward: 15.32281954753468, agent episode reward: [-16.827127878208476, 16.07497371287158, 16.07497371287158], time: 69.402
mmmaddpg vs mmmaddpg steps: 749975, episodes: 30000, mean episode reward: 15.068305233697938, agent episode reward: [-16.48152909733423, 15.774917165516086, 15.774917165516086], time: 68.163
mmmaddpg vs mmmaddpg steps: 774975, episodes: 31000, mean episode reward: 15.186886389345336, agent episode reward: [-16.627265811083316, 15.907076100214326, 15.907076100214326], time: 68.779
mmmaddpg vs mmmaddpg steps: 799975, episodes: 32000, mean episode reward: 15.289419777359988, agent episode reward: [-16.751671744973223, 16.02054576116661, 16.02054576116661], time: 67.901
mmmaddpg vs mmmaddpg steps: 824975, episodes: 33000, mean episode reward: 15.094634234065404, agent episode reward: [-16.5766611569543, 15.835647695509852, 15.835647695509852], time: 68.752
mmmaddpg vs mmmaddpg steps: 849975, episodes: 34000, mean episode reward: 15.222513942349263, agent episode reward: [-16.66380234647667, 15.943158144412962, 15.943158144412962], time: 68.915
mmmaddpg vs mmmaddpg steps: 874975, episodes: 35000, mean episode reward: 15.365694488963472, agent episode reward: [-16.776152175830706, 16.07092333239709, 16.07092333239709], time: 69.943
mmmaddpg vs mmmaddpg steps: 899975, episodes: 36000, mean episode reward: 15.25363153893144, agent episode reward: [-16.669842027913656, 15.961736783422552, 15.961736783422552], time: 68.45
mmmaddpg vs mmmaddpg steps: 924975, episodes: 37000, mean episode reward: 15.175802476476306, agent episode reward: [-16.586440275404854, 15.881121375940582, 15.881121375940582], time: 70.294
mmmaddpg vs mmmaddpg steps: 949975, episodes: 38000, mean episode reward: 15.23432402605171, agent episode reward: [-16.66654603759147, 15.950435031821588, 15.950435031821588], time: 68.566
mmmaddpg vs mmmaddpg steps: 974975, episodes: 39000, mean episode reward: 15.332909705012357, agent episode reward: [-16.75636620763287, 16.044637956322614, 16.044637956322614], time: 67.691
mmmaddpg vs mmmaddpg steps: 999975, episodes: 40000, mean episode reward: 15.225495358109963, agent episode reward: [-16.702713984706325, 15.964104671408146, 15.964104671408146], time: 67.848
mmmaddpg vs mmmaddpg steps: 1024975, episodes: 41000, mean episode reward: 15.203850704075677, agent episode reward: [-16.652258982930945, 15.928054843503313, 15.928054843503313], time: 69.434
mmmaddpg vs mmmaddpg steps: 1049975, episodes: 42000, mean episode reward: 14.988069701573753, agent episode reward: [-16.453179459056837, 15.720624580315295, 15.720624580315295], time: 68.849
mmmaddpg vs mmmaddpg steps: 1074975, episodes: 43000, mean episode reward: 13.961793538800157, agent episode reward: [-17.211617976795054, 15.586705757797604, 15.586705757797604], time: 69.456
mmmaddpg vs mmmaddpg steps: 1099975, episodes: 44000, mean episode reward: 11.113653252288836, agent episode reward: [-13.687955917662475, 12.400804584975655, 12.400804584975655], time: 68.279
mmmaddpg vs mmmaddpg steps: 1124975, episodes: 45000, mean episode reward: 7.780801075176373, agent episode reward: [-18.914856734257775, 13.347828904717074, 13.347828904717074], time: 67.975
mmmaddpg vs mmmaddpg steps: 1149975, episodes: 46000, mean episode reward: 15.204516644482904, agent episode reward: [-16.65286273645606, 15.928689690469483, 15.928689690469483], time: 69.213
mmmaddpg vs mmmaddpg steps: 1174975, episodes: 47000, mean episode reward: 0.02750329899324197, agent episode reward: [-20.87586607813293, 10.451684688563086, 10.451684688563086], time: 68.253
mmmaddpg vs mmmaddpg steps: 1199975, episodes: 48000, mean episode reward: 13.379948320926088, agent episode reward: [-16.49679189779801, 14.938370109362047, 14.938370109362047], time: 68.996
mmmaddpg vs mmmaddpg steps: 1224975, episodes: 49000, mean episode reward: 14.55039887627578, agent episode reward: [-16.06943986747373, 15.309919371874754, 15.309919371874754], time: 69.198
mmmaddpg vs mmmaddpg steps: 1249975, episodes: 50000, mean episode reward: 15.196278370575447, agent episode reward: [-16.637621781656783, 15.916950076116116, 15.916950076116116], time: 68.819
mmmaddpg vs mmmaddpg steps: 1274975, episodes: 51000, mean episode reward: 14.92985401763492, agent episode reward: [-17.171867435362387, 16.05086072649865, 16.05086072649865], time: 69.829
mmmaddpg vs mmmaddpg steps: 1299975, episodes: 52000, mean episode reward: 9.94052670953377, agent episode reward: [-19.083279749496683, 14.511903229515227, 14.511903229515227], time: 68.992
mmmaddpg vs mmmaddpg steps: 1324975, episodes: 53000, mean episode reward: 12.56829944425817, agent episode reward: [-15.63573339856438, 14.102016421411276, 14.102016421411276], time: 68.983
mmmaddpg vs mmmaddpg steps: 1349975, episodes: 54000, mean episode reward: 15.337531305779118, agent episode reward: [-16.78750747774883, 16.062519391763974, 16.062519391763974], time: 69.668
mmmaddpg vs mmmaddpg steps: 1374975, episodes: 55000, mean episode reward: 16.681871283486966, agent episode reward: [-18.760385921448663, 17.72112860246781, 17.72112860246781], time: 69.903
mmmaddpg vs mmmaddpg steps: 1399975, episodes: 56000, mean episode reward: 16.346122923325588, agent episode reward: [-18.076178688038656, 17.211150805682127, 17.211150805682127], time: 69.934
mmmaddpg vs mmmaddpg steps: 1424975, episodes: 57000, mean episode reward: 14.842207497409607, agent episode reward: [-16.364626200313666, 15.603416848861638, 15.603416848861638], time: 68.969
mmmaddpg vs mmmaddpg steps: 1449975, episodes: 58000, mean episode reward: 4.637860764165817, agent episode reward: [-22.91762229692666, 13.777741530546239, 13.777741530546239], time: 67.855
mmmaddpg vs mmmaddpg steps: 1474975, episodes: 59000, mean episode reward: 16.074944741626393, agent episode reward: [-21.635517568436338, 18.855231155031365, 18.855231155031365], time: 68.76
mmmaddpg vs mmmaddpg steps: 1499975, episodes: 60000, mean episode reward: 14.864317448776383, agent episode reward: [-17.282072483402526, 16.073194966089456, 16.073194966089456], time: 68.267
mmmaddpg vs mmmaddpg steps: 1524975, episodes: 61000, mean episode reward: 16.075972326976387, agent episode reward: [-18.04754871122593, 17.06176051910116, 17.06176051910116], time: 67.707
mmmaddpg vs mmmaddpg steps: 1549975, episodes: 62000, mean episode reward: 15.827093605432736, agent episode reward: [-17.71371361031641, 16.770403607874574, 16.770403607874574], time: 68.123
mmmaddpg vs mmmaddpg steps: 1574975, episodes: 63000, mean episode reward: 14.627956196209801, agent episode reward: [-16.685429143419032, 15.656692669814415, 15.656692669814415], time: 69.997
mmmaddpg vs mmmaddpg steps: 1599975, episodes: 64000, mean episode reward: 15.08783680819035, agent episode reward: [-16.672257892669734, 15.880047350430043, 15.880047350430043], time: 69.03
mmmaddpg vs mmmaddpg steps: 1624975, episodes: 65000, mean episode reward: 15.768452133986415, agent episode reward: [-17.419876085506637, 16.594164109746526, 16.594164109746526], time: 68.63
mmmaddpg vs mmmaddpg steps: 1649975, episodes: 66000, mean episode reward: 14.937308800509559, agent episode reward: [-16.505343583349717, 15.72132619192964, 15.72132619192964], time: 68.999
mmmaddpg vs mmmaddpg steps: 1674975, episodes: 67000, mean episode reward: 15.191740920287506, agent episode reward: [-16.61962902842441, 15.905684974355962, 15.905684974355962], time: 69.012
mmmaddpg vs mmmaddpg steps: 1699975, episodes: 68000, mean episode reward: 15.048664104657869, agent episode reward: [-17.317245014822067, 16.182954559739965, 16.182954559739965], time: 69.78
mmmaddpg vs mmmaddpg steps: 1724975, episodes: 69000, mean episode reward: 13.62551971023281, agent episode reward: [-16.9003845078311, 15.262952109031955, 15.262952109031955], time: 68.674
mmmaddpg vs mmmaddpg steps: 1749975, episodes: 70000, mean episode reward: 14.295765938278938, agent episode reward: [-16.863664528178656, 15.579715233228796, 15.579715233228796], time: 68.43
mmmaddpg vs mmmaddpg steps: 1774975, episodes: 71000, mean episode reward: 14.690588812014482, agent episode reward: [-16.26684751733353, 15.478718164674008, 15.478718164674008], time: 68.818
mmmaddpg vs mmmaddpg steps: 1799975, episodes: 72000, mean episode reward: 15.162761361182657, agent episode reward: [-16.606030105344388, 15.884395733263522, 15.884395733263522], time: 68.485
mmmaddpg vs mmmaddpg steps: 1824975, episodes: 73000, mean episode reward: 15.241318927206049, agent episode reward: [-16.929703314316182, 16.08551112076112, 16.08551112076112], time: 67.285
mmmaddpg vs mmmaddpg steps: 1849975, episodes: 74000, mean episode reward: 15.504440940439519, agent episode reward: [-17.032081711403443, 16.268261325921483, 16.268261325921483], time: 67.479
mmmaddpg vs mmmaddpg steps: 1874975, episodes: 75000, mean episode reward: 15.17722816219218, agent episode reward: [-16.711631477221584, 15.94442981970688, 15.94442981970688], time: 67.548
mmmaddpg vs mmmaddpg steps: 1899975, episodes: 76000, mean episode reward: 15.236239963004426, agent episode reward: [-16.733931829786265, 15.985085896395345, 15.985085896395345], time: 68.303
mmmaddpg vs mmmaddpg steps: 1924975, episodes: 77000, mean episode reward: 15.28523189013873, agent episode reward: [-16.746801676226198, 16.01601678318246, 16.01601678318246], time: 67.68
mmmaddpg vs mmmaddpg steps: 1949975, episodes: 78000, mean episode reward: 15.089924922487914, agent episode reward: [-16.63502197749956, 15.862473449993736, 15.862473449993736], time: 68.993
mmmaddpg vs mmmaddpg steps: 1974975, episodes: 79000, mean episode reward: 15.140838649259706, agent episode reward: [-16.579732354861118, 15.86028550206041, 15.86028550206041], time: 68.668
mmmaddpg vs mmmaddpg steps: 1999975, episodes: 80000, mean episode reward: 6.046445195908753, agent episode reward: [-14.415954395909816, 10.231199795909284, 10.231199795909284], time: 67.736
mmmaddpg vs mmmaddpg steps: 2024975, episodes: 81000, mean episode reward: 17.774083218360733, agent episode reward: [-21.14596933484936, 19.460026276605042, 19.460026276605042], time: 67.938
mmmaddpg vs mmmaddpg steps: 2049975, episodes: 82000, mean episode reward: 18.891737017281585, agent episode reward: [-22.92297940629075, 20.907358211786168, 20.907358211786168], time: 68.356
mmmaddpg vs mmmaddpg steps: 2074975, episodes: 83000, mean episode reward: 16.04482954628944, agent episode reward: [-23.103238910708136, 19.57403422849879, 19.57403422849879], time: 69.354
mmmaddpg vs mmmaddpg steps: 2099975, episodes: 84000, mean episode reward: 18.830306004824706, agent episode reward: [-22.549356328662398, 20.689831166743556, 20.689831166743556], time: 68.807
mmmaddpg vs mmmaddpg steps: 2124975, episodes: 85000, mean episode reward: 18.274879992538406, agent episode reward: [-21.26416763574192, 19.769523814140165, 19.769523814140165], time: 67.197
mmmaddpg vs mmmaddpg steps: 2149975, episodes: 86000, mean episode reward: 6.989456507030571, agent episode reward: [-25.745820720656038, 16.367638613843305, 16.367638613843305], time: 67.536
mmmaddpg vs mmmaddpg steps: 2174975, episodes: 87000, mean episode reward: 14.297571762241539, agent episode reward: [-20.49310261543001, 17.395337188835775, 17.395337188835775], time: 69.023
mmmaddpg vs mmmaddpg steps: 2199975, episodes: 88000, mean episode reward: 17.744708571909346, agent episode reward: [-21.54452607777389, 19.644617324841615, 19.644617324841615], time: 69.28
mmmaddpg vs mmmaddpg steps: 2224975, episodes: 89000, mean episode reward: 17.3009926036662, agent episode reward: [-21.06208380614229, 19.181538204904246, 19.181538204904246], time: 68.945
mmmaddpg vs mmmaddpg steps: 2249975, episodes: 90000, mean episode reward: 15.640867621649202, agent episode reward: [-20.372116875703437, 18.006492248676317, 18.006492248676317], time: 69.447
mmmaddpg vs mmmaddpg steps: 2274975, episodes: 91000, mean episode reward: 16.14329131544281, agent episode reward: [-19.792557400886675, 17.967924358164744, 17.967924358164744], time: 67.886
mmmaddpg vs mmmaddpg steps: 2299975, episodes: 92000, mean episode reward: 19.218833917264643, agent episode reward: [-21.428430859562702, 20.323632388413674, 20.323632388413674], time: 68.224
mmmaddpg vs mmmaddpg steps: 2324975, episodes: 93000, mean episode reward: 17.96322570671139, agent episode reward: [-19.70412883930879, 18.83367727301009, 18.83367727301009], time: 70.037
mmmaddpg vs mmmaddpg steps: 2349975, episodes: 94000, mean episode reward: 17.605354171788605, agent episode reward: [-19.745801665167157, 18.67557791847788, 18.67557791847788], time: 68.615
mmmaddpg vs mmmaddpg steps: 2374975, episodes: 95000, mean episode reward: 15.475637202333441, agent episode reward: [-17.96208207057171, 16.718859636452574, 16.718859636452574], time: 69.77
mmmaddpg vs mmmaddpg steps: 2399975, episodes: 96000, mean episode reward: 14.667301009289032, agent episode reward: [-16.993436902776214, 15.830368956032624, 15.830368956032624], time: 68.606
mmmaddpg vs mmmaddpg steps: 2424975, episodes: 97000, mean episode reward: 17.55899269625084, agent episode reward: [-20.119436354913297, 18.83921452558207, 18.83921452558207], time: 69.416
mmmaddpg vs mmmaddpg steps: 2449975, episodes: 98000, mean episode reward: 18.96638632904096, agent episode reward: [-21.45871224448824, 20.212549286764602, 20.212549286764602], time: 67.996
mmmaddpg vs mmmaddpg steps: 2474975, episodes: 99000, mean episode reward: 20.007778547626984, agent episode reward: [-22.522195651010513, 21.26498709931875, 21.26498709931875], time: 67.828
mmmaddpg vs mmmaddpg steps: 2499975, episodes: 100000, mean episode reward: 17.45262249880362, agent episode reward: [-19.28232755044063, 18.367475024622127, 18.367475024622127], time: 68.16
...Finished total of 100001 episodes.
