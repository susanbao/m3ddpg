0 bad agents
      adv rate for q_index :  0 [1e-05, 0.001, 0.001]
      adv rate for p_index :  0 [1e-05, 0.001, 0.001]
1 good agents
      adv rate for q_index :  1 [0.001, 1e-05, 1e-05]
      adv rate for p_index :  1 [0.001, 1e-05, 1e-05]
2 good agents
      adv rate for q_index :  2 [0.001, 1e-05, 1e-05]
      adv rate for p_index :  2 [0.001, 1e-05, 1e-05]
Using good policy mmmaddpg and bad policy mmmaddpg with 1 adversaries
Starting iterations...
mmmaddpg vs mmmaddpg steps: 24975, episodes: 1000, mean episode reward: -23.06067410280394, agent episode reward: [-44.44412173810186, 10.691723817648963, 10.691723817648963], time: 57.326
mmmaddpg vs mmmaddpg steps: 49975, episodes: 2000, mean episode reward: -17.059719451197953, agent episode reward: [-20.296280687052295, 1.6182806179271687, 1.6182806179271687], time: 122.616
mmmaddpg vs mmmaddpg steps: 74975, episodes: 3000, mean episode reward: 3.545499835745791, agent episode reward: [-9.399157336968553, 6.472328586357173, 6.472328586357173], time: 121.072
mmmaddpg vs mmmaddpg steps: 99975, episodes: 4000, mean episode reward: 2.5641118638421436, agent episode reward: [-8.894988696556497, 5.72955028019932, 5.72955028019932], time: 121.162
mmmaddpg vs mmmaddpg steps: 124975, episodes: 5000, mean episode reward: 2.544625150378484, agent episode reward: [-10.095234244845408, 6.319929697611946, 6.319929697611946], time: 122.291
mmmaddpg vs mmmaddpg steps: 149975, episodes: 6000, mean episode reward: 2.378835703170784, agent episode reward: [-10.149182115196904, 6.264008909183843, 6.264008909183843], time: 118.902
mmmaddpg vs mmmaddpg steps: 174975, episodes: 7000, mean episode reward: 2.3800777366882975, agent episode reward: [-10.873556396504187, 6.626817066596243, 6.626817066596243], time: 120.904
mmmaddpg vs mmmaddpg steps: 199975, episodes: 8000, mean episode reward: 2.688496237397748, agent episode reward: [-10.536709646711639, 6.612602942054693, 6.612602942054693], time: 122.721
mmmaddpg vs mmmaddpg steps: 224975, episodes: 9000, mean episode reward: 2.200413116414701, agent episode reward: [-10.529748264386749, 6.365080690400724, 6.365080690400724], time: 120.539
mmmaddpg vs mmmaddpg steps: 249975, episodes: 10000, mean episode reward: 2.1153638593292112, agent episode reward: [-10.214136200706891, 6.164750030018051, 6.164750030018051], time: 119.222
mmmaddpg vs mmmaddpg steps: 274975, episodes: 11000, mean episode reward: 2.1381862744527096, agent episode reward: [-11.630558621682733, 6.88437244806772, 6.88437244806772], time: 122.193
mmmaddpg vs mmmaddpg steps: 299975, episodes: 12000, mean episode reward: 2.450424551750585, agent episode reward: [-11.627771912277506, 7.039098232014045, 7.039098232014045], time: 121.71
mmmaddpg vs mmmaddpg steps: 324975, episodes: 13000, mean episode reward: 2.6703085648396665, agent episode reward: [-11.471420794859423, 7.070864679849545, 7.070864679849545], time: 121.401
mmmaddpg vs mmmaddpg steps: 349975, episodes: 14000, mean episode reward: 2.8299536296449497, agent episode reward: [-11.615703793836557, 7.222828711740753, 7.222828711740753], time: 119.325
mmmaddpg vs mmmaddpg steps: 374975, episodes: 15000, mean episode reward: 2.962461025407978, agent episode reward: [-11.590809776258897, 7.276635400833437, 7.276635400833437], time: 121.129
mmmaddpg vs mmmaddpg steps: 399975, episodes: 16000, mean episode reward: 2.948206591114592, agent episode reward: [-12.10051643172758, 7.524361511421088, 7.524361511421088], time: 122.049
mmmaddpg vs mmmaddpg steps: 424975, episodes: 17000, mean episode reward: 2.622786665316443, agent episode reward: [-11.681564548852272, 7.152175607084357, 7.152175607084357], time: 122.095
mmmaddpg vs mmmaddpg steps: 449975, episodes: 18000, mean episode reward: 3.404129445816283, agent episode reward: [-11.758486968743405, 7.581308207279844, 7.581308207279844], time: 119.455
mmmaddpg vs mmmaddpg steps: 474975, episodes: 19000, mean episode reward: 2.7999362643984336, agent episode reward: [-11.787763604141517, 7.293849934269975, 7.293849934269975], time: 119.416
mmmaddpg vs mmmaddpg steps: 499975, episodes: 20000, mean episode reward: 2.5692227275077055, agent episode reward: [-11.887641965359405, 7.228432346433555, 7.228432346433555], time: 119.794
mmmaddpg vs mmmaddpg steps: 524975, episodes: 21000, mean episode reward: 2.620275434268533, agent episode reward: [-12.431352116779543, 7.525813775524036, 7.525813775524036], time: 119.615
mmmaddpg vs mmmaddpg steps: 549975, episodes: 22000, mean episode reward: 2.912125020213861, agent episode reward: [-12.62310068296115, 7.767612851587506, 7.767612851587506], time: 120.656
mmmaddpg vs mmmaddpg steps: 574975, episodes: 23000, mean episode reward: 2.031780299056124, agent episode reward: [-12.123605308270049, 7.077692803663086, 7.077692803663086], time: 120.529
mmmaddpg vs mmmaddpg steps: 599975, episodes: 24000, mean episode reward: 2.2351222309393766, agent episode reward: [-12.329020231761085, 7.282071231350232, 7.282071231350232], time: 121.7
mmmaddpg vs mmmaddpg steps: 624975, episodes: 25000, mean episode reward: 2.056477644641157, agent episode reward: [-12.581042788008181, 7.318760216324669, 7.318760216324669], time: 120.525
mmmaddpg vs mmmaddpg steps: 649975, episodes: 26000, mean episode reward: 1.7426319207400596, agent episode reward: [-12.653100394664923, 7.197866157702492, 7.197866157702492], time: 120.0
mmmaddpg vs mmmaddpg steps: 674975, episodes: 27000, mean episode reward: 1.9854121386130466, agent episode reward: [-12.570772071679773, 7.27809210514641, 7.27809210514641], time: 120.616
mmmaddpg vs mmmaddpg steps: 699975, episodes: 28000, mean episode reward: 1.7917687041546178, agent episode reward: [-12.813623321603414, 7.302696012879016, 7.302696012879016], time: 120.09
mmmaddpg vs mmmaddpg steps: 724975, episodes: 29000, mean episode reward: 1.1599668227480497, agent episode reward: [-13.045063635382135, 7.1025152290650935, 7.1025152290650935], time: 121.472
mmmaddpg vs mmmaddpg steps: 749975, episodes: 30000, mean episode reward: 1.5930644563678236, agent episode reward: [-13.606737368706932, 7.599900912537378, 7.599900912537378], time: 120.376
mmmaddpg vs mmmaddpg steps: 774975, episodes: 31000, mean episode reward: 1.0111392166399382, agent episode reward: [-13.608641464002554, 7.309890340321246, 7.309890340321246], time: 121.386
mmmaddpg vs mmmaddpg steps: 799975, episodes: 32000, mean episode reward: 1.5121340203426914, agent episode reward: [-12.842685738125736, 7.177409879234213, 7.177409879234213], time: 121.45
mmmaddpg vs mmmaddpg steps: 824975, episodes: 33000, mean episode reward: 1.1266883568499884, agent episode reward: [-13.364693254406369, 7.245690805628178, 7.245690805628178], time: 121.612
mmmaddpg vs mmmaddpg steps: 849975, episodes: 34000, mean episode reward: 2.1128883985203393, agent episode reward: [-13.369390660470941, 7.74113952949564, 7.74113952949564], time: 122.813
mmmaddpg vs mmmaddpg steps: 874975, episodes: 35000, mean episode reward: 2.311887857738085, agent episode reward: [-13.436301502710739, 7.874094680224412, 7.874094680224412], time: 122.345
mmmaddpg vs mmmaddpg steps: 899975, episodes: 36000, mean episode reward: 2.4537240524510264, agent episode reward: [-12.907073725602588, 7.680398889026806, 7.680398889026806], time: 119.688
mmmaddpg vs mmmaddpg steps: 924975, episodes: 37000, mean episode reward: 2.6920968237938294, agent episode reward: [-13.214749556062117, 7.953423189927975, 7.953423189927975], time: 121.956
mmmaddpg vs mmmaddpg steps: 949975, episodes: 38000, mean episode reward: 2.599027410243116, agent episode reward: [-13.517647933294182, 8.058337671768648, 8.058337671768648], time: 122.66
mmmaddpg vs mmmaddpg steps: 974975, episodes: 39000, mean episode reward: 2.4456545752069485, agent episode reward: [-13.652736082614815, 8.049195328910882, 8.049195328910882], time: 119.001
mmmaddpg vs mmmaddpg steps: 999975, episodes: 40000, mean episode reward: 2.5902371934323694, agent episode reward: [-13.440078089977382, 8.015157641704874, 8.015157641704874], time: 120.299
mmmaddpg vs mmmaddpg steps: 1024975, episodes: 41000, mean episode reward: 2.6420534950289607, agent episode reward: [-13.656752744005608, 8.149403119517283, 8.149403119517283], time: 123.56
mmmaddpg vs mmmaddpg steps: 1049975, episodes: 42000, mean episode reward: 2.512407768366953, agent episode reward: [-13.80903384622804, 8.160720807297496, 8.160720807297496], time: 123.778
mmmaddpg vs mmmaddpg steps: 1074975, episodes: 43000, mean episode reward: 1.901634138031944, agent episode reward: [-13.418668730953044, 7.660151434492494, 7.660151434492494], time: 125.089
mmmaddpg vs mmmaddpg steps: 1099975, episodes: 44000, mean episode reward: 1.5454195392884302, agent episode reward: [-13.410178517770357, 7.477799028529393, 7.477799028529393], time: 122.972
mmmaddpg vs mmmaddpg steps: 1124975, episodes: 45000, mean episode reward: 2.079860082670334, agent episode reward: [-13.61030398804845, 7.845082035359392, 7.845082035359392], time: 123.195
mmmaddpg vs mmmaddpg steps: 1149975, episodes: 46000, mean episode reward: 2.513345852211951, agent episode reward: [-14.26971616540144, 8.391531008806696, 8.391531008806696], time: 122.63
mmmaddpg vs mmmaddpg steps: 1174975, episodes: 47000, mean episode reward: 2.3863533204660485, agent episode reward: [-14.367213843255348, 8.376783581860698, 8.376783581860698], time: 124.036
mmmaddpg vs mmmaddpg steps: 1199975, episodes: 48000, mean episode reward: 2.6846548125342666, agent episode reward: [-13.386604230528866, 8.035629521531567, 8.035629521531567], time: 124.13
mmmaddpg vs mmmaddpg steps: 1224975, episodes: 49000, mean episode reward: 3.217496891440635, agent episode reward: [-13.953162227331209, 8.585329559385922, 8.585329559385922], time: 121.592
mmmaddpg vs mmmaddpg steps: 1249975, episodes: 50000, mean episode reward: 3.598174880781979, agent episode reward: [-13.840984612130223, 8.719579746456102, 8.719579746456102], time: 121.973
mmmaddpg vs mmmaddpg steps: 1274975, episodes: 51000, mean episode reward: 3.8392783582686487, agent episode reward: [-13.64345048909495, 8.7413644236818, 8.7413644236818], time: 124.224
mmmaddpg vs mmmaddpg steps: 1299975, episodes: 52000, mean episode reward: 4.091150231274597, agent episode reward: [-13.039011559968111, 8.565080895621355, 8.565080895621355], time: 124.454
mmmaddpg vs mmmaddpg steps: 1324975, episodes: 53000, mean episode reward: 4.247506746778941, agent episode reward: [-12.994556380737116, 8.621031563758027, 8.621031563758027], time: 121.29
mmmaddpg vs mmmaddpg steps: 1349975, episodes: 54000, mean episode reward: 4.020734058542702, agent episode reward: [-13.324051078709621, 8.672392568626162, 8.672392568626162], time: 121.145
mmmaddpg vs mmmaddpg steps: 1374975, episodes: 55000, mean episode reward: 4.2879709901113126, agent episode reward: [-13.255068767938262, 8.771519879024789, 8.771519879024789], time: 122.416
mmmaddpg vs mmmaddpg steps: 1399975, episodes: 56000, mean episode reward: 3.6605419716857233, agent episode reward: [-13.225181510699105, 8.442861741192413, 8.442861741192413], time: 123.199
mmmaddpg vs mmmaddpg steps: 1424975, episodes: 57000, mean episode reward: 3.3853004453407913, agent episode reward: [-12.652340825324979, 8.018820635332885, 8.018820635332885], time: 122.597
mmmaddpg vs mmmaddpg steps: 1449975, episodes: 58000, mean episode reward: 4.095327255356775, agent episode reward: [-12.945145623424752, 8.520236439390763, 8.520236439390763], time: 122.767
mmmaddpg vs mmmaddpg steps: 1474975, episodes: 59000, mean episode reward: 4.034001343361432, agent episode reward: [-13.067039323633184, 8.550520333497309, 8.550520333497309], time: 123.126
mmmaddpg vs mmmaddpg steps: 1499975, episodes: 60000, mean episode reward: 3.242954583607251, agent episode reward: [-12.645210591960938, 7.944082587784094, 7.944082587784094], time: 122.009
mmmaddpg vs mmmaddpg steps: 1524975, episodes: 61000, mean episode reward: 3.3729415655702906, agent episode reward: [-13.072439273745362, 8.222690419657825, 8.222690419657825], time: 124.215
mmmaddpg vs mmmaddpg steps: 1549975, episodes: 62000, mean episode reward: 3.594727989426241, agent episode reward: [-13.446072845470058, 8.520400417448151, 8.520400417448151], time: 123.325
mmmaddpg vs mmmaddpg steps: 1574975, episodes: 63000, mean episode reward: 3.0744357758958905, agent episode reward: [-12.432856563993878, 7.7536461699448855, 7.7536461699448855], time: 122.137
mmmaddpg vs mmmaddpg steps: 1599975, episodes: 64000, mean episode reward: 2.377007312374356, agent episode reward: [-12.732056271509762, 7.554531791942058, 7.554531791942058], time: 123.549
mmmaddpg vs mmmaddpg steps: 1624975, episodes: 65000, mean episode reward: 2.609970108902061, agent episode reward: [-13.43080763765655, 8.020388873279305, 8.020388873279305], time: 123.378
mmmaddpg vs mmmaddpg steps: 1649975, episodes: 66000, mean episode reward: 2.839322362449587, agent episode reward: [-12.955976956307932, 7.89764965937876, 7.89764965937876], time: 123.062
mmmaddpg vs mmmaddpg steps: 1674975, episodes: 67000, mean episode reward: 2.5109116294371714, agent episode reward: [-13.345666925124325, 7.928289277280748, 7.928289277280748], time: 122.77
mmmaddpg vs mmmaddpg steps: 1699975, episodes: 68000, mean episode reward: 3.006949216108379, agent episode reward: [-13.253869526252892, 8.130409371180637, 8.130409371180637], time: 120.145
mmmaddpg vs mmmaddpg steps: 1724975, episodes: 69000, mean episode reward: 2.2096234156998924, agent episode reward: [-13.015982834028408, 7.612803124864149, 7.612803124864149], time: 122.086
mmmaddpg vs mmmaddpg steps: 1749975, episodes: 70000, mean episode reward: 2.757123435389561, agent episode reward: [-13.39853440201656, 8.07782891870306, 8.07782891870306], time: 122.065
mmmaddpg vs mmmaddpg steps: 1774975, episodes: 71000, mean episode reward: 3.3104449231878443, agent episode reward: [-13.772112563728264, 8.541278743458053, 8.541278743458053], time: 120.378
mmmaddpg vs mmmaddpg steps: 1799975, episodes: 72000, mean episode reward: 3.1157876998651157, agent episode reward: [-13.208144043732448, 8.161965871798781, 8.161965871798781], time: 120.373
mmmaddpg vs mmmaddpg steps: 1824975, episodes: 73000, mean episode reward: 2.871154981022939, agent episode reward: [-13.886474273789215, 8.378814627406078, 8.378814627406078], time: 121.952
mmmaddpg vs mmmaddpg steps: 1849975, episodes: 74000, mean episode reward: 3.1862331766357843, agent episode reward: [-13.242107589090782, 8.214170382863282, 8.214170382863282], time: 124.041
mmmaddpg vs mmmaddpg steps: 1874975, episodes: 75000, mean episode reward: 3.2416897771305586, agent episode reward: [-13.125416230809241, 8.1835530039699, 8.1835530039699], time: 120.169
mmmaddpg vs mmmaddpg steps: 1899975, episodes: 76000, mean episode reward: 2.935105577373993, agent episode reward: [-13.48543911630972, 8.210272346841856, 8.210272346841856], time: 119.46
mmmaddpg vs mmmaddpg steps: 1924975, episodes: 77000, mean episode reward: 3.7839503600336513, agent episode reward: [-13.064372676864027, 8.42416151844884, 8.42416151844884], time: 124.59
mmmaddpg vs mmmaddpg steps: 1949975, episodes: 78000, mean episode reward: 3.5604019288121127, agent episode reward: [-13.305838408007116, 8.433120168409616, 8.433120168409616], time: 121.451
mmmaddpg vs mmmaddpg steps: 1974975, episodes: 79000, mean episode reward: 3.546729129606718, agent episode reward: [-13.600874552435467, 8.573801841021092, 8.573801841021092], time: 121.015
mmmaddpg vs mmmaddpg steps: 1999975, episodes: 80000, mean episode reward: 3.5774677345060653, agent episode reward: [-13.82555449081616, 8.701511112661112, 8.701511112661112], time: 121.397
mmmaddpg vs mmmaddpg steps: 2024975, episodes: 81000, mean episode reward: 3.673387069310402, agent episode reward: [-13.223798916638767, 8.448592992974586, 8.448592992974586], time: 120.4
mmmaddpg vs mmmaddpg steps: 2049975, episodes: 82000, mean episode reward: 3.3387257348333925, agent episode reward: [-13.234147428956454, 8.286436581894923, 8.286436581894923], time: 120.908
mmmaddpg vs mmmaddpg steps: 2074975, episodes: 83000, mean episode reward: 3.670951678971643, agent episode reward: [-13.205477124154092, 8.438214401562865, 8.438214401562865], time: 121.954
mmmaddpg vs mmmaddpg steps: 2099975, episodes: 84000, mean episode reward: 3.037120647161289, agent episode reward: [-13.680923838741048, 8.359022242951168, 8.359022242951168], time: 120.815
mmmaddpg vs mmmaddpg steps: 2124975, episodes: 85000, mean episode reward: 3.1687431602203153, agent episode reward: [-14.338241635083438, 8.753492397651877, 8.753492397651877], time: 121.824
mmmaddpg vs mmmaddpg steps: 2149975, episodes: 86000, mean episode reward: 2.835918772798325, agent episode reward: [-13.885793229766724, 8.360856001282524, 8.360856001282524], time: 120.639
mmmaddpg vs mmmaddpg steps: 2174975, episodes: 87000, mean episode reward: 2.570715429227893, agent episode reward: [-13.157176004788287, 7.8639457170080895, 7.8639457170080895], time: 120.223
mmmaddpg vs mmmaddpg steps: 2199975, episodes: 88000, mean episode reward: 3.1324593029633925, agent episode reward: [-12.928985966408632, 8.030722634686013, 8.030722634686013], time: 120.308
mmmaddpg vs mmmaddpg steps: 2224975, episodes: 89000, mean episode reward: 2.5835710472510964, agent episode reward: [-13.497028175143992, 8.040299611197545, 8.040299611197545], time: 121.846
mmmaddpg vs mmmaddpg steps: 2249975, episodes: 90000, mean episode reward: 2.85330315269549, agent episode reward: [-13.015687452482144, 7.934495302588817, 7.934495302588817], time: 119.658
mmmaddpg vs mmmaddpg steps: 2274975, episodes: 91000, mean episode reward: 2.5587236742713264, agent episode reward: [-12.638694683858704, 7.598709179065016, 7.598709179065016], time: 122.761
mmmaddpg vs mmmaddpg steps: 2299975, episodes: 92000, mean episode reward: 2.7388881776796015, agent episode reward: [-13.217549969410674, 7.978219073545139, 7.978219073545139], time: 121.359
mmmaddpg vs mmmaddpg steps: 2324975, episodes: 93000, mean episode reward: 2.5541256404915456, agent episode reward: [-13.715590909162005, 8.134858274826774, 8.134858274826774], time: 120.617
mmmaddpg vs mmmaddpg steps: 2349975, episodes: 94000, mean episode reward: 2.415530026358583, agent episode reward: [-13.45231903760029, 7.933924531979436, 7.933924531979436], time: 119.893
mmmaddpg vs mmmaddpg steps: 2374975, episodes: 95000, mean episode reward: 2.2388742028651905, agent episode reward: [-13.276256747206823, 7.757565475036007, 7.757565475036007], time: 121.441
mmmaddpg vs mmmaddpg steps: 2399975, episodes: 96000, mean episode reward: 2.3600563526529768, agent episode reward: [-13.224529142195802, 7.79229274742439, 7.79229274742439], time: 119.986
mmmaddpg vs mmmaddpg steps: 2424975, episodes: 97000, mean episode reward: 1.6604698618713736, agent episode reward: [-13.213569993350712, 7.437019927611042, 7.437019927611042], time: 120.76
mmmaddpg vs mmmaddpg steps: 2449975, episodes: 98000, mean episode reward: 1.910136845680272, agent episode reward: [-13.7217712523697, 7.8159540490249855, 7.8159540490249855], time: 120.07
mmmaddpg vs mmmaddpg steps: 2474975, episodes: 99000, mean episode reward: 2.0410618466829566, agent episode reward: [-13.934301712736127, 7.9876817797095425, 7.9876817797095425], time: 119.714
mmmaddpg vs mmmaddpg steps: 2499975, episodes: 100000, mean episode reward: 1.3168019672034956, agent episode reward: [-13.55193934532389, 7.434370656263693, 7.434370656263693], time: 120.135
...Finished total of 100001 episodes.
