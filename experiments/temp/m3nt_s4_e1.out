0 bad agents
      adv rate for q_index :  0 [1e-05, 0.001, 0.001]
      adv rate for p_index :  0 [1e-05, 0.001, 0.001]
1 good agents
      adv rate for q_index :  1 [0.001, 1e-05, 1e-05]
      adv rate for p_index :  1 [0.001, 1e-05, 1e-05]
2 good agents
      adv rate for q_index :  2 [0.001, 1e-05, 1e-05]
      adv rate for p_index :  2 [0.001, 1e-05, 1e-05]
Using good policy mmmaddpg and bad policy mmmaddpg with 1 adversaries
Starting iterations...
mmmaddpg vs mmmaddpg steps: 24975, episodes: 1000, mean episode reward: -23.423934604262065, agent episode reward: [-41.88814585493757, 9.23210562533775, 9.23210562533775], time: 52.087
mmmaddpg vs mmmaddpg steps: 49975, episodes: 2000, mean episode reward: -28.228766046660912, agent episode reward: [-37.00468606721972, 4.387960010279406, 4.387960010279406], time: 76.0
mmmaddpg vs mmmaddpg steps: 74975, episodes: 3000, mean episode reward: 1.5791017974613082, agent episode reward: [-11.317991066188334, 6.448546431824821, 6.448546431824821], time: 74.57
mmmaddpg vs mmmaddpg steps: 99975, episodes: 4000, mean episode reward: 2.530323348667669, agent episode reward: [-9.891900006797686, 6.211111677732677, 6.211111677732677], time: 76.756
mmmaddpg vs mmmaddpg steps: 124975, episodes: 5000, mean episode reward: 2.486275285096146, agent episode reward: [-9.528964579674723, 6.007619932385435, 6.007619932385435], time: 75.608
mmmaddpg vs mmmaddpg steps: 149975, episodes: 6000, mean episode reward: 1.9063839521742993, agent episode reward: [-9.506773732990322, 5.706578842582308, 5.706578842582308], time: 75.695
mmmaddpg vs mmmaddpg steps: 174975, episodes: 7000, mean episode reward: 1.1970438826074261, agent episode reward: [-8.885601091504133, 5.041322487055781, 5.041322487055781], time: 76.198
mmmaddpg vs mmmaddpg steps: 199975, episodes: 8000, mean episode reward: 0.34423101386617944, agent episode reward: [-9.593292642504148, 4.968761828185163, 4.968761828185163], time: 76.233
mmmaddpg vs mmmaddpg steps: 224975, episodes: 9000, mean episode reward: 0.06908237602248585, agent episode reward: [-10.005685172617758, 5.037383774320122, 5.037383774320122], time: 77.22
mmmaddpg vs mmmaddpg steps: 249975, episodes: 10000, mean episode reward: 0.6368516895735107, agent episode reward: [-9.956349842633212, 5.296600766103361, 5.296600766103361], time: 76.816
mmmaddpg vs mmmaddpg steps: 274975, episodes: 11000, mean episode reward: 0.3722012499495182, agent episode reward: [-10.123629271138187, 5.247915260543852, 5.247915260543852], time: 76.44
mmmaddpg vs mmmaddpg steps: 299975, episodes: 12000, mean episode reward: 0.09864142532976954, agent episode reward: [-10.589516263233543, 5.344078844281656, 5.344078844281656], time: 74.811
mmmaddpg vs mmmaddpg steps: 324975, episodes: 13000, mean episode reward: -0.25769387550160816, agent episode reward: [-10.70159299175251, 5.22194955812545, 5.22194955812545], time: 76.261
mmmaddpg vs mmmaddpg steps: 349975, episodes: 14000, mean episode reward: -0.1687838817173745, agent episode reward: [-10.57696871641902, 5.204092417350822, 5.204092417350822], time: 76.039
mmmaddpg vs mmmaddpg steps: 374975, episodes: 15000, mean episode reward: -0.4398636215859151, agent episode reward: [-11.500704640862253, 5.53042050963817, 5.53042050963817], time: 76.131
mmmaddpg vs mmmaddpg steps: 399975, episodes: 16000, mean episode reward: -1.0570166604867317, agent episode reward: [-11.811263126235541, 5.377123232874405, 5.377123232874405], time: 76.055
mmmaddpg vs mmmaddpg steps: 424975, episodes: 17000, mean episode reward: -1.2276940046147442, agent episode reward: [-11.988144581144974, 5.380225288265113, 5.380225288265113], time: 76.904
mmmaddpg vs mmmaddpg steps: 449975, episodes: 18000, mean episode reward: -0.5915306547599973, agent episode reward: [-12.652409007198273, 6.030439176219137, 6.030439176219137], time: 75.871
mmmaddpg vs mmmaddpg steps: 474975, episodes: 19000, mean episode reward: -1.211947695272036, agent episode reward: [-13.020167135707094, 5.904109720217528, 5.904109720217528], time: 77.124
mmmaddpg vs mmmaddpg steps: 499975, episodes: 20000, mean episode reward: -1.4017553993914271, agent episode reward: [-12.128253366667595, 5.363248983638084, 5.363248983638084], time: 76.41
mmmaddpg vs mmmaddpg steps: 524975, episodes: 21000, mean episode reward: -1.220592953115006, agent episode reward: [-12.147608778846312, 5.463507912865654, 5.463507912865654], time: 77.986
mmmaddpg vs mmmaddpg steps: 549975, episodes: 22000, mean episode reward: -0.9944311894622261, agent episode reward: [-11.859350388486835, 5.432459599512304, 5.432459599512304], time: 76.503
mmmaddpg vs mmmaddpg steps: 574975, episodes: 23000, mean episode reward: -0.6446677978115353, agent episode reward: [-11.875891533081816, 5.61561186763514, 5.61561186763514], time: 76.391
mmmaddpg vs mmmaddpg steps: 599975, episodes: 24000, mean episode reward: -1.0489962898002745, agent episode reward: [-12.087516827074024, 5.519260268636875, 5.519260268636875], time: 76.573
mmmaddpg vs mmmaddpg steps: 624975, episodes: 25000, mean episode reward: -1.3203875269222294, agent episode reward: [-12.202575287783915, 5.4410938804308415, 5.4410938804308415], time: 77.635
mmmaddpg vs mmmaddpg steps: 649975, episodes: 26000, mean episode reward: -0.6802029413496765, agent episode reward: [-12.02552878562785, 5.672662922139087, 5.672662922139087], time: 76.85
mmmaddpg vs mmmaddpg steps: 674975, episodes: 27000, mean episode reward: -0.9757832347591616, agent episode reward: [-11.49546452294091, 5.2598406440908745, 5.2598406440908745], time: 78.46
mmmaddpg vs mmmaddpg steps: 699975, episodes: 28000, mean episode reward: -2.171150283379771, agent episode reward: [-11.361811377482306, 4.595330547051268, 4.595330547051268], time: 78.064
mmmaddpg vs mmmaddpg steps: 724975, episodes: 29000, mean episode reward: -2.383049791274059, agent episode reward: [-11.097510165917134, 4.357230187321537, 4.357230187321537], time: 77.989
mmmaddpg vs mmmaddpg steps: 749975, episodes: 30000, mean episode reward: -2.554167816036111, agent episode reward: [-10.796689051401845, 4.121260617682867, 4.121260617682867], time: 77.782
mmmaddpg vs mmmaddpg steps: 774975, episodes: 31000, mean episode reward: -3.2463473140048302, agent episode reward: [-11.724277323927904, 4.238965004961536, 4.238965004961536], time: 78.2
mmmaddpg vs mmmaddpg steps: 799975, episodes: 32000, mean episode reward: -2.8138889436267456, agent episode reward: [-10.852777348198961, 4.019444202286108, 4.019444202286108], time: 76.73
mmmaddpg vs mmmaddpg steps: 824975, episodes: 33000, mean episode reward: -2.642887854192252, agent episode reward: [-10.708619189204802, 4.0328656675062735, 4.0328656675062735], time: 75.95
mmmaddpg vs mmmaddpg steps: 849975, episodes: 34000, mean episode reward: -2.6345048679494214, agent episode reward: [-11.31144608705871, 4.338470609554644, 4.338470609554644], time: 76.841
mmmaddpg vs mmmaddpg steps: 874975, episodes: 35000, mean episode reward: -2.773698289783818, agent episode reward: [-10.875896654991436, 4.051099182603809, 4.051099182603809], time: 79.263
mmmaddpg vs mmmaddpg steps: 899975, episodes: 36000, mean episode reward: -2.58492465126334, agent episode reward: [-10.694162977605407, 4.054619163171034, 4.054619163171034], time: 77.799
mmmaddpg vs mmmaddpg steps: 924975, episodes: 37000, mean episode reward: -3.3322400064706237, agent episode reward: [-10.833833116488115, 3.750796555008745, 3.750796555008745], time: 80.383
mmmaddpg vs mmmaddpg steps: 949975, episodes: 38000, mean episode reward: -2.644459638143512, agent episode reward: [-10.948930586297429, 4.152235474076958, 4.152235474076958], time: 79.829
mmmaddpg vs mmmaddpg steps: 974975, episodes: 39000, mean episode reward: -2.9996186584363795, agent episode reward: [-11.417333955296302, 4.208857648429962, 4.208857648429962], time: 78.414
mmmaddpg vs mmmaddpg steps: 999975, episodes: 40000, mean episode reward: -1.9752761882268928, agent episode reward: [-11.256581006632233, 4.64065240920267, 4.64065240920267], time: 77.539
mmmaddpg vs mmmaddpg steps: 1024975, episodes: 41000, mean episode reward: -3.049726254180023, agent episode reward: [-11.548477295139303, 4.2493755204796395, 4.2493755204796395], time: 74.763
mmmaddpg vs mmmaddpg steps: 1049975, episodes: 42000, mean episode reward: -3.581807071090613, agent episode reward: [-11.591898291069867, 4.005045609989627, 4.005045609989627], time: 79.403
mmmaddpg vs mmmaddpg steps: 1074975, episodes: 43000, mean episode reward: -2.7121858631200495, agent episode reward: [-10.910780414641696, 4.099297275760823, 4.099297275760823], time: 77.309
mmmaddpg vs mmmaddpg steps: 1099975, episodes: 44000, mean episode reward: -3.3326886661567494, agent episode reward: [-11.030061337238228, 3.848686335540739, 3.848686335540739], time: 78.233
mmmaddpg vs mmmaddpg steps: 1124975, episodes: 45000, mean episode reward: -3.3549995372763246, agent episode reward: [-10.672985510349472, 3.658992986536574, 3.658992986536574], time: 81.072
mmmaddpg vs mmmaddpg steps: 1149975, episodes: 46000, mean episode reward: -2.1540520372422813, agent episode reward: [-10.941771044503406, 4.393859503630562, 4.393859503630562], time: 79.729
mmmaddpg vs mmmaddpg steps: 1174975, episodes: 47000, mean episode reward: -2.8482041895262706, agent episode reward: [-11.265484096271969, 4.208639953372849, 4.208639953372849], time: 80.605
mmmaddpg vs mmmaddpg steps: 1199975, episodes: 48000, mean episode reward: -3.0083250451867887, agent episode reward: [-11.284185167629898, 4.137930061221554, 4.137930061221554], time: 79.356
mmmaddpg vs mmmaddpg steps: 1224975, episodes: 49000, mean episode reward: -3.4902673814997267, agent episode reward: [-11.332781964107363, 3.9212572913038186, 3.9212572913038186], time: 79.985
mmmaddpg vs mmmaddpg steps: 1249975, episodes: 50000, mean episode reward: -3.4492216694835722, agent episode reward: [-11.313263543678124, 3.9320209370972763, 3.9320209370972763], time: 78.867
mmmaddpg vs mmmaddpg steps: 1274975, episodes: 51000, mean episode reward: -3.0311964247389054, agent episode reward: [-11.306727439426801, 4.137765507343947, 4.137765507343947], time: 78.397
mmmaddpg vs mmmaddpg steps: 1299975, episodes: 52000, mean episode reward: -2.058853494653214, agent episode reward: [-11.243446862777386, 4.592296684062085, 4.592296684062085], time: 79.06
mmmaddpg vs mmmaddpg steps: 1324975, episodes: 53000, mean episode reward: -2.017302396947052, agent episode reward: [-11.586308544094472, 4.78450307357371, 4.78450307357371], time: 79.795
mmmaddpg vs mmmaddpg steps: 1349975, episodes: 54000, mean episode reward: -1.5808809203814358, agent episode reward: [-11.526050942555823, 4.972585011087192, 4.972585011087192], time: 80.188
mmmaddpg vs mmmaddpg steps: 1374975, episodes: 55000, mean episode reward: -1.9824775408651945, agent episode reward: [-12.092914198345015, 5.05521832873991, 5.05521832873991], time: 80.098
mmmaddpg vs mmmaddpg steps: 1399975, episodes: 56000, mean episode reward: -1.4945445335726, agent episode reward: [-11.4453121491288, 4.9753838077781, 4.9753838077781], time: 80.2
mmmaddpg vs mmmaddpg steps: 1424975, episodes: 57000, mean episode reward: -1.56339673286146, agent episode reward: [-11.25678760992569, 4.846695438532115, 4.846695438532115], time: 79.787
mmmaddpg vs mmmaddpg steps: 1449975, episodes: 58000, mean episode reward: -1.2965597982158825, agent episode reward: [-11.350278572799777, 5.026859387291947, 5.026859387291947], time: 80.678
mmmaddpg vs mmmaddpg steps: 1474975, episodes: 59000, mean episode reward: -0.949562862681473, agent episode reward: [-11.772839484955066, 5.411638311136796, 5.411638311136796], time: 80.266
mmmaddpg vs mmmaddpg steps: 1499975, episodes: 60000, mean episode reward: -1.1874258423909683, agent episode reward: [-11.789455314631562, 5.301014736120297, 5.301014736120297], time: 78.046
mmmaddpg vs mmmaddpg steps: 1524975, episodes: 61000, mean episode reward: -0.4252427001841299, agent episode reward: [-12.198670960825709, 5.886714130320789, 5.886714130320789], time: 76.723
mmmaddpg vs mmmaddpg steps: 1549975, episodes: 62000, mean episode reward: -0.620934881558471, agent episode reward: [-12.19064491243161, 5.78485501543657, 5.78485501543657], time: 78.056
mmmaddpg vs mmmaddpg steps: 1574975, episodes: 63000, mean episode reward: -0.7162820673304586, agent episode reward: [-12.16371014170446, 5.723714037187001, 5.723714037187001], time: 74.919
mmmaddpg vs mmmaddpg steps: 1599975, episodes: 64000, mean episode reward: -0.19143193561220817, agent episode reward: [-12.18395089719399, 5.996259480790892, 5.996259480790892], time: 78.676
mmmaddpg vs mmmaddpg steps: 1624975, episodes: 65000, mean episode reward: -0.47968063292957824, agent episode reward: [-12.295225094664547, 5.907772230867485, 5.907772230867485], time: 79.956
mmmaddpg vs mmmaddpg steps: 1649975, episodes: 66000, mean episode reward: -0.751472124186929, agent episode reward: [-12.125902462210295, 5.687215169011682, 5.687215169011682], time: 75.571
mmmaddpg vs mmmaddpg steps: 1674975, episodes: 67000, mean episode reward: -0.4381963644079149, agent episode reward: [-13.335508989865048, 6.448656312728566, 6.448656312728566], time: 77.343
mmmaddpg vs mmmaddpg steps: 1699975, episodes: 68000, mean episode reward: -0.5967726756685443, agent episode reward: [-12.438262816219273, 5.920745070275365, 5.920745070275365], time: 76.715
mmmaddpg vs mmmaddpg steps: 1724975, episodes: 69000, mean episode reward: -1.2318375801759096, agent episode reward: [-12.428563440393038, 5.598362930108565, 5.598362930108565], time: 75.635
mmmaddpg vs mmmaddpg steps: 1749975, episodes: 70000, mean episode reward: -0.0985649020670356, agent episode reward: [-12.289872827596417, 6.095653962764691, 6.095653962764691], time: 76.995
mmmaddpg vs mmmaddpg steps: 1774975, episodes: 71000, mean episode reward: -0.5623161636629079, agent episode reward: [-12.512311790919847, 5.97499781362847, 5.97499781362847], time: 79.79
mmmaddpg vs mmmaddpg steps: 1799975, episodes: 72000, mean episode reward: -0.5469299056627596, agent episode reward: [-12.551756562133642, 6.002413328235441, 6.002413328235441], time: 78.763
mmmaddpg vs mmmaddpg steps: 1824975, episodes: 73000, mean episode reward: -0.8817134198115271, agent episode reward: [-12.585267229808023, 5.851776904998249, 5.851776904998249], time: 79.894
mmmaddpg vs mmmaddpg steps: 1849975, episodes: 74000, mean episode reward: -0.9704670382810008, agent episode reward: [-12.210051864825436, 5.619792413272219, 5.619792413272219], time: 77.967
mmmaddpg vs mmmaddpg steps: 1874975, episodes: 75000, mean episode reward: -0.5016918432035469, agent episode reward: [-12.636364013223313, 6.067336085009884, 6.067336085009884], time: 79.83
mmmaddpg vs mmmaddpg steps: 1899975, episodes: 76000, mean episode reward: -0.7164252590877058, agent episode reward: [-12.63331862028036, 5.958446680596326, 5.958446680596326], time: 76.921
mmmaddpg vs mmmaddpg steps: 1924975, episodes: 77000, mean episode reward: -0.9008250644495417, agent episode reward: [-12.193390579782026, 5.646282757666242, 5.646282757666242], time: 77.244
mmmaddpg vs mmmaddpg steps: 1949975, episodes: 78000, mean episode reward: 0.33132224409942324, agent episode reward: [-13.187263956149328, 6.759293100124376, 6.759293100124376], time: 79.121
mmmaddpg vs mmmaddpg steps: 1974975, episodes: 79000, mean episode reward: 0.5341462970092011, agent episode reward: [-12.247822084719083, 6.390984190864141, 6.390984190864141], time: 75.086
mmmaddpg vs mmmaddpg steps: 1999975, episodes: 80000, mean episode reward: 0.5002278536955432, agent episode reward: [-12.176587550889975, 6.33840770229276, 6.33840770229276], time: 76.952
mmmaddpg vs mmmaddpg steps: 2024975, episodes: 81000, mean episode reward: 0.5568547802067748, agent episode reward: [-12.981448991584948, 6.7691518858958615, 6.7691518858958615], time: 77.035
mmmaddpg vs mmmaddpg steps: 2049975, episodes: 82000, mean episode reward: -0.2668923673486476, agent episode reward: [-12.91390797952194, 6.323507806086646, 6.323507806086646], time: 76.976
mmmaddpg vs mmmaddpg steps: 2074975, episodes: 83000, mean episode reward: 0.557620643848976, agent episode reward: [-12.123428730321457, 6.340524687085217, 6.340524687085217], time: 77.761
mmmaddpg vs mmmaddpg steps: 2099975, episodes: 84000, mean episode reward: 1.1479629350820633, agent episode reward: [-12.177025893103606, 6.662494414092834, 6.662494414092834], time: 75.897
mmmaddpg vs mmmaddpg steps: 2124975, episodes: 85000, mean episode reward: 0.4539671738217197, agent episode reward: [-12.136028183852897, 6.294997678837308, 6.294997678837308], time: 77.699
mmmaddpg vs mmmaddpg steps: 2149975, episodes: 86000, mean episode reward: 1.191106844368089, agent episode reward: [-12.80242330852346, 6.996765076445776, 6.996765076445776], time: 79.867
mmmaddpg vs mmmaddpg steps: 2174975, episodes: 87000, mean episode reward: 1.3863269178381594, agent episode reward: [-12.399194631494916, 6.892760774666538, 6.892760774666538], time: 78.116
mmmaddpg vs mmmaddpg steps: 2199975, episodes: 88000, mean episode reward: 1.7601837904920394, agent episode reward: [-12.671843575414568, 7.216013682953305, 7.216013682953305], time: 77.646
mmmaddpg vs mmmaddpg steps: 2224975, episodes: 89000, mean episode reward: 1.157468146221237, agent episode reward: [-12.688112864845346, 6.922790505533293, 6.922790505533293], time: 79.17
mmmaddpg vs mmmaddpg steps: 2249975, episodes: 90000, mean episode reward: 1.3944161004027242, agent episode reward: [-12.167211268464762, 6.780813684433742, 6.780813684433742], time: 79.472
mmmaddpg vs mmmaddpg steps: 2274975, episodes: 91000, mean episode reward: 2.0191130540192583, agent episode reward: [-12.773764540143336, 7.396438797081298, 7.396438797081298], time: 79.639
mmmaddpg vs mmmaddpg steps: 2299975, episodes: 92000, mean episode reward: 1.5907142927729192, agent episode reward: [-12.25555119172507, 6.9231327422489946, 6.9231327422489946], time: 81.28
mmmaddpg vs mmmaddpg steps: 2324975, episodes: 93000, mean episode reward: 1.9316578081177713, agent episode reward: [-12.282167604210873, 7.106912706164322, 7.106912706164322], time: 78.538
mmmaddpg vs mmmaddpg steps: 2349975, episodes: 94000, mean episode reward: 2.1207274281992023, agent episode reward: [-12.39350272358761, 7.257115075893405, 7.257115075893405], time: 80.587
mmmaddpg vs mmmaddpg steps: 2374975, episodes: 95000, mean episode reward: 1.9577317066677369, agent episode reward: [-12.939331356465926, 7.448531531566831, 7.448531531566831], time: 79.189
mmmaddpg vs mmmaddpg steps: 2399975, episodes: 96000, mean episode reward: 1.9225994949806118, agent episode reward: [-12.949119849834672, 7.435859672407641, 7.435859672407641], time: 77.93
mmmaddpg vs mmmaddpg steps: 2424975, episodes: 97000, mean episode reward: 1.7411605630286338, agent episode reward: [-12.635990165867035, 7.188575364447835, 7.188575364447835], time: 76.616
mmmaddpg vs mmmaddpg steps: 2449975, episodes: 98000, mean episode reward: 1.8837999662656808, agent episode reward: [-12.473740018726064, 7.178769992495872, 7.178769992495872], time: 77.418
mmmaddpg vs mmmaddpg steps: 2474975, episodes: 99000, mean episode reward: 1.9775991336240284, agent episode reward: [-13.439527842896295, 7.708563488260161, 7.708563488260161], time: 77.331
mmmaddpg vs mmmaddpg steps: 2499975, episodes: 100000, mean episode reward: 1.9254304023877957, agent episode reward: [-12.680519361885638, 7.302974882136717, 7.302974882136717], time: 76.532
...Finished total of 100001 episodes.
