0 bad agents
      adv rate for q_index :  0 [1e-05, 1e-05, 1e-05, 0.001]
      adv rate for p_index :  0 [1e-05, 1e-05, 1e-05, 0.001]
1 bad agents
      adv rate for q_index :  1 [1e-05, 1e-05, 1e-05, 0.001]
      adv rate for p_index :  1 [1e-05, 1e-05, 1e-05, 0.001]
2 bad agents
      adv rate for q_index :  2 [1e-05, 1e-05, 1e-05, 0.001]
      adv rate for p_index :  2 [1e-05, 1e-05, 1e-05, 0.001]
3 good agents
      adv rate for q_index :  3 [0.001, 0.001, 0.001, 1e-05]
      adv rate for p_index :  3 [0.001, 0.001, 0.001, 1e-05]
Using good policy mmmaddpg and bad policy mmmaddpg with 3 adversaries
Starting iterations...
mmmaddpg vs mmmaddpg steps: 24975, episodes: 1000, mean episode reward: -3.6926906267590947, agent episode reward: [1.74, 1.74, 1.74, -8.912690626759094], time: 81.909
mmmaddpg vs mmmaddpg steps: 49975, episodes: 2000, mean episode reward: 2.408106919735772, agent episode reward: [3.05, 3.05, 3.05, -6.741893080264228], time: 121.972
mmmaddpg vs mmmaddpg steps: 74975, episodes: 3000, mean episode reward: 7.654773106283823, agent episode reward: [4.06, 4.06, 4.06, -4.5252268937161775], time: 118.162
mmmaddpg vs mmmaddpg steps: 99975, episodes: 4000, mean episode reward: 8.24141666316408, agent episode reward: [4.36, 4.36, 4.36, -4.838583336835919], time: 117.672
mmmaddpg vs mmmaddpg steps: 124975, episodes: 5000, mean episode reward: 10.974709654159309, agent episode reward: [5.76, 5.76, 5.76, -6.305290345840691], time: 117.968
mmmaddpg vs mmmaddpg steps: 149975, episodes: 6000, mean episode reward: 13.162550695761333, agent episode reward: [7.09, 7.09, 7.09, -8.107449304238667], time: 118.384
mmmaddpg vs mmmaddpg steps: 174975, episodes: 7000, mean episode reward: 15.391578442554332, agent episode reward: [8.08, 8.08, 8.08, -8.848421557445668], time: 118.073
mmmaddpg vs mmmaddpg steps: 199975, episodes: 8000, mean episode reward: 13.047964644915318, agent episode reward: [7.5, 7.5, 7.5, -9.452035355084682], time: 117.761
mmmaddpg vs mmmaddpg steps: 224975, episodes: 9000, mean episode reward: 11.347277809021417, agent episode reward: [7.55, 7.55, 7.55, -11.302722190978582], time: 117.72
mmmaddpg vs mmmaddpg steps: 249975, episodes: 10000, mean episode reward: 8.864857043462605, agent episode reward: [6.77, 6.77, 6.77, -11.445142956537394], time: 122.444
mmmaddpg vs mmmaddpg steps: 274975, episodes: 11000, mean episode reward: 7.3687104043624565, agent episode reward: [5.47, 5.47, 5.47, -9.041289595637544], time: 125.285
mmmaddpg vs mmmaddpg steps: 299975, episodes: 12000, mean episode reward: 4.787689094816804, agent episode reward: [4.03, 4.03, 4.03, -7.302310905183196], time: 123.07
mmmaddpg vs mmmaddpg steps: 324975, episodes: 13000, mean episode reward: 10.934604714090296, agent episode reward: [6.67, 6.67, 6.67, -9.075395285909705], time: 124.44
mmmaddpg vs mmmaddpg steps: 349975, episodes: 14000, mean episode reward: 15.020498120578207, agent episode reward: [9.11, 9.11, 9.11, -12.309501879421793], time: 122.047
mmmaddpg vs mmmaddpg steps: 374975, episodes: 15000, mean episode reward: 17.417891586156898, agent episode reward: [10.4, 10.4, 10.4, -13.782108413843103], time: 122.523
mmmaddpg vs mmmaddpg steps: 399975, episodes: 16000, mean episode reward: 19.366060652633823, agent episode reward: [11.89, 11.89, 11.89, -16.303939347366175], time: 123.413
mmmaddpg vs mmmaddpg steps: 424975, episodes: 17000, mean episode reward: 23.74241897755153, agent episode reward: [14.48, 14.48, 14.48, -19.697581022448475], time: 119.618
mmmaddpg vs mmmaddpg steps: 449975, episodes: 18000, mean episode reward: 23.570246949126552, agent episode reward: [14.34, 14.34, 14.34, -19.44975305087345], time: 118.509
mmmaddpg vs mmmaddpg steps: 474975, episodes: 19000, mean episode reward: 18.26360074191523, agent episode reward: [11.99, 11.99, 11.99, -17.70639925808477], time: 121.202
mmmaddpg vs mmmaddpg steps: 499975, episodes: 20000, mean episode reward: 28.884411711127154, agent episode reward: [16.44, 16.44, 16.44, -20.435588288872843], time: 122.134
mmmaddpg vs mmmaddpg steps: 524975, episodes: 21000, mean episode reward: 24.915189737889857, agent episode reward: [15.22, 15.22, 15.22, -20.744810262110143], time: 122.775
mmmaddpg vs mmmaddpg steps: 549975, episodes: 22000, mean episode reward: 11.882068681179923, agent episode reward: [11.02, 11.02, 11.02, -21.177931318820075], time: 121.339
mmmaddpg vs mmmaddpg steps: 574975, episodes: 23000, mean episode reward: 15.226283283905385, agent episode reward: [10.65, 10.65, 10.65, -16.723716716094618], time: 123.18
mmmaddpg vs mmmaddpg steps: 599975, episodes: 24000, mean episode reward: 23.37474557092212, agent episode reward: [15.27, 15.27, 15.27, -22.435254429077883], time: 122.428
mmmaddpg vs mmmaddpg steps: 624975, episodes: 25000, mean episode reward: 19.615832018085825, agent episode reward: [13.61, 13.61, 13.61, -21.214167981914176], time: 122.974
mmmaddpg vs mmmaddpg steps: 649975, episodes: 26000, mean episode reward: 4.482814588243081, agent episode reward: [8.72, 8.72, 8.72, -21.67718541175692], time: 123.045
mmmaddpg vs mmmaddpg steps: 674975, episodes: 27000, mean episode reward: -1.8437837987158117, agent episode reward: [7.09, 7.09, 7.09, -23.11378379871581], time: 122.608
mmmaddpg vs mmmaddpg steps: 699975, episodes: 28000, mean episode reward: 6.342635266317592, agent episode reward: [10.58, 10.58, 10.58, -25.397364733682412], time: 122.413
mmmaddpg vs mmmaddpg steps: 724975, episodes: 29000, mean episode reward: 20.788604778806913, agent episode reward: [15.51, 15.51, 15.51, -25.741395221193088], time: 123.891
mmmaddpg vs mmmaddpg steps: 749975, episodes: 30000, mean episode reward: 17.81016454174052, agent episode reward: [13.75, 13.75, 13.75, -23.439835458259484], time: 123.72
mmmaddpg vs mmmaddpg steps: 774975, episodes: 31000, mean episode reward: 18.203382269039658, agent episode reward: [13.39, 13.39, 13.39, -21.966617730960337], time: 123.375
mmmaddpg vs mmmaddpg steps: 799975, episodes: 32000, mean episode reward: 21.809558992913214, agent episode reward: [14.61, 14.61, 14.61, -22.02044100708678], time: 122.821
mmmaddpg vs mmmaddpg steps: 824975, episodes: 33000, mean episode reward: 19.413002651054573, agent episode reward: [13.71, 13.71, 13.71, -21.716997348945426], time: 122.855
mmmaddpg vs mmmaddpg steps: 849975, episodes: 34000, mean episode reward: 18.55068103007389, agent episode reward: [13.42, 13.42, 13.42, -21.709318969926105], time: 124.332
mmmaddpg vs mmmaddpg steps: 874975, episodes: 35000, mean episode reward: 15.73679410062074, agent episode reward: [12.33, 12.33, 12.33, -21.25320589937926], time: 123.477
mmmaddpg vs mmmaddpg steps: 899975, episodes: 36000, mean episode reward: 15.593923000198226, agent episode reward: [12.43, 12.43, 12.43, -21.69607699980177], time: 123.6
mmmaddpg vs mmmaddpg steps: 924975, episodes: 37000, mean episode reward: 18.53436261496987, agent episode reward: [12.86, 12.86, 12.86, -20.045637385030133], time: 123.532
mmmaddpg vs mmmaddpg steps: 949975, episodes: 38000, mean episode reward: 20.350958359507846, agent episode reward: [13.1, 13.1, 13.1, -18.949041640492155], time: 124.837
mmmaddpg vs mmmaddpg steps: 974975, episodes: 39000, mean episode reward: 16.08694324628258, agent episode reward: [11.33, 11.33, 11.33, -17.903056753717422], time: 124.088
mmmaddpg vs mmmaddpg steps: 999975, episodes: 40000, mean episode reward: 17.61512407503058, agent episode reward: [12.26, 12.26, 12.26, -19.16487592496942], time: 107.109
mmmaddpg vs mmmaddpg steps: 1024975, episodes: 41000, mean episode reward: 14.740528455634134, agent episode reward: [10.73, 10.73, 10.73, -17.449471544365863], time: 106.986
mmmaddpg vs mmmaddpg steps: 1049975, episodes: 42000, mean episode reward: 15.657386490943447, agent episode reward: [11.61, 11.61, 11.61, -19.17261350905655], time: 107.845
mmmaddpg vs mmmaddpg steps: 1074975, episodes: 43000, mean episode reward: 16.41254383658055, agent episode reward: [11.87, 11.87, 11.87, -19.19745616341945], time: 109.445
mmmaddpg vs mmmaddpg steps: 1099975, episodes: 44000, mean episode reward: 17.45049590899195, agent episode reward: [12.0, 12.0, 12.0, -18.54950409100805], time: 108.823
mmmaddpg vs mmmaddpg steps: 1124975, episodes: 45000, mean episode reward: 20.647263792967117, agent episode reward: [13.54, 13.54, 13.54, -19.97273620703288], time: 109.335
mmmaddpg vs mmmaddpg steps: 1149975, episodes: 46000, mean episode reward: 21.07685445665685, agent episode reward: [13.46, 13.46, 13.46, -19.303145543343152], time: 110.003
mmmaddpg vs mmmaddpg steps: 1174975, episodes: 47000, mean episode reward: 19.410125253975306, agent episode reward: [12.53, 12.53, 12.53, -18.179874746024694], time: 110.161
mmmaddpg vs mmmaddpg steps: 1199975, episodes: 48000, mean episode reward: 17.310552254385684, agent episode reward: [12.23, 12.23, 12.23, -19.37944774561432], time: 108.32
mmmaddpg vs mmmaddpg steps: 1224975, episodes: 49000, mean episode reward: 18.76335028510949, agent episode reward: [13.16, 13.16, 13.16, -20.71664971489051], time: 107.055
mmmaddpg vs mmmaddpg steps: 1249975, episodes: 50000, mean episode reward: 20.395450636551494, agent episode reward: [13.52, 13.52, 13.52, -20.164549363448504], time: 106.822
mmmaddpg vs mmmaddpg steps: 1274975, episodes: 51000, mean episode reward: 17.888511613215385, agent episode reward: [12.78, 12.78, 12.78, -20.451488386784614], time: 106.345
mmmaddpg vs mmmaddpg steps: 1299975, episodes: 52000, mean episode reward: 19.05142026206003, agent episode reward: [13.2, 13.2, 13.2, -20.54857973793997], time: 110.379
mmmaddpg vs mmmaddpg steps: 1324975, episodes: 53000, mean episode reward: 18.880002188025134, agent episode reward: [13.02, 13.02, 13.02, -20.179997811974868], time: 108.633
mmmaddpg vs mmmaddpg steps: 1349975, episodes: 54000, mean episode reward: 17.57862404838816, agent episode reward: [12.31, 12.31, 12.31, -19.35137595161184], time: 117.2
mmmaddpg vs mmmaddpg steps: 1374975, episodes: 55000, mean episode reward: 17.5528050342619, agent episode reward: [12.46, 12.46, 12.46, -19.827194965738098], time: 126.099
mmmaddpg vs mmmaddpg steps: 1399975, episodes: 56000, mean episode reward: 16.872450860458386, agent episode reward: [11.56, 11.56, 11.56, -17.807549139541614], time: 131.115
mmmaddpg vs mmmaddpg steps: 1424975, episodes: 57000, mean episode reward: 15.389928898301102, agent episode reward: [11.25, 11.25, 11.25, -18.360071101698896], time: 131.125
mmmaddpg vs mmmaddpg steps: 1449975, episodes: 58000, mean episode reward: 16.53530532953302, agent episode reward: [12.1, 12.1, 12.1, -19.76469467046698], time: 125.668
mmmaddpg vs mmmaddpg steps: 1474975, episodes: 59000, mean episode reward: 23.411905100985155, agent episode reward: [14.65, 14.65, 14.65, -20.538094899014848], time: 130.943
mmmaddpg vs mmmaddpg steps: 1499975, episodes: 60000, mean episode reward: 25.27430905491757, agent episode reward: [15.28, 15.28, 15.28, -20.56569094508243], time: 131.093
mmmaddpg vs mmmaddpg steps: 1524975, episodes: 61000, mean episode reward: 26.07656451635646, agent episode reward: [15.73, 15.73, 15.73, -21.11343548364354], time: 129.91
mmmaddpg vs mmmaddpg steps: 1549975, episodes: 62000, mean episode reward: 21.62547398890552, agent episode reward: [13.66, 13.66, 13.66, -19.35452601109448], time: 130.951
mmmaddpg vs mmmaddpg steps: 1574975, episodes: 63000, mean episode reward: 22.68590777921423, agent episode reward: [14.14, 14.14, 14.14, -19.734092220785772], time: 132.397
mmmaddpg vs mmmaddpg steps: 1599975, episodes: 64000, mean episode reward: 20.970728314697666, agent episode reward: [13.74, 13.74, 13.74, -20.249271685302332], time: 124.745
mmmaddpg vs mmmaddpg steps: 1624975, episodes: 65000, mean episode reward: 20.55771055304019, agent episode reward: [13.41, 13.41, 13.41, -19.672289446959805], time: 128.074
mmmaddpg vs mmmaddpg steps: 1649975, episodes: 66000, mean episode reward: 20.936722360349247, agent episode reward: [13.57, 13.57, 13.57, -19.773277639650754], time: 128.31
mmmaddpg vs mmmaddpg steps: 1674975, episodes: 67000, mean episode reward: 21.263856700159433, agent episode reward: [13.55, 13.55, 13.55, -19.386143299840565], time: 125.995
mmmaddpg vs mmmaddpg steps: 1699975, episodes: 68000, mean episode reward: 15.353005983644678, agent episode reward: [11.7, 11.7, 11.7, -19.746994016355323], time: 126.333
mmmaddpg vs mmmaddpg steps: 1724975, episodes: 69000, mean episode reward: 11.859803731312661, agent episode reward: [10.75, 10.75, 10.75, -20.390196268687337], time: 128.709
mmmaddpg vs mmmaddpg steps: 1749975, episodes: 70000, mean episode reward: 14.601837191421296, agent episode reward: [11.09, 11.09, 11.09, -18.668162808578703], time: 132.217
mmmaddpg vs mmmaddpg steps: 1774975, episodes: 71000, mean episode reward: 18.27116423471475, agent episode reward: [12.26, 12.26, 12.26, -18.508835765285248], time: 133.446
mmmaddpg vs mmmaddpg steps: 1799975, episodes: 72000, mean episode reward: 17.570029141894587, agent episode reward: [12.46, 12.46, 12.46, -19.809970858105416], time: 131.766
mmmaddpg vs mmmaddpg steps: 1824975, episodes: 73000, mean episode reward: 18.26885365239784, agent episode reward: [12.23, 12.23, 12.23, -18.42114634760216], time: 130.422
mmmaddpg vs mmmaddpg steps: 1849975, episodes: 74000, mean episode reward: 17.38398041148997, agent episode reward: [11.97, 11.97, 11.97, -18.52601958851003], time: 131.473
mmmaddpg vs mmmaddpg steps: 1874975, episodes: 75000, mean episode reward: 19.765059999979957, agent episode reward: [13.07, 13.07, 13.07, -19.444940000020047], time: 127.309
mmmaddpg vs mmmaddpg steps: 1899975, episodes: 76000, mean episode reward: 16.431424515502762, agent episode reward: [12.27, 12.27, 12.27, -20.378575484497237], time: 128.911
mmmaddpg vs mmmaddpg steps: 1924975, episodes: 77000, mean episode reward: 19.237545076773355, agent episode reward: [12.8, 12.8, 12.8, -19.162454923226644], time: 127.179
mmmaddpg vs mmmaddpg steps: 1949975, episodes: 78000, mean episode reward: 17.225702074592437, agent episode reward: [12.31, 12.31, 12.31, -19.704297925407563], time: 127.091
mmmaddpg vs mmmaddpg steps: 1974975, episodes: 79000, mean episode reward: 18.042970011855775, agent episode reward: [12.39, 12.39, 12.39, -19.127029988144226], time: 129.81
mmmaddpg vs mmmaddpg steps: 1999975, episodes: 80000, mean episode reward: 19.261376104449006, agent episode reward: [13.07, 13.07, 13.07, -19.948623895550995], time: 132.133
mmmaddpg vs mmmaddpg steps: 2024975, episodes: 81000, mean episode reward: 18.01250447443682, agent episode reward: [12.78, 12.78, 12.78, -20.32749552556318], time: 127.846
mmmaddpg vs mmmaddpg steps: 2049975, episodes: 82000, mean episode reward: 19.045429160285742, agent episode reward: [12.68, 12.68, 12.68, -18.99457083971426], time: 133.368
mmmaddpg vs mmmaddpg steps: 2074975, episodes: 83000, mean episode reward: 13.8065220873546, agent episode reward: [11.35, 11.35, 11.35, -20.2434779126454], time: 131.45
mmmaddpg vs mmmaddpg steps: 2099975, episodes: 84000, mean episode reward: 20.06196372658894, agent episode reward: [13.16, 13.16, 13.16, -19.418036273411065], time: 129.32
mmmaddpg vs mmmaddpg steps: 2124975, episodes: 85000, mean episode reward: 18.9493843070087, agent episode reward: [12.97, 12.97, 12.97, -19.9606156929913], time: 130.9
mmmaddpg vs mmmaddpg steps: 2149975, episodes: 86000, mean episode reward: 15.230526936079483, agent episode reward: [11.43, 11.43, 11.43, -19.059473063920514], time: 130.196
mmmaddpg vs mmmaddpg steps: 2174975, episodes: 87000, mean episode reward: 13.708447313918542, agent episode reward: [11.14, 11.14, 11.14, -19.711552686081454], time: 131.105
mmmaddpg vs mmmaddpg steps: 2199975, episodes: 88000, mean episode reward: 15.136298331999315, agent episode reward: [11.51, 11.51, 11.51, -19.393701668000684], time: 130.685
mmmaddpg vs mmmaddpg steps: 2224975, episodes: 89000, mean episode reward: 17.982383826120593, agent episode reward: [12.66, 12.66, 12.66, -19.997616173879404], time: 128.987
mmmaddpg vs mmmaddpg steps: 2249975, episodes: 90000, mean episode reward: 15.410034728354633, agent episode reward: [11.82, 11.82, 11.82, -20.049965271645362], time: 130.18
mmmaddpg vs mmmaddpg steps: 2274975, episodes: 91000, mean episode reward: 15.000789258321314, agent episode reward: [10.99, 10.99, 10.99, -17.969210741678687], time: 131.585
mmmaddpg vs mmmaddpg steps: 2299975, episodes: 92000, mean episode reward: 20.408155537999935, agent episode reward: [13.72, 13.72, 13.72, -20.751844462000065], time: 127.658
mmmaddpg vs mmmaddpg steps: 2324975, episodes: 93000, mean episode reward: 17.47453340675334, agent episode reward: [12.12, 12.12, 12.12, -18.885466593246658], time: 130.791
mmmaddpg vs mmmaddpg steps: 2349975, episodes: 94000, mean episode reward: 17.589342410314185, agent episode reward: [12.05, 12.05, 12.05, -18.560657589685817], time: 131.839
mmmaddpg vs mmmaddpg steps: 2374975, episodes: 95000, mean episode reward: 17.015920472447124, agent episode reward: [12.32, 12.32, 12.32, -19.944079527552876], time: 132.548
mmmaddpg vs mmmaddpg steps: 2399975, episodes: 96000, mean episode reward: 17.614880553095407, agent episode reward: [12.72, 12.72, 12.72, -20.545119446904597], time: 129.448
mmmaddpg vs mmmaddpg steps: 2424975, episodes: 97000, mean episode reward: 18.416561188599907, agent episode reward: [12.56, 12.56, 12.56, -19.263438811400093], time: 130.215
mmmaddpg vs mmmaddpg steps: 2449975, episodes: 98000, mean episode reward: 17.41265844524255, agent episode reward: [12.24, 12.24, 12.24, -19.30734155475745], time: 130.253
mmmaddpg vs mmmaddpg steps: 2474975, episodes: 99000, mean episode reward: 16.788807965670923, agent episode reward: [12.21, 12.21, 12.21, -19.841192034329076], time: 128.912
mmmaddpg vs mmmaddpg steps: 2499975, episodes: 100000, mean episode reward: 14.470206614008031, agent episode reward: [11.54, 11.54, 11.54, -20.149793385991966], time: 122.889
...Finished total of 100001 episodes.
