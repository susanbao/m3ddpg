0 bad agents
      adv rate for q_index :  0 [1e-05, 1e-05, 1e-05, 0.001]
      adv rate for p_index :  0 [1e-05, 1e-05, 1e-05, 0.001]
1 bad agents
      adv rate for q_index :  1 [1e-05, 1e-05, 1e-05, 0.001]
      adv rate for p_index :  1 [1e-05, 1e-05, 1e-05, 0.001]
2 bad agents
      adv rate for q_index :  2 [1e-05, 1e-05, 1e-05, 0.001]
      adv rate for p_index :  2 [1e-05, 1e-05, 1e-05, 0.001]
3 good agents
      adv rate for q_index :  3 [0.001, 0.001, 0.001, 1e-05]
      adv rate for p_index :  3 [0.001, 0.001, 0.001, 1e-05]
Using good policy mmmaddpg and bad policy mmmaddpg with 3 adversaries
Starting iterations...
mmmaddpg vs mmmaddpg steps: 24975, episodes: 1000, mean episode reward: -3.071102874008041, agent episode reward: [2.16, 2.16, 2.16, -9.55110287400804], time: 83.405
mmmaddpg vs mmmaddpg steps: 49975, episodes: 2000, mean episode reward: -2.6336020986236517, agent episode reward: [4.01, 4.01, 4.01, -14.66360209862365], time: 111.367
mmmaddpg vs mmmaddpg steps: 74975, episodes: 3000, mean episode reward: 9.219581740543122, agent episode reward: [4.75, 4.75, 4.75, -5.030418259456879], time: 108.429
mmmaddpg vs mmmaddpg steps: 99975, episodes: 4000, mean episode reward: 15.020307120388384, agent episode reward: [7.61, 7.61, 7.61, -7.809692879611616], time: 109.184
mmmaddpg vs mmmaddpg steps: 124975, episodes: 5000, mean episode reward: 28.929017235441375, agent episode reward: [14.61, 14.61, 14.61, -14.900982764558623], time: 108.861
mmmaddpg vs mmmaddpg steps: 149975, episodes: 6000, mean episode reward: 60.40289391055357, agent episode reward: [31.46, 31.46, 31.46, -33.97710608944642], time: 110.229
mmmaddpg vs mmmaddpg steps: 174975, episodes: 7000, mean episode reward: 46.2695199541095, agent episode reward: [28.36, 28.36, 28.36, -38.8104800458905], time: 109.35
mmmaddpg vs mmmaddpg steps: 199975, episodes: 8000, mean episode reward: 38.26802541662394, agent episode reward: [23.48, 23.48, 23.48, -32.17197458337606], time: 109.594
mmmaddpg vs mmmaddpg steps: 224975, episodes: 9000, mean episode reward: 34.89198772975623, agent episode reward: [20.21, 20.21, 20.21, -25.738012270243768], time: 109.63
mmmaddpg vs mmmaddpg steps: 249975, episodes: 10000, mean episode reward: 25.54075922427717, agent episode reward: [15.05, 15.05, 15.05, -19.609240775722828], time: 109.638
mmmaddpg vs mmmaddpg steps: 274975, episodes: 11000, mean episode reward: 20.801867794624474, agent episode reward: [12.65, 12.65, 12.65, -17.148132205375525], time: 108.222
mmmaddpg vs mmmaddpg steps: 299975, episodes: 12000, mean episode reward: 22.733726433053963, agent episode reward: [13.52, 13.52, 13.52, -17.82627356694604], time: 110.669
mmmaddpg vs mmmaddpg steps: 324975, episodes: 13000, mean episode reward: 16.225709483944506, agent episode reward: [10.66, 10.66, 10.66, -15.754290516055493], time: 110.19
mmmaddpg vs mmmaddpg steps: 349975, episodes: 14000, mean episode reward: 19.627387183426453, agent episode reward: [11.97, 11.97, 11.97, -16.282612816573543], time: 109.204
mmmaddpg vs mmmaddpg steps: 374975, episodes: 15000, mean episode reward: 21.921588950466983, agent episode reward: [13.3, 13.3, 13.3, -17.978411049533015], time: 109.627
mmmaddpg vs mmmaddpg steps: 399975, episodes: 16000, mean episode reward: 29.80707813370442, agent episode reward: [17.11, 17.11, 17.11, -21.522921866295583], time: 108.938
mmmaddpg vs mmmaddpg steps: 424975, episodes: 17000, mean episode reward: 36.18103007292636, agent episode reward: [20.63, 20.63, 20.63, -25.70896992707364], time: 109.6
mmmaddpg vs mmmaddpg steps: 449975, episodes: 18000, mean episode reward: 44.29917869396562, agent episode reward: [24.26, 24.26, 24.26, -28.480821306034375], time: 109.494
mmmaddpg vs mmmaddpg steps: 474975, episodes: 19000, mean episode reward: 29.340369841105446, agent episode reward: [16.94, 16.94, 16.94, -21.479630158894555], time: 106.588
mmmaddpg vs mmmaddpg steps: 499975, episodes: 20000, mean episode reward: 24.86397920972663, agent episode reward: [15.31, 15.31, 15.31, -21.06602079027337], time: 107.309
mmmaddpg vs mmmaddpg steps: 524975, episodes: 21000, mean episode reward: 20.7942963422506, agent episode reward: [14.11, 14.11, 14.11, -21.5357036577494], time: 106.198
mmmaddpg vs mmmaddpg steps: 549975, episodes: 22000, mean episode reward: 18.728410033750592, agent episode reward: [12.79, 12.79, 12.79, -19.64158996624941], time: 107.882
mmmaddpg vs mmmaddpg steps: 574975, episodes: 23000, mean episode reward: 17.134868826834076, agent episode reward: [11.81, 11.81, 11.81, -18.295131173165924], time: 106.58
mmmaddpg vs mmmaddpg steps: 599975, episodes: 24000, mean episode reward: 15.085909485332813, agent episode reward: [10.76, 10.76, 10.76, -17.194090514667188], time: 106.15
mmmaddpg vs mmmaddpg steps: 624975, episodes: 25000, mean episode reward: 13.181899131307237, agent episode reward: [9.26, 9.26, 9.26, -14.598100868692763], time: 107.515
mmmaddpg vs mmmaddpg steps: 649975, episodes: 26000, mean episode reward: 12.728679633654457, agent episode reward: [8.73, 8.73, 8.73, -13.461320366345545], time: 106.075
mmmaddpg vs mmmaddpg steps: 674975, episodes: 27000, mean episode reward: 12.792593537042933, agent episode reward: [9.15, 9.15, 9.15, -14.657406462957072], time: 105.376
mmmaddpg vs mmmaddpg steps: 699975, episodes: 28000, mean episode reward: 10.128026568086131, agent episode reward: [7.75, 7.75, 7.75, -13.121973431913865], time: 107.942
mmmaddpg vs mmmaddpg steps: 724975, episodes: 29000, mean episode reward: 12.952035679635381, agent episode reward: [8.79, 8.79, 8.79, -13.41796432036462], time: 107.588
mmmaddpg vs mmmaddpg steps: 749975, episodes: 30000, mean episode reward: 13.001751781813196, agent episode reward: [9.09, 9.09, 9.09, -14.268248218186804], time: 105.734
mmmaddpg vs mmmaddpg steps: 774975, episodes: 31000, mean episode reward: 11.618268802364982, agent episode reward: [8.04, 8.04, 8.04, -12.501731197635015], time: 107.459
mmmaddpg vs mmmaddpg steps: 799975, episodes: 32000, mean episode reward: 12.589356546501584, agent episode reward: [8.49, 8.49, 8.49, -12.880643453498417], time: 105.644
mmmaddpg vs mmmaddpg steps: 824975, episodes: 33000, mean episode reward: 10.346894247028821, agent episode reward: [7.45, 7.45, 7.45, -12.003105752971178], time: 105.872
mmmaddpg vs mmmaddpg steps: 849975, episodes: 34000, mean episode reward: 12.130275527903283, agent episode reward: [8.25, 8.25, 8.25, -12.619724472096719], time: 106.423
mmmaddpg vs mmmaddpg steps: 874975, episodes: 35000, mean episode reward: 10.254060936118854, agent episode reward: [7.46, 7.46, 7.46, -12.125939063881146], time: 108.147
mmmaddpg vs mmmaddpg steps: 899975, episodes: 36000, mean episode reward: 8.351185223709484, agent episode reward: [6.42, 6.42, 6.42, -10.908814776290516], time: 106.122
mmmaddpg vs mmmaddpg steps: 924975, episodes: 37000, mean episode reward: 7.650573861857057, agent episode reward: [6.42, 6.42, 6.42, -11.609426138142942], time: 106.366
mmmaddpg vs mmmaddpg steps: 949975, episodes: 38000, mean episode reward: 8.47072532183492, agent episode reward: [6.61, 6.61, 6.61, -11.359274678165079], time: 106.527
mmmaddpg vs mmmaddpg steps: 974975, episodes: 39000, mean episode reward: 8.120294095210218, agent episode reward: [6.66, 6.66, 6.66, -11.859705904789783], time: 107.655
mmmaddpg vs mmmaddpg steps: 999975, episodes: 40000, mean episode reward: 9.888855406993134, agent episode reward: [7.55, 7.55, 7.55, -12.761144593006867], time: 107.448
mmmaddpg vs mmmaddpg steps: 1024975, episodes: 41000, mean episode reward: 8.244082703721315, agent episode reward: [6.61, 6.61, 6.61, -11.585917296278684], time: 108.88
mmmaddpg vs mmmaddpg steps: 1049975, episodes: 42000, mean episode reward: 11.60226705740719, agent episode reward: [8.5, 8.5, 8.5, -13.89773294259281], time: 105.493
mmmaddpg vs mmmaddpg steps: 1074975, episodes: 43000, mean episode reward: 11.064986829904235, agent episode reward: [8.65, 8.65, 8.65, -14.885013170095764], time: 105.904
mmmaddpg vs mmmaddpg steps: 1099975, episodes: 44000, mean episode reward: 10.608596407070978, agent episode reward: [7.89, 7.89, 7.89, -13.061403592929022], time: 108.043
mmmaddpg vs mmmaddpg steps: 1124975, episodes: 45000, mean episode reward: 8.7428376198794, agent episode reward: [7.19, 7.19, 7.19, -12.827162380120601], time: 106.406
mmmaddpg vs mmmaddpg steps: 1149975, episodes: 46000, mean episode reward: 9.819959319051534, agent episode reward: [7.43, 7.43, 7.43, -12.470040680948465], time: 107.993
mmmaddpg vs mmmaddpg steps: 1174975, episodes: 47000, mean episode reward: 13.704274920936246, agent episode reward: [9.52, 9.52, 9.52, -14.855725079063754], time: 109.612
mmmaddpg vs mmmaddpg steps: 1199975, episodes: 48000, mean episode reward: 14.536270248670684, agent episode reward: [9.69, 9.69, 9.69, -14.533729751329316], time: 108.498
mmmaddpg vs mmmaddpg steps: 1224975, episodes: 49000, mean episode reward: 15.266476537800832, agent episode reward: [9.98, 9.98, 9.98, -14.673523462199169], time: 109.168
mmmaddpg vs mmmaddpg steps: 1249975, episodes: 50000, mean episode reward: 14.119052202061427, agent episode reward: [9.59, 9.59, 9.59, -14.650947797938576], time: 108.393
mmmaddpg vs mmmaddpg steps: 1274975, episodes: 51000, mean episode reward: 14.651115474110563, agent episode reward: [9.65, 9.65, 9.65, -14.298884525889436], time: 105.613
mmmaddpg vs mmmaddpg steps: 1299975, episodes: 52000, mean episode reward: 14.57782236918272, agent episode reward: [9.42, 9.42, 9.42, -13.68217763081728], time: 108.601
mmmaddpg vs mmmaddpg steps: 1324975, episodes: 53000, mean episode reward: 15.594361026364243, agent episode reward: [9.66, 9.66, 9.66, -13.385638973635755], time: 105.364
mmmaddpg vs mmmaddpg steps: 1349975, episodes: 54000, mean episode reward: 15.79798143025511, agent episode reward: [10.06, 10.06, 10.06, -14.38201856974489], time: 106.327
mmmaddpg vs mmmaddpg steps: 1374975, episodes: 55000, mean episode reward: 19.070980612718763, agent episode reward: [11.6, 11.6, 11.6, -15.729019387281234], time: 108.803
mmmaddpg vs mmmaddpg steps: 1399975, episodes: 56000, mean episode reward: 16.83986470304811, agent episode reward: [10.43, 10.43, 10.43, -14.450135296951888], time: 108.566
mmmaddpg vs mmmaddpg steps: 1424975, episodes: 57000, mean episode reward: 16.92027544727129, agent episode reward: [10.69, 10.69, 10.69, -15.149724552728708], time: 106.16
mmmaddpg vs mmmaddpg steps: 1449975, episodes: 58000, mean episode reward: 16.086491266057326, agent episode reward: [10.48, 10.48, 10.48, -15.353508733942675], time: 108.692
mmmaddpg vs mmmaddpg steps: 1474975, episodes: 59000, mean episode reward: 16.125139093382927, agent episode reward: [10.33, 10.33, 10.33, -14.864860906617071], time: 107.061
mmmaddpg vs mmmaddpg steps: 1499975, episodes: 60000, mean episode reward: 18.774570322521665, agent episode reward: [12.09, 12.09, 12.09, -17.495429677478338], time: 106.725
mmmaddpg vs mmmaddpg steps: 1524975, episodes: 61000, mean episode reward: 21.466948749594287, agent episode reward: [13.4, 13.4, 13.4, -18.733051250405712], time: 108.099
mmmaddpg vs mmmaddpg steps: 1549975, episodes: 62000, mean episode reward: 19.613218013927145, agent episode reward: [12.29, 12.29, 12.29, -17.256781986072852], time: 107.452
mmmaddpg vs mmmaddpg steps: 1574975, episodes: 63000, mean episode reward: 17.164973051176208, agent episode reward: [11.35, 11.35, 11.35, -16.885026948823793], time: 108.376
mmmaddpg vs mmmaddpg steps: 1599975, episodes: 64000, mean episode reward: 20.843986103474794, agent episode reward: [12.88, 12.88, 12.88, -17.796013896525213], time: 98.633
mmmaddpg vs mmmaddpg steps: 1624975, episodes: 65000, mean episode reward: 21.057005691828948, agent episode reward: [13.1, 13.1, 13.1, -18.242994308171053], time: 88.149
mmmaddpg vs mmmaddpg steps: 1649975, episodes: 66000, mean episode reward: 21.11481627158894, agent episode reward: [13.02, 13.02, 13.02, -17.945183728411063], time: 87.817
mmmaddpg vs mmmaddpg steps: 1674975, episodes: 67000, mean episode reward: 20.84144097989166, agent episode reward: [12.97, 12.97, 12.97, -18.06855902010834], time: 87.685
mmmaddpg vs mmmaddpg steps: 1699975, episodes: 68000, mean episode reward: 20.856237449436012, agent episode reward: [13.54, 13.54, 13.54, -19.76376255056399], time: 89.023
mmmaddpg vs mmmaddpg steps: 1724975, episodes: 69000, mean episode reward: 19.97351967602742, agent episode reward: [12.78, 12.78, 12.78, -18.36648032397258], time: 88.439
mmmaddpg vs mmmaddpg steps: 1749975, episodes: 70000, mean episode reward: 21.254100009008827, agent episode reward: [13.06, 13.06, 13.06, -17.925899990991173], time: 89.797
mmmaddpg vs mmmaddpg steps: 1774975, episodes: 71000, mean episode reward: 21.64435421118756, agent episode reward: [13.4, 13.4, 13.4, -18.555645788812438], time: 87.202
mmmaddpg vs mmmaddpg steps: 1799975, episodes: 72000, mean episode reward: 20.494577319288606, agent episode reward: [12.67, 12.67, 12.67, -17.515422680711396], time: 88.648
mmmaddpg vs mmmaddpg steps: 1824975, episodes: 73000, mean episode reward: 19.685458667794244, agent episode reward: [12.54, 12.54, 12.54, -17.934541332205757], time: 87.547
mmmaddpg vs mmmaddpg steps: 1849975, episodes: 74000, mean episode reward: 18.988621533486427, agent episode reward: [12.7, 12.7, 12.7, -19.111378466513575], time: 90.787
mmmaddpg vs mmmaddpg steps: 1874975, episodes: 75000, mean episode reward: 19.456959470587922, agent episode reward: [12.55, 12.55, 12.55, -18.193040529412077], time: 90.967
mmmaddpg vs mmmaddpg steps: 1899975, episodes: 76000, mean episode reward: 18.04458902815964, agent episode reward: [12.18, 12.18, 12.18, -18.49541097184036], time: 91.199
mmmaddpg vs mmmaddpg steps: 1924975, episodes: 77000, mean episode reward: 15.569294128333274, agent episode reward: [10.79, 10.79, 10.79, -16.80070587166672], time: 90.156
mmmaddpg vs mmmaddpg steps: 1949975, episodes: 78000, mean episode reward: 13.521400966190672, agent episode reward: [9.99, 9.99, 9.99, -16.448599033809327], time: 86.405
mmmaddpg vs mmmaddpg steps: 1974975, episodes: 79000, mean episode reward: 18.12687116353534, agent episode reward: [11.73, 11.73, 11.73, -17.063128836464657], time: 86.313
mmmaddpg vs mmmaddpg steps: 1999975, episodes: 80000, mean episode reward: 18.14032323093502, agent episode reward: [11.62, 11.62, 11.62, -16.71967676906498], time: 88.529
mmmaddpg vs mmmaddpg steps: 2024975, episodes: 81000, mean episode reward: 16.58948300333959, agent episode reward: [11.04, 11.04, 11.04, -16.53051699666041], time: 86.874
mmmaddpg vs mmmaddpg steps: 2049975, episodes: 82000, mean episode reward: 16.057039674132476, agent episode reward: [10.84, 10.84, 10.84, -16.462960325867524], time: 87.058
mmmaddpg vs mmmaddpg steps: 2074975, episodes: 83000, mean episode reward: 19.047164676631517, agent episode reward: [11.98, 11.98, 11.98, -16.89283532336848], time: 89.635
mmmaddpg vs mmmaddpg steps: 2099975, episodes: 84000, mean episode reward: 18.672459786865467, agent episode reward: [11.94, 11.94, 11.94, -17.147540213134533], time: 86.815
mmmaddpg vs mmmaddpg steps: 2124975, episodes: 85000, mean episode reward: 16.172667912387837, agent episode reward: [10.56, 10.56, 10.56, -15.507332087612161], time: 88.54
mmmaddpg vs mmmaddpg steps: 2149975, episodes: 86000, mean episode reward: 18.011594735549785, agent episode reward: [11.44, 11.44, 11.44, -16.30840526445022], time: 90.424
mmmaddpg vs mmmaddpg steps: 2174975, episodes: 87000, mean episode reward: 18.24862232826953, agent episode reward: [11.52, 11.52, 11.52, -16.311377671730472], time: 87.404
mmmaddpg vs mmmaddpg steps: 2199975, episodes: 88000, mean episode reward: 20.01436122468082, agent episode reward: [12.4, 12.4, 12.4, -17.18563877531918], time: 87.482
mmmaddpg vs mmmaddpg steps: 2224975, episodes: 89000, mean episode reward: 17.91931221806908, agent episode reward: [11.56, 11.56, 11.56, -16.760687781930915], time: 90.878
mmmaddpg vs mmmaddpg steps: 2249975, episodes: 90000, mean episode reward: 18.184166203322114, agent episode reward: [11.56, 11.56, 11.56, -16.495833796677886], time: 89.841
mmmaddpg vs mmmaddpg steps: 2274975, episodes: 91000, mean episode reward: 18.54489095247109, agent episode reward: [11.77, 11.77, 11.77, -16.76510904752891], time: 89.009
mmmaddpg vs mmmaddpg steps: 2299975, episodes: 92000, mean episode reward: 19.54053197684903, agent episode reward: [11.9, 11.9, 11.9, -16.159468023150968], time: 89.075
mmmaddpg vs mmmaddpg steps: 2324975, episodes: 93000, mean episode reward: 18.54068282322857, agent episode reward: [11.69, 11.69, 11.69, -16.529317176771432], time: 88.612
mmmaddpg vs mmmaddpg steps: 2349975, episodes: 94000, mean episode reward: 16.067379750473595, agent episode reward: [10.18, 10.18, 10.18, -14.472620249526404], time: 89.594
mmmaddpg vs mmmaddpg steps: 2374975, episodes: 95000, mean episode reward: 16.810509026494163, agent episode reward: [10.65, 10.65, 10.65, -15.139490973505836], time: 89.501
mmmaddpg vs mmmaddpg steps: 2399975, episodes: 96000, mean episode reward: 17.216618916796882, agent episode reward: [10.7, 10.7, 10.7, -14.883381083203117], time: 90.843
mmmaddpg vs mmmaddpg steps: 2424975, episodes: 97000, mean episode reward: 20.86360339111406, agent episode reward: [12.58, 12.58, 12.58, -16.876396608885937], time: 91.557
mmmaddpg vs mmmaddpg steps: 2449975, episodes: 98000, mean episode reward: 16.333640378151774, agent episode reward: [10.37, 10.37, 10.37, -14.776359621848227], time: 89.977
mmmaddpg vs mmmaddpg steps: 2474975, episodes: 99000, mean episode reward: 16.90664323718254, agent episode reward: [10.93, 10.93, 10.93, -15.88335676281746], time: 88.688
mmmaddpg vs mmmaddpg steps: 2499975, episodes: 100000, mean episode reward: 15.948542345087057, agent episode reward: [10.65, 10.65, 10.65, -16.001457654912944], time: 89.631
...Finished total of 100001 episodes.
